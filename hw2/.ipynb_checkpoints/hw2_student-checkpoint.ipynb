{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "\n",
       "hr {\n",
       "    height: 1px;\n",
       "    background-color: black;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "div.quote {\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12px;\n",
       "\talign-items: center;\n",
       "\tmax-width: 80%;\n",
       "\ttext-align: center;\n",
       "}\n",
       "\n",
       "div.header_purple {\n",
       "\tbackground-color: #D0C7FF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_purple {\n",
       "\tbackground-color: #9183D9;\n",
       "\tborder-color: #FF8484;\n",
       "\tborder-left: 5px solid #FF8484; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_teagreen {\n",
       "\tbackground-color: #DEEFB7; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_teagreen {\n",
       "\tbackground-color: #DEEFB7;\n",
       "\tborder-color: #5FB49C;\n",
       "\tborder-left: 5px solid #5FB49C; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_aquagreen {\n",
       "\tbackground-color: #AACFC4; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_aquagreen {\n",
       "\tbackground-color: #AACFC4;\n",
       "\tborder-color: #5F758E;\n",
       "\tborder-left: 5px solid #5F758E; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_lightpurp {\n",
       "\tbackground-color: #CBC5EA; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_lightpurp {\n",
       "\tbackground-color: #CBC5EA;\n",
       "\tborder-color: #73628A;\n",
       "\tborder-left: 5px solid #73628A; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_silver {\n",
       "\tbackground-color: #707078; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_silver {\n",
       "\tbackground-color: #707078;\n",
       "\tborder-color: #090909;\n",
       "\tborder-left: 5px solid #090909; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_pink {\n",
       "\tbackground-color: #FFC8C8;\n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_pink {\n",
       "\tbackground-color: #FFC8C8;\n",
       "\tborder-color: #FF8484;\n",
       "\tborder-left: 5px solid #FF8484; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_yellow {\n",
       "\tbackground-color: #FDFFB6; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_yellow {\n",
       "\tbackground-color: #FDFFD0;\n",
       "\tborder-color: #FFD6A5;\n",
       "\tborder-left: 5px solid #FFD6A5; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_orange {\n",
       "\tbackground-color: #FFD6A5; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_orange {\n",
       "\tbackground-color: #FFD6A5;\n",
       "\tborder-color: #D6562C;\n",
       "\tborder-left: 5px solid #D6562C; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_green {\n",
       "\tbackground-color: #CAFFBF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_green {\n",
       "\tbackground-color: #CAFFBF;\n",
       "\tborder-color: #98C98E;\n",
       "\tborder-left: 5px solid #98C98E; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "div.header_blue {\n",
       "\tbackground-color: #C9FAFF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_blue {\n",
       "\tbackground-color: #C9FAFF;\n",
       "\tborder-color: #A0C4FF;\n",
       "\tborder-left: 5px solid #A0C4FF; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "h1 {\n",
       "    text-align: left; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "h2 { \n",
       "    text-align: left; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "#        RUN THIS CELL\n",
    "################################\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"style.css\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class='header_teagreen'>\n",
    "\n",
    "# <img style=\"float: left; padding-right: 10px; width: 60px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> AC295/CS287/E-115B: Deep Learning for NLP\n",
    "\n",
    "<br/>\n",
    "<hr color=black>\n",
    "\n",
    "## Homework 2: Recurrent Neural Networks and Machine Translation\n",
    "### THE TEA GREEN BOOK\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2021**<br/>\n",
    "**Instructor**: Chris Tanner<br/>\n",
    "**Release Date**: September 21 (Tues)<br/>\n",
    "<font color=\"red\">**Due Date**: October 5 (Tues) @ 11:59pm (EST)</font>\n",
    "\n",
    "<hr color=black>\n",
    "<center>\n",
    "<div class='quote'>\n",
    "\n",
    "_\"We don't speak the same language [...] you missin' every single shot that you ain't taken\"_\n",
    "\n",
    "    Malcolm McCormick (August 3, 2018)\n",
    "</div>\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_teagreen'>\n",
    "    \n",
    "# OVERVIEW\n",
    "\n",
    "</div>\n",
    "<br/>\n",
    "This assignment spans the content covered in the following lectures:\n",
    "\n",
    "- **Lecture 5:** Recurrent Neural Networks (RNNs)\n",
    "- **Lecture 6:** LSTMs\n",
    "- **Lecture 7:** seq2seq + Attention\n",
    "- **Lecture 8:** Machine Translation\n",
    "\n",
    "Language is inherently sequential in nature, which makes it conducive to models that can capture the contextual, long-range dependencies. Toward this, you will first gain experience working with a simple RNN. The RNN aims to capture the data's meaning in its hidden layer (like all neural models), which will be used toward a classification task (sentiment analysis of IMDb movies).\n",
    "\n",
    "After seeing the effectiveness of this basic model, you will then extend this model for two missions. As a warm-up, we would like you to try your hand on performing sentiment analysis on an IMDB review dataset. Afterwards, your *true* mission, should you accept, is to make a complete Machine Translation system. There are some evil hackers on the Dark Web who are stealing and selling others' personal information, financial documents, CS287 assignments, etc. To make their operation covert, they are speaking in a \"Mystery Language\". Forensics suspect their mystery language is actually one of the following languages:\n",
    "- Danish\n",
    "- English\n",
    "- German\n",
    "- Finnish\n",
    "- Spanish\n",
    "\n",
    "You are tasked with determining the true identity of their mystery language, so that their words can be read and understood. Help save the day and keep everyone's data safe (for now). ~~This tape will self-destruct in five seconds.~\n",
    "\n",
    "As a heads-up, this assignment is shorter than Homework 1, as we wanted to provide you all with more time to focus on research. This pattern will persist, as each homework assignment will be shorter than the previous. With that said, the models at hand are increasing in complexity, and thus please ensure you allocate sufficient time to building, debugging, and running the models. For example, the last part of Problem 2 (programming) requires you to run your model on 5 different corpora. Our solutions can train the full model in just a few minutes (i.e., 1-5); however, if your solution is overwhelmingly slow, the total running time can start to become a hindrance.\n",
    "\n",
    "If your code runs slowly on your own local machine, you are free to run your code on [Google Colab](https://colab.research.google.com/) -- just be mindful that the academic policy is still in tact, and that nobody else should have access to your code. In terms of grading, in general, we will not be too picky with the _efficiency_ of your code, unless it's egregious. Having a sound solution is the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_teagreen'>\n",
    "    \n",
    "# LEARNING OBJECTIVES\n",
    "\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "The purpose of this homework is to help you:\n",
    "\n",
    "- understand the sequential nature of language\n",
    "- develop a strong foundation in working with recurrent networks\n",
    "- gain experience working with text classification\n",
    "- understand the mechanics of a basic, neural Machine Translation system\n",
    "- think critically about how language can be used and leveraged (e.g., for classification and translation), while recognizing strengths and weaknesses.\n",
    "\n",
    "To assist you reach these learning objectives, this homework is structured into three parts:\n",
    "- <span style=\"background-color: #FDFFB6\"><b>Foundation (concepts):</b></span> demonstrate an understanding of the core concepts taught in lectures\n",
    "- <span style=\"background-color: #FFC8C8\"><b>Application (programming):</b></span> gain experience putting that knowledge into practice \n",
    "- <span style=\"background-color: #CAFFBF\"><b>Research (creating new knowledge):</b></span> use your current NLP knowledge and skills to go beyond the course material, to grasp cutting-edge results and to critically accept or challenge that information. This serves as practice for you to research your own NLP interests and to be well-equipped to continuously learn the latest, greatest NLP work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_teagreen'>\n",
    "    \n",
    "## SUPPORT\n",
    "\n",
    "</div>\n",
    "\n",
    "- **Supplemental Resources:** See the list of [supplemental resources](https://harvard-iacs.github.io/CS287/supplemental) for a wealth of rich information concerning Machine Learning, NLP, and Math. Some of the courses listed concern the exact topics covered in this homework and lectures.\n",
    "- **Sanity Check cells:** Throughout the homeworks, we sometimes provide 'sanity check' cells which allow you to see our expected outputs. You should ensure your code produces the same. <span style=\"background-color: #FDFFB6\"><b>**NOTE:** We are not claiming that passing the sanity check cells indicates that you have _fully_ implemented everything correctly; rather, they provide simple checks to help inform you if you are on the right track.</span>\n",
    "- **Ed**: If you are stuck on anything conceptual (not code) about the content from lectures, please post a question on Ed. This is your community, and please contribute and help each other out. If your questions concern the homework, you can post these on Ed, too, but make sure you are not posting any of your code or solutions in general. If you think you've spotted a bug in our homework questions, or something that needs clarifying, please let us know on Ed! <span style=\"background-color: #FDFFB6\">Extra credit will be awarded for bugs.</span> We want to correct these issues ASAP.\n",
    "- **OH:** After having given a wholehearted attempt, if you are having trouble with the homework, please come to Office Hours.\n",
    "- **Classmates:** We have a strict policy about the homeworks being individual. You are free to discuss _concepts_ with one another, to help each other learn the material. However, no student shall ever discuss their solutions or see another student's solutions to any problem. Once you see someone's coding solution, it's nearly impossible to harness that information in a way that you can write your own unique solution. You've been robbed of a learning opportunity and will likely just regurgitate someone else's work. As a reminder, if you want to take a shortcut on any problem by looking online for already-existing solutions, that's permissible, but you must cite your sources. Otherwise, it constitutes cheating. Posting any pieces of this homework online for others to see if a flagrant violation of our academic policy.\n",
    "- **Other:** I want everyone to be and feel fully supported. If there's anything else we, as a teaching staff, can do to further assist in your learning, please let us know. Related, at the end of this homework assignment, you are expected to complete an anonymous feedback form. I urge you to critically and earnestly think about your own learning, communicate to us your thoughts, and to optionally tell us possible adjustments we could make so that you meet our learning expectations and you achieve your own learning goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_lightpurp'>\n",
    "    \n",
    "# 1. FOUNDATION (CONCEPTS) [10 points]\n",
    "\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_lightpurp'><b>1.1 RNN [2 points]</b>\n",
    "\n",
    "Recall the standard, canonical RNN that was discussed in Lecture 5. Our hidden layer at timestep $t$ is defined as $h_{t} = f([h_{t-1}; x_{t}])$, where:\n",
    "\n",
    "- $f()$ is any non-linear activation function\n",
    "- $x$ corresponds to the input Embedding (densely encoded, not one-hot representation)\n",
    "- $;$ represents vector concatenation\n",
    "- this is a slightly abstract view, as we are not explicitly showing the two weight matrices by which $h_{t-1}$ and $x_{t}$ are being multipled before they're concatenated together. We're also not indicating the bias.\n",
    "\n",
    "Let's say we change $h_{t}$ as follows:\n",
    "\n",
    "$h_{t} = f([x_{t-1}; x_{t}])$\n",
    "\n",
    "In 2-3 sentences, discuss how and why you expect this to affect performance.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE\n",
    "\n",
    "If we modify $h_t$ to be as described then we are basically losing the memory capacity of the RNN. So, we will not be able to model long term relationships within the language and thus our results will be degraded. Basically, when we generate each new hidden state we will only be feeding into the model the current word embedding $x_t$ and the previous word embedding $x_{t-1}$ but not much more than that. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_lightpurp'><b>1.2 seq2seq with Attention [2 points]</b>\n",
    "\n",
    "NOTE: This question concerns the standard Attention discussed in Lecture 7, not Self-Attention\n",
    "Which of the following statements about Attention are true (select all that apply)?\n",
    "\n",
    "- A: Attention is used for situations where you have both an encoder and decoder model\n",
    "- B: Attention determines how much emphasis to place on each hidden state from an encoder\n",
    "- C: Attention determines how much emphasis to place on each hidden state from a decoder\n",
    "- D: Attention scores can be computed in various ways (e.g., dot-product, bilinear transformation, feed-forward neural network)\n",
    "\n",
    "No explanation needed, just write below the letters you believe are true statements.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE\n",
    "Correct answers are B and D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_lightpurp'><b>1.3 Machine Translation: Directionality [2 points]</b>\n",
    "\n",
    "Let's say we have a parallel corpus of 100,000 sentences in two languages: \"source language\" and \"target language\". For example, perhaps the \"source language\" is Indonesian and the \"target language\" is English, and sentence $i$ in the English corpus is the translation of sentence $i$ in the Indonesian corpus.\n",
    "\n",
    "Let's model Machine Translation with a `seq2seq model with Attention` that operates on word tokens. Generally, for any particular pair of languages (e.g., Language $A$ and Language $B$), will the model yield the \"same\" results regardless of if language $A$ serves as the \"source\" language or \"target\" language?\n",
    "\n",
    "Few clarifying statements about what we're asking:\n",
    "\n",
    "- We are contrasting (1) treating language $A$ as the source language and $B$ as the target language; versus, (2) treating $A$ as the target language and $B$ as the source language\n",
    "- We are **not** contrasting language pairs ($A$,$B$) with language pairs ($C$, $D$), or even ($B$, $C$).\n",
    "- By \"same results\", we are not nitpicking about floating point precision and natural variation. Rather, we assert that any model trained on a given pair $(A, B)$, when run a few times, will naturally produce slightly varying results (due to the stochasticity of a NN), which one can summarize as a performance _range_. We are effectively asking if reversing the language pairs to be $(B,A)$ will yield performance that is consistently within the same performance _range_ as $(A, B)$.\n",
    "- We assume all other experimental setup is sound; e.g., nothing unusual with the train/dev/test splits. So, you can expect that in every situation, the first 70k sentences are used for train, the next 10k for dev, and the remaining 20k for test.\n",
    "\n",
    "Please discuss in 3-4 sentences your model expectations and justify.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE\n",
    "\n",
    "The model will not yield the same results if we use language A as a source vs using language A as a target. The intuition of this is that when we use language A for training, we will get a specific set of hidden states that model the connections and structure of language A and then, when working with the decoder, we use these hidden states all the time for generating the attention weights. In contrast, if we use language A as a target, we will only use the hidden states generated from language A in the decoding stage, thus we won't have the model of the structure of language A in the encoding hidden states but rather as an input for the prediction step. THus, when language A is the target, we won't have the information of the encodings of A in the attention weights. Hence, given the change in hidden states from the encodings and the attention weights when we change language A to be either source or target, we expect the results to be quite different. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_lightpurp'><b>1.4 Machine Translation: Denoising [4 points]</b>\n",
    "\n",
    "Again, let's say we have a parallel corpus of 100,000 sentences in two languages (\"source language\" and \"target language\"), and that we're using a `seq2seq model with Attention` that operates on word tokens.\n",
    "\n",
    "**PART 1 (2 points):**\n",
    "If we alter our corpus such that for **every distinct, non-white space character** in the source language, we instantly replace it with a corresponding **different, distinct, non-whitespace character**. Then, we run the same model, from scratch, on this modified corpus. Would you expect the performance of the system to decrease, stay the same, or improve? Discuss in ~3 sentences what your expectations are and why.\n",
    "\n",
    "**PART 2 (2 points):**\n",
    "If we alter our corpus such that for **every distinct, non-white space character** in the source language, we instantly replace it with a corresponding **different, distinct, character (that may include whitespace)**. Then, we run the same model, from scratch, on this modified corpus. Would you expect the performance of the system to decrease, stay the same, or improve? Discuss in ~3 sentences what your expectations are and why.\n",
    "\n",
    "Few clarifying statements about what we're asking in PART 1 and PART 2:\n",
    "\n",
    "- each distinct character in the source language (e.g., 'a' will be consistently replaced with a different distinct character such as 'p')\n",
    "- no two characters in the original source language should become replaced by the same character (i.e., if 'a' is replaced with 'p', then no other letter will also be replaced by a 'p')\n",
    "- this is not a Distributed Systems class; we're **not** treating this replacement as a _series_ of replacements. That is, we do not need to worry about any race conditions. Letters are simply getting mapped to others.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE\n",
    "PART 1: If we just map every character in the source language to a distinct non-whitespace character in a one-to-one fashion, we don't expect the performance of the system to decrease. I believe this because we are basically encoding the same relationships between words and have the same number of words in the source language and the new encoded language, thus the model should learn the same representations and the same connections between the words.\n",
    "\n",
    "PART 2: If we ap every distinct, non-white space charater to different, distinct, character (including whitespaces) then I do expect the model performance to decrease. In particular, I expect this because now there is a chance of splitting a word into more than 1 word if two or more characters in the word are mapped to white spaces. This changes the number of words we have in the encoded language and possibly the relationships between the words. Thus, the model would effectively be learning representations of a different language than the initial source language. Thus, we should se a decrease in the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_yellow'>\n",
    "    \n",
    "# 2. APPLICATION (PROGRAMMING) [70 points]\n",
    "\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "\n",
    "In this programming exercise, you will be guided through an implementation of the encoder-decoder.\n",
    "\n",
    "We start with an RNN-based `Encoder`, from which we can extract the final hidden state and cell state. LSTM units are used so that we can retain long-term dependencies. We treat the final vectors as a summary of the sentence, which we can use for binary classification on the text. We will apply this idea to the sentiment analysis of an IMDB movie review dataset, where we hope to determine whether a review is positive or negative. \n",
    "\n",
    "Building on the `Encoder`, we will further add on an RNN-based `Decoder`. This time, we will work on a translation task between source language and target language. We feed the source sentence to the Encoder, obtain the final states and feed them into the `Decoder`. The outputs of the Decoder is our translation.\n",
    "\n",
    "In total, you will gain hands-on experience building an important, powerful model (RNN-based Encoder/Decoder), which you'll demonstrate as being highly useful for completely different tasks and data. We're starting to see the beauty of using deep learning models for NLP!\n",
    "\n",
    "### DATA\n",
    "\n",
    "See the relevant section for a detailed description of the data we use. \n",
    "\n",
    "### PANDAS\n",
    "In all homework assignments, including this one, you are free to use `Pandas`. You are not required to use it at all, but it has some highly useful functionality, e.g., its `read_csv()` function, `DataFrame` and `Series` data structures, and its ability to quickly filter/sort/edit data (which is particularly helpful when experimenting and exploring your data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities you will need or are free to use\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, NLLLoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_yellow'>\n",
    "\n",
    "# IMDb Sentiment Analysis\n",
    "\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "For this problem, we're going to build a binary sentiment classifier for movie reviews using the classic [IMDb dataset](https://ai.stanford.edu/~amaas/data/sentiment/). \n",
    "\n",
    "## Data\n",
    "\n",
    "Since you've already seen how to process and handle raw text data in HW1, we've gone ahead and handled the data processing and infrastructure for you this time. We've trimmed the reviews of punctuation and HTML tags, removed stop words, and [lemmatized](https://en.wikipedia.org/wiki/Lemmatisation) the remaining tokens using [NLTK's WordNet Lemmatizer](https://www.nltk.org/_modules/nltk/stem/wordnet.html). For example, the review:\n",
    "> Billy Crystal normally brings the crowd to laughter, but in this movie he and all the rest of them cannot bring any smile on my face.... or perhaps just one. They call it comedy, I say it's a waste of my time.\n",
    "\n",
    "Becomes:\n",
    "> ['billy', 'crystal', 'normally', 'bring', 'crowd', 'laughter', 'movie', 'rest', 'bring', 'smile', 'face', 'perhaps', 'one', 'call', 'comedy', 'say', 'waste', 'time']\n",
    "\n",
    "For the sake of training speed, we've limited the original corpus of 50,000 reviews to just 5,000 by filtering for only reviews that are shorter than 100 words. \n",
    "\n",
    "We've provided two datasets for you to use in the form of Python Pickle files ([documentation on what Pickling is](https://docs.python.org/3/library/pickle.html)):\n",
    "- `imdb_train.pkl` contains 4000 reviews for training. \n",
    "- `imdb_test.pkl` contains 1000 reviews for testing.\n",
    "\n",
    "Each pickled file contains a dictionary formatted as follows: \n",
    "\n",
    "```\n",
    "{\n",
    "    'tokenized_reviews': [\n",
    "        [token, token, token, ...],\n",
    "        [token, token, token, ...],\n",
    "        ...\n",
    "    ],\n",
    "    'full_reviews': [review review review ...],\n",
    "    'sentiments': [sentiment sentiment sentiment ...]\n",
    "}\n",
    "```\n",
    "Where each sentiment is binary, either `\"positive\"` or `\"negative\"`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.1 Load the data [0 points]</b>\n",
    "\n",
    "In the cell below, we load each dataset for you (simply run the cell). Note that you can load each dataset using the `pickle` module in Python's standard library: \n",
    "```py\n",
    "import pickle\n",
    "with open(\"imdb_train.pkl\", \"rb\") as fp:\n",
    "    train_dict = pickle.load(fp)\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU DO NOT NEED ADD ANY CODE IN THIS CELL\n",
    "with open(\"data/imdb_train.pkl\", \"rb\") as f:\n",
    "    train_dict = pickle.load(f)\n",
    "    \n",
    "with open(\"data/imdb_test.pkl\", \"rb\") as f:\n",
    "    test_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encourage you to inspect and perform some *quick* exploratory data analysis on the IMDb reviews and sentiments. For instance, what percentage of the sentiments are positive? Understanding the data before training the data can often lead to very useful observations. Should you be worried if it turns out that only $1\\%$ of the datapoints are labelled negative?\n",
    "\n",
    "This part is for your understanding only. Do not worry, we will not grade it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, there is 50.0% of negative reviews and 50.0% of positive reviews.\n",
      "In test set, there is 50.0% of negative reviews and 50.0% of positive reviews.\n",
      "For training set, number of reviews is 4000 and length of max review is 81\n",
      "For test set, number of reviews is 1000 and length of max review is 80\n"
     ]
    }
   ],
   "source": [
    "# TODO: inspect the dicts and perform some quick exploratory analysis\n",
    "# Percentage of positive and negative reviews training\n",
    "train_perc_neg = len([x for x in train_dict['sentiments'] if x=='negative'])/len(train_dict['sentiments'])*100\n",
    "train_perc_pos = len([x for x in train_dict['sentiments'] if x=='positive'])/len(train_dict['sentiments'])*100\n",
    "\n",
    "print(f\"In training set, there is {train_perc_neg}% of negative reviews and {train_perc_pos}% of positive reviews.\")\n",
    "\n",
    "test_perc_neg = len([x for x in test_dict['sentiments'] if x=='negative'])/len(test_dict['sentiments'])*100\n",
    "test_perc_pos = len([x for x in test_dict['sentiments'] if x=='positive'])/len(test_dict['sentiments'])*100\n",
    "\n",
    "print(f\"In test set, there is {test_perc_neg}% of negative reviews and {test_perc_pos}% of positive reviews.\")\n",
    "\n",
    "# Number of reviews and max size\n",
    "num_reviews_train = len(train_dict['full_reviews'])\n",
    "num_reviews_test = len(test_dict['full_reviews'])\n",
    "max_review_train = max([len(x) for x in train_dict['tokenized_reviews']])\n",
    "max_review_test = max([len(x) for x in test_dict['tokenized_reviews']])\n",
    "\n",
    "print(f\"For training set, number of reviews is {num_reviews_train} and length of max review is {max_review_train}\")\n",
    "print(f\"For test set, number of reviews is {num_reviews_test} and length of max review is {max_review_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the data into a Dataset\n",
    "\n",
    "For time efficiency, we've also provided you a `torch.utils.data.Dataset` class below which generates an indexed vocabulary from a given corpus. Note that it replaces infrequent words with the `<UNK>` token and appends an `<EOS>` tag to the end of each review. Also note that it can accept another corpus' vocabulary instead of generating its own. This is helpful because, as you should remember from lecture, we need our model to be able to interpret and use all of the tokens that we encounter at _test time_. We always rely on our training set to provide us with the vocabulary we are expected to see, so it's nice to have the freedom to easily \"import\" another expansive vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU DO NOT NEED ADD ANY CODE IN THIS CELL\n",
    "\n",
    "# Some useful helper functions, which we will need for later...\n",
    "PADDING_IDX = 0\n",
    "EOS_IDX = 1 \n",
    "UNK_IDX = 2\n",
    "\n",
    "def get_word_counts(reviews: List[List[str]]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Given a tokenized corpus (in this case reviews), we count the frequency of\n",
    "    each word in the corpus\n",
    "    \"\"\"\n",
    "    word_counts = {}\n",
    "    for review in reviews:\n",
    "        for word in review:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "    return word_counts\n",
    "\n",
    "def generate_vocab(word_counts: Dict[str, int], min_freq: int) -> Tuple[Dict[str, int], int]:\n",
    "    \"\"\"\n",
    "    Given a set of word counts, we generate a vocabulary. We return two things\n",
    "    from this method:\n",
    "\n",
    "        1. A dict mapping tokens to indices\n",
    "        2. THe length of the vocab\n",
    "    \n",
    "    Words that occur fewer than `min_freq` are replaced with <UNK>\n",
    "    \"\"\"\n",
    "\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    vocab = {word: i+3 for i, (word, count) in enumerate(sorted_words) if count > min_freq}\n",
    "    vocab[\"<PAD>\"] = PADDING_IDX\n",
    "    vocab[\"<EOS>\"] = EOS_IDX \n",
    "    vocab[\"<UNK>\"] = UNK_IDX\n",
    "    return vocab, len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU DO NOT NEED ADD ANY CODE IN THIS CELL\n",
    "class IMDBDataset(Dataset):   \n",
    "    def __init__(self, reviews: List[List[str]], sentiments: List[str], min_freq=3, vocab=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if vocab is None:\n",
    "            word_counts = get_word_counts(reviews)\n",
    "            self.vocab, self.vocab_size = generate_vocab(word_counts, min_freq)\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "            self.vocab_size = len(vocab)\n",
    "\n",
    "        self.reviews, self.targets = self._get_idx_dataset(reviews, sentiments, self.vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.reviews[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "    def _get_idx_dataset(self, corpus: List[List[str]], labels: List[str], vocab):\n",
    "        reviews = []\n",
    "        targets = []\n",
    "        for review, label in zip(corpus, labels):\n",
    "            reviews.append([vocab[token] if token in vocab else vocab[\"<UNK>\"] for token in review] + [vocab[\"<EOS>\"]])\n",
    "            targets.append(0.0 if label == \"negative\" else 1.0)\n",
    "        \n",
    "        return reviews, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.2 Instantiate Two Datasets [2 points]</b>\n",
    "    \n",
    "Instantiate two `IMDBDataset`'s, one train and one test, **making sure to use the training vocabulary when instantiating the test dataset** (as this is all our model rightfully knows).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize the following datasets\n",
    "train_ds = IMDBDataset(train_dict['tokenized_reviews'], train_dict['sentiments'])\n",
    "test_ds = IMDBDataset(test_dict['tokenized_reviews'], test_dict['sentiments'], vocab=train_ds.vocab)\n",
    "\n",
    "#raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='q_yellow'><b>2.3 Collation and padding [2 points]</b>\n",
    "\n",
    "Each review is of varying length, but we'd like to combine them together into a single batch (i.e., a 2D matrix, where all data instances are of the same length). So, in order to batch them, we'll need to define a custom collate function which pads them all to the same length. This functionality is the same as in the first homework. However, unlike last time, we'll also need to return a Tensor of labels. Note that since our dataset's `__getitem__()` function returns multiple values (i.e., a Tuple), so our collate function will receive as input a **list of tuples.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_classifier(batch: List[Tuple[torch.tensor, torch.tensor]]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "    batch_tokens = [item[0] for item in batch]\n",
    "    batch_targets = [torch.unsqueeze(item[1],0) for item in batch]\n",
    "    padded_batch = pad_sequence(batch_tokens, batch_first=True, padding_value=PADDING_IDX)\n",
    "    return (padded_batch, torch.stack(batch_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.4 Instantiating DataLoaders [1 point]</b>\n",
    "\n",
    "Instantiate two `DataLoader` objects, one train and one test, with our custom collate function and with other arguments as appropriate (see the [docs](https://pytorch.org/docs/stable/data.html) for more details).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: intialize the dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True, collate_fn=pad_collate_classifier)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True, drop_last=True, collate_fn=pad_collate_classifier)\n",
    "\n",
    "#raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2149,  236,    8,  ...,  916,  624,    1],\n",
      "        [  18,    5,   29,  ...,    0,    0,    0],\n",
      "        [ 324,   29,    4,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  32, 1137,    4,  ...,    0,    0,    0],\n",
      "        [  95,   32,  776,  ...,    0,    0,    0],\n",
      "        [  62,  150,  115,  ...,    0,    0,    0]]), tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]))\n",
      "(tensor([[  36,  599, 1063,  ...,    0,    0,    0],\n",
      "        [ 154,   68, 3132,  ...,    0,    0,    0],\n",
      "        [ 144, 1040,  357,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 180,  180,  180,  ...,    0,    0,    0],\n",
      "        [  65,   50,  302,  ...,    0,    0,    0],\n",
      "        [ 181, 2445,   86,  ...,    0,    0,    0]]), tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]))\n"
     ]
    }
   ],
   "source": [
    "train_batch = next(iter(train_dl))\n",
    "test_batch = next(iter(test_dl))\n",
    "print(train_batch)\n",
    "print(test_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.5 The LSTM Encoder [7 points]</b>\n",
    "\n",
    "Now it's time to implement the Encoder class. As usual, we'll extend the `torch.nn.Module` class. Remember that we have to implement the following methods:\n",
    "1. An `__init__()` method which instantializes the `Module` object. Here, we typically save input variables (such as model hyperparameters) and define/instantiate our layers. \n",
    "    - For the LSTM Encoder, we've provided the signature of `__init__()`. \n",
    "    - For simplicity, instantiate a fresh Embedding layer (rather than using existing embeddings)\n",
    "    - No need implement your own LSTM from scratch! For this homework, it suffices to use the PyTorch [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) class. Be sure to read the docs thoroughly to understand the parameters.\n",
    "\n",
    "2. A `forward()` method which takes as input (1) a batch of data from the `DataLoader`; and (2) the lengths of each sequence in the batch. The `forward()` method returns a tuple of two tensors: (a) the final hidden state (i.e., \"short-term memory\") and (b) the final cell state (i.e., \"long-term memory\") of the LSTM.\n",
    "\n",
    "In your code for `forward()`, you will need to make use of a function that is important for RNNs: the `torch.nn.utils.rnn` method [`pack_padded_sequence`](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html).  To gain some intuition on what this method is doing, see this [StackOverflow post](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch/) (especially the diagrams).  There are two reasons why we need `pack_padded_sequence()`:\n",
    "- First, packing saves computation for batch sequences, especially if there is a lot of padding involved. Packing before feeding sequences to an LSTM can speed up computation if there is one sequence in your batch that is much longer than all of the others.\n",
    "- The second, and more important, reason is that packing is used for *extracting the correct hidden state for each element of the batch* after passing the sequence through the LSTM.  Let's say we have $B$ sequences in our batch, and they have lengths $t_1, t_2, \\ldots, t_B$.  The size of `input_seqs` (i.e., the input to `forward()`) will be $B \\times T$, where $T = \\max_{i=1}^B t_i$.  Recall that in LSTMs, a hidden state is generated *for each time step* from $1$ to $T$. However, we want to ensure that for the first element in the batch, we end up extracting the hidden state corresponding to time $t_1$ (and for the second element, $t_2$, and for the third element, $t_3$, etc.). In short, packing helps us achieve this.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASK WHERE WE SHOULD USE PADDING IDX\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, padding_idx: int):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.embeddings = nn.Embedding(input_size, hidden_size)#, padding_idx=self.padding_idx) \n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True) ## ASK WHAT TO DO WITH THESE DIMENSIONS\n",
    "        \n",
    "    def forward(self, input_seqs: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        seqs_length = [((t == self.padding_idx).nonzero(as_tuple=True)[0])[0].item() if len(((t == self.padding_idx).nonzero(as_tuple=True)[0])) != 0 else t.shape.numel() for t in input_seqs]\n",
    "        embedding_sequences = self.embeddings(input_seqs)\n",
    "        packed_seq_batch = torch.nn.utils.rnn.pack_padded_sequence(embedding_sequences, lengths=seqs_length, batch_first=True, enforce_sorted=False)\n",
    "        output, (hn, cn) = self.lstm(packed_seq_batch) \n",
    "        return (hn, cn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation cell\n",
    "\n",
    "#LSTM = EncoderLSTM(10, 10, 4)\n",
    "# evaluation cell\n",
    "batch = next(iter(train_dl))\n",
    "model = EncoderLSTM(train_dl.dataset.vocab_size, 100, PADDING_IDX)\n",
    "hidden_cell, final_cell = model(batch[0]) # Alias for model.forward(batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 100])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cell.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.6 Binary Classifier [7 points]</b>\n",
    "\n",
    "Now we can use our Encoder class to create a binary classifier! Again, we'll subclass `torch.nn.Module`, and you'll need to implement the `__init__()` and `forward()` methods. \n",
    "\n",
    "Since we've already designed the Encoder, we can use an instance of our LSTM Encoder class here. In particular, we can take the final (hidden, cell) states as features and use them as input to a standard classifier network. We'll leave the particular details up to you here. \n",
    "\n",
    "As this is a binary classifier, you may want to add a final sigmoid output layer to your network. However, best practice is to leave the model without the softmax and instead incorporate it into the loss function (take a look at [`torch.nn.BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) and the more general [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) due to numerical stability improvements from the [log-sum-exp trick](https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/). Thus, your model should output logits (i.e., values *before* softmax), rather than probabilities (i.e., values *after* softmax), and use an appropriate loss function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, padding_idx: int):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        # Number of input features is 12.\n",
    "        self.layer1 = nn.Linear(self.hidden_size*2, 256)\n",
    "        self.dropout = nn.Dropout(p=0.05)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_out = nn.Linear(256, 1) \n",
    "        self.encoder = EncoderLSTM(self.input_size, self.hidden_size, self.padding_idx)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        hidden_cell, final_cell = self.encoder(input_seq)\n",
    "        concat_cell_torch = torch.cat([hidden_cell, final_cell], -1)\n",
    "        out = self.layer1(concat_cell_torch)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        output = self.layer_out(out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.7 Train the classifier [9 points]</b>\n",
    "\n",
    "Now, we get to train our classifier! Remember that we'll need to:\n",
    "1. Choose an optimizer. (Adam with default settings works well for us but feel free to experiment!)\n",
    "2. Choose a loss function. (Remember that for classifiers, this should be tied to your model's final, output layer.)\n",
    "3. Write a training loop. (We recommend 10-15 epochs.) **Please compute and print/graph a loss and a classification accuracy for each epoch on both the test and train sets.**\n",
    "    \n",
    "For reference, our solution runs 8 epochs in 7 minutes 25 seconds (on an i7-8650U @ 1.9 GHz).\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 0.633, training accuracy: 63.464\n",
      "Epoch 1, testing loss: 0.013, testing accuracy: 72.774\n",
      "Epoch 2, training loss: 0.551, training accuracy: 71.856\n",
      "Epoch 2, testing loss: 0.022, testing accuracy: 76.677\n",
      "Epoch 3, training loss: 0.340, training accuracy: 85.880\n",
      "Epoch 3, testing loss: 0.021, testing accuracy: 81.258\n",
      "Epoch 4, training loss: 0.230, training accuracy: 91.568\n",
      "Epoch 4, testing loss: 0.007, testing accuracy: 81.258\n",
      "Epoch 5, training loss: 0.143, training accuracy: 94.864\n",
      "Epoch 5, testing loss: 0.016, testing accuracy: 78.871\n",
      "Epoch 6, training loss: 0.120, training accuracy: 95.904\n",
      "Epoch 6, testing loss: 0.018, testing accuracy: 77.613\n",
      "Epoch 7, training loss: 0.058, training accuracy: 98.248\n",
      "Epoch 7, testing loss: 0.043, testing accuracy: 79.194\n",
      "Epoch 8, training loss: 0.072, training accuracy: 97.536\n",
      "Epoch 8, testing loss: 0.034, testing accuracy: 79.258\n",
      "Epoch 9, training loss: 0.045, training accuracy: 98.560\n",
      "Epoch 9, testing loss: 0.026, testing accuracy: 79.903\n",
      "Epoch 10, training loss: 0.010, training accuracy: 99.736\n",
      "Epoch 10, testing loss: 0.038, testing accuracy: 79.742\n",
      "Epoch 11, training loss: 0.002, training accuracy: 99.952\n",
      "Epoch 11, testing loss: 0.081, testing accuracy: 80.774\n",
      "Epoch 12, training loss: 0.001, training accuracy: 99.976\n",
      "Epoch 12, testing loss: 0.027, testing accuracy: 80.742\n",
      "Finished Training\n",
      "CPU times: user 20min 23s, sys: 1min 26s, total: 21min 49s\n",
      "Wall time: 15min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "final_model = BinaryClassifier(train_dl.dataset.vocab_size, 512, PADDING_IDX)\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# TODO: train the model!\n",
    "loss_function = BCEWithLogitsLoss()\n",
    "optimizer =  Adam(final_model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "epochs = 12\n",
    "\n",
    "losses = {\n",
    "    'train': [], # keep track of your losses in these lists\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "accuracies = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    avg_training_acc = 0\n",
    "    test_running_loss = 0.0\n",
    "    avg_testing_acc = 0\n",
    "    \n",
    "    for i, train_batch in enumerate(train_dl):\n",
    "        word_seq, targets = train_batch\n",
    "        \n",
    "        just_model = torch.squeeze(final_model(word_seq),0)\n",
    "        loss = loss_function(just_model, targets)\n",
    "        training_acc = binary_acc(just_model, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        avg_training_acc += training_acc.item()\n",
    "        \n",
    "    for i, test_batch in enumerate(test_dl):\n",
    "        with torch.no_grad():\n",
    "    \n",
    "            test_word_seq, test_targets = test_batch\n",
    "            final_model.eval()\n",
    "            test_logit_output = torch.squeeze(final_model(test_word_seq), 0)\n",
    "            test_loss = loss_function(test_logit_output, test_targets)\n",
    "            testing_acc = binary_acc(test_logit_output, test_targets)\n",
    "            \n",
    "            test_running_loss += test_loss.item()\n",
    "            avg_testing_acc += testing_acc.item()\n",
    "\n",
    "        \n",
    "    print('Epoch %d, training loss: %.3f, training accuracy: %.3f' %\n",
    "            (epoch + 1, running_loss/len(train_dl), avg_training_acc/len(train_dl)))\n",
    "    print('Epoch %d, testing loss: %.3f, testing accuracy: %.3f' %\n",
    "            (epoch + 1, test_loss/len(test_dl), avg_testing_acc/len(test_dl)))\n",
    "    \n",
    "    losses['train'].append(running_loss/len(train_dl))\n",
    "    losses['test'].append(test_running_loss/len(test_dl))\n",
    "    accuracies['train'].append(avg_training_acc/len(train_dl))\n",
    "    accuracies['test'].append(avg_testing_acc/len(test_dl))\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [0.633010810136795, 0.5508565953969955, 0.33979962587356566, 0.230233225107193, 0.14267847253382207, 0.12023570550978184, 0.057634784769266846, 0.07170662193931639, 0.044881610985845324, 0.009590006170561537, 0.0022450025199796074, 0.0014981188217643648], 'test': [0.5281161137165562, 0.5685331643589081, 0.4289443146797918, 0.5061669227096343, 0.5461046258288045, 0.7217815571254299, 0.7109184438182462, 0.7952902956355002, 0.8827915297400567, 1.0788730642487925, 1.188762322548897, 1.2467801164715522]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e06e0f50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optionally plot your losses\n",
    "print(losses)\n",
    "pd.DataFrame(losses).plot(title='Train and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [63.464, 71.856, 85.88, 91.568, 94.864, 95.904, 98.248, 97.536, 98.56, 99.736, 99.952, 99.976], 'test': [72.7741935483871, 76.6774193548387, 81.25806451612904, 81.25806451612904, 78.87096774193549, 77.61290322580645, 79.19354838709677, 79.25806451612904, 79.90322580645162, 79.74193548387096, 80.7741935483871, 80.74193548387096]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e06f4890>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1f3/8dcn+0pCFkJISAKC7BggIoJS3EVRxH0Ft+K3tla7qm1da1ur1lp/bVVcqVtVFrGKiPu+QYgQ1rCTEEIIhOzrnN8f9wZCSELITHJnJp/n4zGPmbl37p3PzSTv3Dn33HPFGINSSin/EuB0AUoppTxPw10ppfyQhrtSSvkhDXellPJDGu5KKeWHNNyVUsoPabgrAEQkUEQqRCTNC2r5QkSu7ep1i8gsEXm3K+oQkYEiUtG5KpVyn4a7j7KDuOnmEpHqZs+vOtr1GWMajTFRxpjtXVGvJ4jINSKyqZXpISKyR0TOPpr1GWPmGmOmeqi2fBGZ0mzdm40xUZ5YdxvvJyKyTURWdtV7KN+m4e6j7CCOsgNkO3Bes2kvt3y9iAR1f5UeNx9IFJGTWkw/B6gD3u/+khxzKhAHDBWRMd35xn7yu+T3NNz9lIg8ICKvicirIlIOXC0iJ4rINyJSKiKFIvK4iATbrw8SESMiGfbzl+z574pIuYh8LSID2nivABGZJyK77HV/IiLDms1vd10icraIrBeR/SLyD0Baex9jTBUwD5jZYtZM4CVjTKOIxIvIYhEpFpF9IvI/EUlpo+4bReSTjtQhIoNF5GMRKbG/JbwoIjH2vFeBfsC79jenX4rIIBExzZZPFZG3RWSviOSJyPUtPqtX7Z9TuYjkisjY1mpuZhawAFhiP26+XfEi8oL9Ge8TkfnN5l0oIjkiUiYiG0XkTHv6Id887JpesB8Psn83rhOR7cDSDnzmESLydxHZbv88PxORUBF5T0R+0qLeNSIy7Qjbq46Shrt/mwG8AsQArwENwK1AAjAJOBu4qZ3lrwTuwtpD3A78sZ3Xvg0MBvoCucCLHVmXiPTBCuw77LrygRPaeZ+5wKUiEmYv3xs4F/iPPT8AeBpIA9KBeuAf7ayPDtYhwANAMjAcGGhvD8aYK4CdwFT7m9OjrbzFa8AWrH8ClwEPiciPms2/AOtnFgu8CzzeTq1RwIXAy/btihZ7068AIXadSU3bLyITgeeAX9nvcwqwrZ0fS0uTgaFYP29o/zP/OzAa62cYB/wOcGF9flc325ZxWD/vJUdRh+oIY4zefPwGbAVObzHtAeCjIyz3a+AN+3EQYIAM+/lLwJPNXns+kNvBehLsdUUeaV3A9cAXzeYFAIXAtW2sW4DNwKX2858Ay9upJQsobvb8i6Z1AzcCn3SyjouB75s9zwemNHs+yPrzMgADsP7JRDab/zDwTLPPakmzeaOBina26VpgFxAIhAPlWM1yAP2x/onHtLLcs8DDbayzZf0PAC803xYgrSOfuV1XLTCildeFA6XAQPv5Y8DjTv8N+eNN99z9247mT0RkqIi8Y3+VLgPux/qjbMuuZo+rgFYPEIrV0+YhEdlsr3ejPav5uttaV7/mdRpjXFhB0yo7LV/kYNPMNVh7g021RIrIM3ZzQBnwEe1vY5N26xCRviLyuogU2Ot9oYPrbVr3HmNMZbNp24DmzUUtfz6R7axvFvCasQ6CVwMLOdg0099+r/2tLNcfOOyA9FE48PM5wmeehPXN4bD3suudB1wlIoHA5Rz+LU95gIa7f2s55OdTWF+fBxljegF300b79lGaiXVQ81SsJqBB9vSOrLsQK3SsBUQCgNQjLPMf4Ey7mSELeLXZvN9i7SmPt7fx1I5sQAfq+CvW3ugoe73Xcuj2tTe86k4gQUSaB3YaUNDB2g4QkXTgR8C19j/pXVhNOtPsJqod9nv1amXxHcAxbay6Eoho9rxvyxfY/1ibtPeZF2Ed4G7rveYCVwFnAvuMMd+38TrlBg33niUa2A9U2ge/2mtvP9r11gIlWAHxp6NY9m0gU0Sm2+3GvwAS21vAGLMJ+BarbfldY0xxi1qqgH0iEo/1D8wTdURjBeB+EemP1aTVXBFWO3xr9W4BlgF/tg8qZgLXYbWXH62ZwBpgCJBp34bY73+5MWYH8AHwLxGJFZFgEZlsL/sscKOInGIfEE0VkSH2vBzgcrEOrI/HatNvT5ufuTGmEeubzWP2N55AEZkk9sF7rKaxYKx/mLrX3kU03HuWX2F9fS/H2ot/zUPrfR5r73QnsBr4qqMLGmOKsA4wPowVFGlYwX0kc7EOmP6nxfRHsfYkS+w62jxJ6SjruAcYj/XP8S2sbpnN/Rm4z+45clsrb3EZ1sHHXVjNEr8zxnzckdpamAn8yxizq9mtEOvzbGqaaTpguQEr9G+xt/Er4MdYB2v3Ax9z8NvK77EOlpZiHSh+5Qh1HOkz/wWwFlgO7MX6+YhdR1PT2kg69w9OdYAc+k1LKaW6nt0VdKYxZorTtfgr3XNXSnUrEYkAbgbmOF2LP9NwV0p1GxE5FyjGOtfBU82CqhXaLKOUUn5I99yVUsoPecUAQAkJCSYjI8PpMpRSyqcsX758jzGm1a7DXhHuGRkZLFu2zOkylFLKp4hIm2MDabOMUkr5IQ13pZTyQxruSinlh7yizb019fX15OfnU1NT43QpXSosLIzU1FSCg4OP/GKllOogrw33/Px8oqOjycjIQMQTAxd6H2MMJSUl5OfnM2BAqxc5UkqpTjlis4yIPCciu0Ukt9m0OBF5375c2Pv2UKNNF+193L5818oOXCqsTTU1NcTHx/ttsAOICPHx8X7/7UQp1f060ub+Atbl2Jq7A/jQGDMY+NB+DjAVa+S7wcBs4Al3ivPnYG/SE7ZRKdX9jtgsY4z5TOyLJjczHZhiP54LfALcbk//jz2k5zf2eNLJ9pCkSinlqPpGF1V1jVTXNVJV10BVXSM19Y1U1Vm36voG6hsMBoMx1hVYjAGXMdbVWOx7l8scmGfdN73+4HIuexr2fJfh0NfY6zp9WBLH9Y/1+LZ2ts09qSmwjTGF9sWFwbpsWPNLu+Xb0w4LdxGZjbV3T1paWifL6DqlpaW88sor3HzzzUe13DnnnMMrr7xCbKznPyyleprymno27q44EL5VdQ2HhvGBUG6k2g7r6vqD86zHDQeeN7i8aywtEegbE+ZV4d6W1toYWv1pGmPmYA/5mZWV5V0/caxw//e//31YuDc2NhIYGNjmcosXL+7q0pTyS8YYCkqrWb5tH8u27mPZtn2s31VGe3ksAhHBgYSHBBEREkhESCDhIYGEBwfSOyLYmh5sTwsJPPA4wn59WHDgIctFhAQRFCAEBAhirz9ArMcICEKAWM2pTfNFxLrn4PQAexot1tFyua7U2XAvampuEZFkYLc9PZ9m16HEugblTncKdModd9zBpk2byMzMJDg4mKioKJKTk8nJyWHNmjVccMEF7Nixg5qaGm699VZmz54NHBxKoaKigqlTp3LSSSfx1VdfkZKSwqJFiwgPD3d4y5TyDg2NLtYUlrFs6z6Wb9/H8q372FVmdS6IDAlkTFpvbjl1MKNSYogOCyIiJIjwkIBDAjs0KECPW7Whs+H+FtYlvR607xc1m/4zEfkvcAKw3xPt7ff9bzVrdpa5u5pDDO/Xi3vOG9Hm/AcffJDc3FxycnL45JNPOPfcc8nNzT3QZfG5554jLi6O6upqjj/+eC666CLi4+MPWUdeXh6vvvoqTz/9NJdeeinz58/n6quvbu3tlPJ7ZTX1ZG/bd2DPPGdHKdX1jQCkxIYzfkAc49J7My69N0P7RhMUqOdYuuOI4S4ir2IdPE0QkXysa0k+CLwuIjdgDbp/if3yxVhXRN+IdZHi67qgZkeMHz/+kL7ojz/+OAsXLgRgx44d5OXlHRbuAwYMIDMzE4Bx48axdevWbqtXKScZY9ixt5rl2/dae+bb9rG+qBxjIECsnavLju/PuPTeZGX0JjlGv9F6Wkd6y1zRxqzTWnmtAX7qblEttbeH3V0iIyMPPP7kk0/44IMP+Prrr4mIiGDKlCmt9lUPDQ098DgwMJDq6upuqVWp7lbf6GL1zjKWbd1r7Zlv20dxeS0AUaFBjEmLZerIZLIyepPZP5bIUK89f9Jv6E+4DdHR0ZSXl7c6b//+/fTu3ZuIiAjWrVvHN998083VKeWs/VX1ZG/fx7Jt1p75D/ml1NS7AKuJZeIx8WSl92ZcehxD+kYTGKDt4t1Nw70N8fHxTJo0iZEjRxIeHk5SUtKBeWeffTZPPvkko0ePZsiQIUyYMMHBSpXqWlV1DazZWcaqgv3WLX8/ebsrAAgMEEb068UV49PISrfazPvGhDlcsQIvuYZqVlaWaXmxjrVr1zJs2DCHKupePWlbewKXy7CrrIY+0aE+d1Cwuq6RNYVWgK8s2E9uwX427q440B0xISqUUSm9GJvWm3F2E0tEiO4jOkVElhtjslqbp5+KUh5SU9/I/Ox8nvl8C1v2VBIUIKT2DictPpKM+AjS4yNJj4sgIyGC1N4RhAW3fb5Ed2ge5KsKylhVUNpqkJ89MplRKTGMSokhqVeodj30ERruSrmptKqOF7/extyvt7Knoo7RqTHcNW04eytr2VpSxbaSSlZs20d5bcOBZUQguVcY6fGRZCREkBbX7B9AfITHDzhaQV7GqvxSVhWUkVuwn7zd5YcH+Yi+jEyJYXRqrAa5j9NwV6qTduyt4tkvtvD6sh1U1TUyZUgiN00+hgkD4w4LRWMM+6rq2VpSyfaSqkPul64uoqSy7pDXJ0SFkhEfQVp8BBl24Kfb3wBiI0LaraspyHML9rMyf38rQR7CqJQYzhqRxMiUGEalxtC3V5gGuZ/RcFfqKOUW7GfOZ5t5Z1UhApyf2Y/ZkwcytG+vNpcREeIiQ4iLDGFsWu/D5pfX1LOtpMq67a1k2x4r+L/eVMKC7IJDXtsrLIiMhMgDzTzp8RFU1TWyqqApyCtotJM8ISqEkRrkPZKGu1IdYIzh87w9zPlsM19s3ENUaBDXT8rgukkD6Bfr/gk40WHBjEyJYWRKzGHzauob2b7XDv6SSraWVLKtpIofdpSyeFXhYUF+xvAku2lFg7wn03BXqh31jS7eWVnIU59tZm1hGX2iQ7lj6lCuPCGNXmHdc2nEsOBAjk2K5tik6FbrK9hXTUhQAMkxGuTqIN/qp9WNmkaF7IzHHnuMqqoqD1ekulNlbQPPfrGFKQ9/wm2v5dDQ6OKhi0fz+e2n8H8/Oqbbgv1IggMDyEiIpF9suAa7OoSGexs03Hum3eU1PPzeOk78y4f88e01pPQO59lZWbx322QuzepPaJCz3ReV6ihtlmlD8yF/zzjjDPr06cPrr79ObW0tM2bM4L777qOyspJLL72U/Px8GhsbueuuuygqKmLnzp2ccsopJCQk8PHHHzu9KaoDNhVX8Mznm5m/vIB6l4uzR/Rl9uSBjGnl4KdSvsA3wv3dO2DXKs+us+8omPpgm7ObD/m7dOlS5s2bx3fffYcxhvPPP5/PPvuM4uJi+vXrxzvvvANYY87ExMTw6KOP8vHHH5OQkODZmpXHLdu6l6c+28wHa4sIDgzgkqxUbjx5IAMSIo+8sFJezDfC3WFLly5l6dKljBkzBoCKigry8vI4+eST+fWvf83tt9/OtGnTOPnkkx2uVHWEy2V4f20Rcz7bzPJt+4iNCOaWUwYxc2IGCVGhR16BUj7AN8K9nT3s7mCM4c477+Smm246bN7y5ctZvHgxd955J2eeeSZ33323AxWqjqipb2ThigKe/nwzm4srSe0dzr3nDefS4/vr+CjK7+hvdBuaD/l71llncdddd3HVVVcRFRVFQUEBwcHBNDQ0EBcXx9VXX01UVBQvvPDCIctqs4zzymvqWb2zjG82l/DSN9vZU1HLyJRePH7FGM4Z2dfnBvZSqqM03NvQfMjfqVOncuWVV3LiiScCEBUVxUsvvcTGjRv5zW9+Q0BAAMHBwTzxxBMAzJ49m6lTp5KcnKwHVLtR09C0K/OtoWlX5peyeU8lTQOfTj42kZsmD2TiMfHabVD5PR3y1wv0pG31lJr6RtbtKmdlfqkV5vmHjp+S1CuUUSmxjE61TrkflRKj7enK73TZkL8icivwY0CAp40xj4nIvfa0YvtlvzPGLHbnfVTPVtfgYkNRub1HboX5+l3lNNhJHh8ZwujUGM4a2ZfR9vgpSb30ghGqZ+t0uIvISKwQHw/UAUtE5B179t+NMY94oD7VwzQ0usjbXWFfLKKUVfn7WVtYTl2jdQm3mPBgRqfGMHvyQEanWnvmetq9UodzZ899GPCNMaYKQEQ+BWZ4pCqbMcbv/2i9oVnMKY0uw5Y9FazM33+gnXz1zv0HrsUZHRrEyJQYrpuUwajUGEanxNI/Tk+zV6oj3An3XOBPIhIPVAPnAMuAEuBnIjLTfv4rY8y+lguLyGxgNkBaWtphKw8LC6OkpIT4eP89+GWMoaSkhLCwntWEsLushgfeWcuHa4uorGsEICIkkJH9YrjqhHSrnTwlhoz4SAL0wspKdYpbB1RF5Abgp0AFsAYr5B8E9gAG+COQbIy5vr31tHZAtb6+nvz8fGpqajpdny8ICwsjNTWV4GDvGIiqKxljeH3ZDv70zlpqGlxcMi6VMWm9GZ0awzGJUQRqkCt1VLrsgKox5lngWftN/gzkG2OKmr3x08DbnVl3cHAwAwYMcKc85UW2lVRy54JVfLWphPED4njwwlEMTIxyuiyl/Ja7vWX6GGN2i0gacCFwoogkG2MK7ZfMwGq+UT1UQ6OL577cwqPvbyA4IIA/zRjJFcenaXOLUl3M3ZOY5ttt7vXAT40x+0TkRRHJxGqW2Qocfs6+6hHWFpZx+/yVrMzfz+nDknjggpH0jelZxxeUcoq7zTKHjZRljLnGnXUq31dT38g/P9rIk59uIjYimH9eOYZzRyX77YFxpbyRDj+gPOr7rXu5Y/5KNhVXcuHYFO46dzi9I0OcLkupHkfDXXlEeU09Dy1Zz4vfbCMlNpy514/nR8cmOl2WUj2Whrty20frivj9wlx2ldVw3aQMfn3mECJD9VdLKSfpX6DqtJKKWu5/ew2LcnZybFIU/7pqImP1snRKeQUNd3XUjDEsytnJff9bTUVtA7edPpibpwwiJEjHRlfKW2i4q6NSUFrN7xeu4pP1xWT2j+Whi0dzbFK002UppVrQcFcd4nIZXvxmGw8tWYfLwN3ThjNrYoYOGaCUl9JwV0e0cXc5t89fxfJt+zh5cAJ/njGK/nERTpellGqHhrtqU12Diyc/3cQ/P9pIRGggf7vkOC4cm6InIynlAzTcVatydpRyx/yVrNtVzrTRydxz3ggSo/UydUr5Cg13dYiqugb+tnQDz3+5hT7RYTw9M4szhic5XZZS6ihpuKsDvsjbw50LV7JjbzVXnZDG7VOH0ivM/8eZV8ofabgrAJ74ZBN/XbKOAQmR/Hf2BCYMjHe6JKWUGzTcFW8s28Ffl6xj2uhkHrnkOMKCA50uSSnlJg33Hu7jdbu5Y8EqThqUwKOXZupZpkr5Cf1L7sFWbN/HzS9nMyw5mievGafBrpQf0b/mHmpzcQXXv/A9idGhPH/teKJ0FEel/IqGew+0u6yGmc99R4AIc68fr/3XlfJDboW7iNwqIrkislpEbrOnxYnI+yKSZ9/rGLBepKymnlnPf8/eyjqev+54BiREOl2SUqoLdDrcRWQk8GNgPHAcME1EBgN3AB8aYwYDH9rPlReobWjk/15cTl5ROU9cPY7RqbFOl6SU6iLu7LkPA74xxlQZYxqAT4EZwHRgrv2aucAF7pWoPMHlMvzq9R/4alMJD108Wi+Bp5Sfcyfcc4HJIhIvIhHAOUB/IMkYUwhg3/dpbWERmS0iy0RkWXFxsRtlqCMxxvDHd9bw9spC7pw6lAvHpjpdklKqi3U63I0xa4G/Au8DS4AfgIajWH6OMSbLGJOVmKh7kV1pzmebef7LrVw/aQCzJw90uhylVDdw64CqMeZZY8xYY8xkYC+QBxSJSDKAfb/b/TJVZy3Izucv71pnn/7h3GE6XK9SPYS7vWX62PdpwIXAq8BbwCz7JbOARe68h+q8TzcU89t5K5l4TDx/u/Q4AvSqSUr1GO6euTJfROKBeuCnxph9IvIg8LqI3ABsBy5xt0h19Fbml/KTl5YzOCmap64ZR2iQjhejVE/iVrgbY05uZVoJcJo761Xu2bqnkuue/564yBDmXnc80Tpsr1I9jp6h6meKy2uZ+dx3GOA/14+nT68wp0tSSjlAw92PVNQ2cN0L31FcXsuzs7IYmBjldElKKYfoaFF+oq7BxU9eWs7awnKemZnFmDQd9UGpnkz33P2Ay2X47bwf+DxvDw9eOIpThrZ63phSqgfRcPcDDy5Zx5s5O/nNWUO4JKu/0+UopbyAhruPe+bzzcz5bDOzTkzn5inHOF2OUspLaLj7sEU5BTzwzlrOGdWXu88boWefKqUO0HD3UV/k7eHXb/zACQPiePTSTAL17FOlVDMa7j4ot2A/N724jGMSo5gzM4uwYD37VCl1KA13H7O9pIprn/+e2IgQXrhuPDHhevapUupw2s/dh+ypqGXmc9/S4HLx3+tPoG+Mnn2qlGqd7rn7iMraBm544Xt2ldXw7KzjGdQn2umSlFJeTMPdB9Q3urj55WxWFeznn1eMZVy6nn2qlGqfNst4OWMMt89fyacbinnwwlGcPjzJ6ZKUUj5A99y93EPvrWdBdgG/PONYLh+f5nQ5SikfoeHuxZ7/cgtPfLKJq05I45ZTBzldjlLKh2i4e6nNxRXc//YazhyexP3TR+rZp0qpo6Lh7qUWZBcgwAMXjNSzT5VSR83dC2T/QkRWi0iuiLwqImEi8oKIbBGRHPuW6aliewqXy7BwRQGTBiXolZSUUp3S6XAXkRTg50CWMWYkEAhcbs/+jTEm077leKDOHuX7rXspKK3morGpTpeilPJR7jbLBAHhIhIERAA73S9JLcguICIkkDNHaLdHpVTndDrcjTEFwCPAdqAQ2G+MWWrP/pOIrBSRv4tIaGvLi8hsEVkmIsuKi4s7W4bfqalvZPGqQs4e2ZeIED0NQSnVOe40y/QGpgMDgH5ApIhcDdwJDAWOB+KA21tb3hgzxxiTZYzJSkxM7GwZfueDtUWU1zZok4xSyi3uNMucDmwxxhQbY+qBBcBEY0yhsdQCzwPjPVFoT7Ewu4C+vcKYMDDe6VKUUj7MnXDfDkwQkQixOmGfBqwVkWQAe9oFQK77ZfYMeypq+WRDMdPH9NPuj0opt3S6UdcY862IzAOygQZgBTAHeFdEEgEBcoD/80ShPcH/fthJo8tw4RhtklFKucetI3bGmHuAe1pMPtWddfZkC1cUMKJfL4b01eF8lVLu0TNUvcTG3eWszN/PjDEpTpeilPIDGu5eYkF2AQEC52f2c7oUpZQf0HD3Ai6XYVHOTiYfm0ifaB1uQCnlPg13L/DtFmu4AW2SUUp5ioa7F1iQnU9UaBBnDu/rdClKKT+h4e6w6rpG3s3dxdSRfQkPCXS6HKWUn9Bwd9j7a4uoqG1gxlhtklFKeY6Gu8MWZOfTLyaMCQN0uAGllOdouDuouLyWz/P2MH1MCgE63IBSyoM03B301oHhBrRJRinlWRruDlq4Ip9RKTEMTtLhBpRSnqXh7pANReXkFpRp33alVJfQcHfIguwCAgNEhxtQSnUJvY6bAxpdhkU5Bfzo2EQSolq9CqGlrBBqSruvsLAY6KX/bJTyBxruDvhmcwmF+2v43TnD2n7Rd0/D4t8AptvqAmDIuXDSL6D/8d37vkopj9Jwd8CC7AKiQ4M4Y3jS4TONgY/+CJ//DY49G467vPsKK1oD3z8Nz74D6ZOskB90Ooh201TK12i4d7PqukaW5BYybXQ/woJbDDfQWA//uw1yXoKxs+DcRyGwGz+iETNg0q2w4kX46p/w8sWQNBIm3WbN685alOpOVXuh8AfYuQKqSuwdGgEJsG/248OmtZzebH5rr21tnf1PgITBHt8k/WvtZkvX7KKyrvHw4QbqKuH1WbDxfZhyJ/zodmf2mEOjYMJPIOsGyJ0HX/4DFtwIH90PE38OmVdBSET316WUp1SXHgzywhzrft/Wg/ODIwEDxmV9kzYu69Y0zdPOfdT7wl1EfgHciNUwvAq4DkgG/gvEYV1f9RpjTJ2bdfqN+dkFpMSGMz4j7uDEyj3wyqXWL9l5/4Bx1zpW3wFBIZB5JYy+HDYsgS/+Dot/DZ/8BU74CYy/EcJ7O12lUu2rKbOCvCnEd66AvZsPzo9Nh36Z1t9cvzGQfNyRf6+NORj6NAv/NqeZ1l/X9Nqw2C7Z9E6Hu4ikAD8HhhtjqkXkdeBy4Bzg78aY/4rIk8ANwBMeqdbH7S6r4Yu8Ym6eMujgcAN7t8BLF0FZAVz2Mgw9x9kiWwoIsGoaMhW2fw1fPAYfPwBfPmb9QUy4GWK0r77yArUVsGvlwRDfmQMleQfnx/S3gnzM1ZCcaYV5RFzb62vLgSYW7+5J7m6zTBAQLiL1QARQiHWB7Cvt+XOBe9FwB6zhBlyGg00yO3Pg5UvAVQ8z34K0E5wtsD0ikD7Ruu3KtZprvnkCvn0KRl8Gk34OiUOcrlL1FHWVsGuV9TfUFOZ7NnCgd1mvFCvAR19mhXi/TIhMcLTk7tbpcDfGFIjII8B2oBpYCiwHSo0xDfbL8oFWd+tEZDYwGyAtLa2zZfiUBdkFHJcawzGJUbDpI3jtGusr4NXvQOKxTpfXcX1HwkVPw6l/gK//CdkvWgeBh06zDr5qN0rfZ4x1jkXpdti3zbov3Q6l22B/AQgQFGbfQlu5D29jemv37cwLDIaGGmuHoinEC3OgeN3B9u+oJOg3FkZeaDetZEJ0Kz3Rehh3mmV6A9OBAUAp8AYwtZWXttpR2xgzB5gDkJWV1c2dubvful1lrCks497zhsPK1+HNn0DiULhqHvRKdrq8zumdDuc8bB38/fYp+G4OrHsb0k+yu1Gept0ovVlNmRXWTcHdMsRryw59fUi09ZnHpFq9PBpqoKEWqvdZ9/XV1qVQOhQAABNlSURBVH3T9IYa61upW5p+f+yIiEy0AnzYeQeD3Ff/frqYO80ypwNbjDHFACKyAJgIxIpIkL33ngrsdL9M37cwu4CgAOGSujdhwb2QcTJc/rJ1Vqivi0yAU39vdaPMnmt3o7wIkkbBSbfB8Au0G6UTaisOBnXz0G4K8ZZnPwdHWuEdmwbpJ1oHG2PTrFvvdOvA39H+s3Y1Hh74h9y38g/hwL39WAKh7ygrzHv10x2GDnLnL247MEFEIrCaZU4DlgEfAxdj9ZiZBSxyt0hf1+gyLFqxg38nzCPy0/lWn/EZT1lfPf1JaBSc+FM4/sew6g3roOv8G+DD+2HiLdaBrOBwp6vsHk09IlyNYBqte1dDi2kNzR67Wp/maji4/IH1NLaY1mD10265F16999CagsIPBnX/8XZwpx+8j4jzfHAGBFpdZ7X7bLcTYzrfIiIi9wGXAQ3ACqxukSkc7Aq5ArjaGFPb3nqysrLMsmXLOl2Ht/tiXT57X76R8wO/troRnvVnqxeKv3O5YMO7VjfK/O8hIgEm/B8c74fdKI2xDuitewfWL4aC5V3TJ7o9gaEH97SbQvxAgKdb37B0r9eviMhyY0xWq/PcCXdP8etwryljw+PTObYqm/pT7yX45Nt63h+YMbDtKyvkN74PIVFWN8qs6yFuoO/+PFyNsOM7WP8OrFsMezdZ0/uNgQGTrWaOgACrWSEg0L4Psh8HWPcBQc3mBzSbH3jo/SGPgw4u3zQtLNY6sNgTdhrUAe2FuzaEdqXyXbhevIgBlWt5Pe33XDr5F05X5AwRyJhk3XatsrtR/tvqaROdbI1jkzHJOhCbMNi7w76+GjZ9bAX6+iVQtQcCgmHAyXDizXDsVO33r7yChntX2ZMHL16Iq6KY6+t/wy2n3uh0Rd6h7yi46Bk47W7IWwpbv4Stn1tDHQBE9rH60mecZIV+4lDn90YrS6yzdNe9Y3VhbaiG0BgYfIZ1gteg0/3jwLjyKxruXWHH99ZwAgGB3JfwMFvKUshK97M2ZnfFpllt78ffaDXblGyCbV9YYb/tS1jzpvW68LhDwz5pZPeEfckmq+183WLY8Y3Vft4rxTooPPRcq5agkK6vQ6lO0nD3tPVL4I1rIbove2b8l5ef2MTPTkk5ONyAOpwIJAyybuOutcJ+31Yr5Ld+aYX+uret14bFQNpEuxlnEvQd7Zluli6XdYLMuretUC9eZ01PGgWTfwNDzrHGHfHmJiOlmtFw96Tlc+Ht26wQuPINFmSX2cMNpDpdmW8RgbgB1m3M1da00h122H9h3W9415oeEg1pEw622ffLtM5q7IiGWtjymd3D5V2o2GUdoEyfaP2TGXKO1eNEKR+k4e4JxsBnD8PHf7LaXy+ZC6FRLMheS2b/WAYkRDpdoe+L7Q+xlx+8eElZ4aFh/8H71vTgSKsPd8ZJ1q3f2EObT6r3Qd77VqBv/ADqKqzeO4NOs65CNfiMzg0mpZSX0XB3l6sR3vkVLH8ejrsCzv9/EBjMmp1lrNtVzh+nj3C6Qv/UKxlGXWzdACp2N2vG+dK6mhVYJ+70P94K+Z3ZVpdMV4PVbXDUxVagD5gMwWHObYtSXUDD3R311TDvBqtb3Em/tHqA2G2yC1fkExwoTButF5zuFlF9rDN/R8ywnleWwPavDrbZf/kPa9TKiT+3Doj2G+t8LxylupCGe2dV7YVXL7dOYpn6MJww+8CshkYXb+bsZMqQPvSO1B4VjoiMtwaXGnae9byhTnu3qB5Fw70zSndYF9jYtwUueQFGXHDI7C83lVBcXstFLS+lp5yjwa56GA33o1W02gr2uiq4ZqF10K6Fhdn5xIQHc8rQPg4UqJRS3n6dKG+z5XN4zh6y/vp3Ww32itoG3ltdxLmjkwkNCuzmApVSyqLh3hHGwFf/D/4zHaL7wg3vQ1LrvWCW5O6iur6RC8dok4xSyjnaLHMk1aWw6KfWmYvDzofp/2x3HJGFK/JJi4tgnA43oJRykIZ7e3bmwBuzYH8+nPUXmPCTdk8/L9xfzVebSvj5qYMRPU1dKeUgDffWGAPLX4B3b7cucHDtYkg74YiLLcrZiTEwQ5tklFIO03Bvqa4S3v4lrPwvHHMqXPi0FfBHYIxhQXY+49J7k6HDDSilHKYHVJsr3gBPnwYrX4Mpv4Or5nUo2AFW7yxjQ1GF7rUrpbxCp/fcRWQI8FqzSQOBu4FY4MdAsT39d8aYxZ2usLusmgf/u9W6aPU1C6y99qOwcEUBIYEBTBud3EUFKqVUx3U63I0x64FMABEJBAqAhcB1wN+NMY94pMKu1lAL7/0evn8a+p8AFz9/1JdJa2h0sShnJ6cMTSQ2Qs+EVEo5z1Nt7qcBm4wx23yql8i+bdaFNXZmw4k/g9Pv7fhY4M18vnEPeypquVDHbVdKeQlPtblfDrza7PnPRGSliDwnIq12+BaR2SKyTESWFRcXt/aSrrXhPXhqMpRshMtegrP+1KlgB1iYXUBsRDCnDNHhBpRS3sHtcBeREOB84A170hPAMVhNNoXA31pbzhgzxxiTZYzJSkxMdLeMjmtsgA/us65xGtsfbvr04MiBnVBeU8/SNbuYNjqZkCA9Pq2U8g6eaJaZCmQbY4oAmu4BRORp4G0PvIdnlBfB/Btg6+cwdhZM/SsEh7u1yndzd1FT79ImGaWUV/FEuF9BsyYZEUk2xhTaT2cAuR54D/dt/QLmXQ81ZXDBk5B5hUdWuzC7gAEJkYzpH+uR9SmllCe4Fe4iEgGcAdzUbPJDIpIJGGBri3ndz+WCLx+zLrsWN9AapreNQb+OVkFpNd9sKeG2047V4QaUUl7FrXA3xlQB8S2mXeNWRZ5UtRfe/AlsWAIjLoTzH4fQaI+t/s0VBTrcgFLKK/nv8AMF2fD6LCgvhHMegeNvbHfQr6NljGHhigKOz+hNWnyEx9arlFKe4H/dO4yB75+B584CDFz/Hoz/sUeDHSC3oIyNuyuYMUYPpCqlvI9/7bnXVlhDCOTOg8FnwoynICKuS95qwYp8QgIDOHeUDjeglPI+/hPuu9fC6zOtk5JOvQtO+iUEdM0Xk/pGF2/l7OT04X2IiejciU9KKdWV/CPcf3gN3r4NQqJg5iIYMLlL3+7zvGJKKuu0SUYp5bV8O9zra2DJHbD8eUifBBc/Z13jtIstyC6gd0QwPzq2G8+sVUqpo+DbB1Q/e8gK9km3wcy3uiXYy2rqWbqmiPOO66fDDSilvJZv77lPug3SJ8Kg07vtLd9dVUhdgw43oJTybr696xnWq1uDHawmmYEJkRyXGtOt76uUUkfDt8O9m+Xvq+LbLXuZMSZFhxtQSnk1Dfej8OaKAgAu0OEGlFJeTsO9gyprG3j52+2cMCCO/nE63IBSyrtpuHfQ4x/lUbi/ht+ePdTpUpRS6og03DtgQ1E5z36+hcuy+jMuvdWrBiqllFfRcD8CYwx/eDOXqLAgbp+qe+1KKd+g4X4EC1cU8N2Wvdxx9lDiIkOcLkcppTpEw70d+6vq+fPitYxJi+XSrP5Ol6OUUh3m22eodrFHlq5nb2Udc68fT0CA9mtXSvmOTu+5i8gQEclpdisTkdtEJE5E3heRPPveJ49Arswv5aVvtzFrYgYj+unZqEop39LpcDfGrDfGZBpjMoFxQBWwELgD+NAYMxj40H7uUxpdhrvezCUxKpRfnnGs0+UopdRR81Sb+2nAJmPMNmA6MNeePhe4wEPv0W1e/W47P+Tv5w/ThhMdphfjUEr5Hk+F++XAq/bjJGNMIYB938dD79Et9lTU8tCSdUwaFM95o/USekop3+R2uItICHA+8MZRLjdbRJaJyLLi4mJ3y/CYvyxeR3V9I/dPH6mDgymlfJYn9tynAtnGmCL7eZGIJAPY97tbW8gYM8cYk2WMyUpM9I4rGn27uYT52fnMnjyQYxKjnC5HKaU6zRPhfgUHm2QA3gJm2Y9nAYs88B5drr7RxV2LckmJDednpwx2uhyllHKLW+EuIhHAGcCCZpMfBM4QkTx73oPuvEd3ef7LLWwoquC+80cQHhLodDlKKeUWt05iMsZUAfEtppVg9Z7xGTtLq3nsgzxOH5bE6cOTnC5HKaXcpsMPAH98ew0uY7jnvOFOl6KUUh7R48P94/W7eTd3F7ecOlgvwqGU8hs9Otxr6hu5Z9FqjkmM5McnD3S6HKWU8pgePXDYE59sYvveKl658QRCgnr0/zmllJ/psYm2dU8lT3y6iemZ/Zg4KMHpcpRSyqN6ZLgbY7j7rdWEBgbw+3OGOV2OUkp5XI8M9yW5u/hsQzG/PPNY+vQKc7ocpZTyuB4X7hW1Ddz3vzUMT+7FNRPSnS5HKaW6RI87oPr4h3nsKqvh31ePJSiwx/1vU0r1ED0q3dbvKufZL7Zwxfj+jE3zyQtEKaVUh/SYcDfG8Ic3V9ErLIjfnjXU6XKUUqpL9Zhwn59dwPdb93Hn1GH0jgxxuhyllOpSPSLcS6vq+MvitYxL783F41KdLkcppbpcjwj3h99bT2l1PQ9cMJKAAL26klLK//l9uOfsKOWV77Zz7cQMhiX3crocpZTqFn4d7o0u6yBqn+hQbjtdr66klOo5/DrcX/l2G7kFZfzh3OFEhwU7XY5SSnUbvw334vJaHnpvPScNSmDa6GSny1FKqW7l7jVUY0VknoisE5G1InKiiNwrIgUikmPfzvFUsUfjL4vXUlvv4v7pIxDRg6hKqZ7F3eEH/gEsMcZcLCIhQARwFvB3Y8wjblfXSd9sLmHBigJuOXUQAxOjnCpDKaUc0+lwF5FewGTgWgBjTB1Q5/Recl2Di7vezKV/XDg/PWWQo7UopZRT3GmWGQgUA8+LyAoReUZEIu15PxORlSLynIh06yAuz325hbzdFdx73gjCggO7862VUspruBPuQcBY4AljzBigErgDeAI4BsgECoG/tbawiMwWkWUisqy4uNiNMg4qKK3mHx/kcebwJE4bluSRdSqllC9yJ9zzgXxjzLf283nAWGNMkTGm0RjjAp4Gxre2sDFmjjEmyxiTlZiY6EYZB93/v9UA3H3ecI+sTymlfFWnw90YswvYISJD7EmnAWtEpHm/wxlArhv1ddhH64p4b3URPz9tMKm9I7rjLZVSymu521vmFuBlu6fMZuA64HERyQQMsBW4yc33OKKa+kbueWs1g/pEccNJA7r67ZRSyuu5Fe7GmBwgq8Xka9xZZ2f8++ON7Nhbzas/nkBIkN+el6WUUh3m80m4ZU8lT366mQsy+3HiMfFOl6OUUl7Bp8PdGMPdi3IJDQrgd+cOc7ocpZTyGj4d7otX7eLzvD38+qwh9IkOc7ocpZTyGj4d7pGhgZw5PImrJ6Q7XYpSSnkVd3vLOGrKkD5MGdLH6TKUUsrr+PSeu1JKqdZpuCullB/ScFdKKT+k4a6UUn5Iw10ppfyQhrtSSvkhDXellPJDGu5KKeWHxBjjdA2ISDGwrZOLJwB7PFiOt/Hn7dNt813+vH2+tG3pxphWr3bkFeHuDhFZZoxpOeyw3/Dn7dNt813+vH3+sm3aLKOUUn5Iw10ppfyQP4T7HKcL6GL+vH26bb7Ln7fPL7bN59vclVJKHc4f9tyVUkq1oOGulFJ+yKfDXUTOFpH1IrJRRO5wuh5PEZH+IvKxiKwVkdUicqvTNXmaiASKyAoRedvpWjxNRGJFZJ6IrLM/wxOdrslTROQX9u9kroi8KiI+fX1LEXlORHaLSG6zaXEi8r6I5Nn3vZ2ssbN8NtxFJBD4FzAVGA5cISLDna3KYxqAXxljhgETgJ/60bY1uRVY63QRXeQfwBJjzFDgOPxkO0UkBfg5kGWMGQkEApc7W5XbXgDObjHtDuBDY8xg4EP7uc/x2XAHxgMbjTGbjTF1wH+B6Q7X5BHGmEJjTLb9uBwrHFKcrcpzRCQVOBd4xulaPE1EegGTgWcBjDF1xphSZ6vyqCAgXESCgAhgp8P1uMUY8xmwt8Xk6cBc+/Fc4IJuLcpDfDncU4AdzZ7n40cB2EREMoAxwLfOVuJRjwG/BVxOF9IFBgLFwPN2s9MzIhLpdFGeYIwpAB4BtgOFwH5jzFJnq+oSScaYQrB2tACfvFCzL4e7tDLNr/p1ikgUMB+4zRhT5nQ9niAi04DdxpjlTtfSRYKAscATxpgxQCU++rW+JbvteTowAOgHRIrI1c5Wpdriy+GeD/Rv9jwVH/+K2JyIBGMF+8vGmAVO1+NBk4DzRWQrVlPaqSLykrMleVQ+kG+MafqmNQ8r7P3B6cAWY0yxMaYeWABMdLimrlAkIskA9v1uh+vpFF8O9++BwSIyQERCsA7svOVwTR4hIoLVZrvWGPOo0/V4kjHmTmNMqjEmA+sz+8gY4zd7f8aYXcAOERliTzoNWONgSZ60HZggIhH27+hp+MnB4hbeAmbZj2cBixyspdOCnC6gs4wxDSLyM+A9rKP2zxljVjtclqdMAq4BVolIjj3td8aYxQ7WpDruFuBle6djM3Cdw/V4hDHmWxGZB2Rj9ehagY+fqi8irwJTgAQRyQfuAR4EXheRG7D+oV3iXIWdp8MPKKWUH/LlZhmllFJt0HBXSik/pOGulFJ+SMNdKaX8kIa7Ukr5IQ13pZTyQxruSinlh/4/JgW8Vvhzm+gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optionally plot your losses\n",
    "print(accuracies)\n",
    "pd.DataFrame(accuracies).plot(title='Train and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.8 Explore the model [2 points]</b>\n",
    "    \n",
    "Congrats on training your model! Hopefully you see meaningful results on a macroscopic scale (in terms of training/test loss). Now, let's explore our model from a more _microscopic_ perspective. **Please display three sentences** in the test set that (a) were classified correctly by your model and (b) were classified incorrectly **(for a grand total of 6 sentences)**. Do you notice anything interesting about these sentences that could help explain why the model classified them correctly or incorrectly? (Note: There is no particular, exact answer we are looking for here; rather, we are just looking to see if you say something reasonable, justifying, and plausible.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 12]\n",
      "These are correct sentences: \n",
      "1. movie film history every way one care anyone think movie transcend criticism every flaw movie easily overcome many amaze thing movie go extremely beautiful movie doubt many u see anything like see time care count still become <UNK> every time feel hard describe one age, WITH TARGET SENTIMENT 1.0 and PREDICTED SENTIMENT 1.0\n",
      "2. despite age film <UNK> <UNK> charm attraction fine survive example early british cinema underlie air <UNK> <UNK> <UNK> humour place serve demonstrate assure direction production value involve many <UNK> type film disjoint <UNK> one standard act help great deal various <UNK> character come across interest believable little gem well worth anyone attention spite one jar note film surprisingly escape <UNK> attention, WITH TARGET SENTIMENT 1.0 and PREDICTED SENTIMENT 1.0\n",
      "3. enjoy movie unlike like pump <UNK> trash pas action movie play god simple realistic character believable action top enough twist turn keep interest end well direct well act good story, WITH TARGET SENTIMENT 1.0 and PREDICTED SENTIMENT 1.0\n",
      "\n",
      "\n",
      "These are incorrect sentences: \n",
      "1. want say disappoint see movie expect <UNK> story <UNK> great special fx etc film find absolute disaster <UNK> boat animal similar story want visual bible version <UNK> go watch movie, WITH TARGET SENTIMENT 0.0 and PREDICTED SENTIMENT 1.0\n",
      "2. course <UNK> already exactly ideal name dancer think michael really push irony <UNK> new title foot flame one really ca resist recommend <UNK> foot <UNK> retire clearly <UNK> <UNK> might add much like cheer london crowd per review <UNK> last live performance hint may last live performance <UNK> cheer <UNK> london crowd perry <UNK> movie guide, WITH TARGET SENTIMENT 0.0 and PREDICTED SENTIMENT 1.0\n",
      "3. okay know like movie pat <UNK> <UNK> interpretation japanese stereotype jay leno annoy yell laugh throughout long take account best movie world good <UNK> favorite part <UNK> talk bos tokyo drink close second, WITH TARGET SENTIMENT 1.0 and PREDICTED SENTIMENT 0.0\n",
      "abc\n"
     ]
    }
   ],
   "source": [
    "# TODO: explore your trained model!\n",
    "correct_sentences = []\n",
    "incorrect_sentences = []\n",
    "vocab = test_dl.dataset.vocab\n",
    "index_to_word = {v: k for k, v in vocab.items()}\n",
    "\n",
    "test_batch = next(iter(test_dl))\n",
    "while len(correct_sentences)<3 and len(incorrect_sentences) < 3:\n",
    "    test_word_seq, test_targets = test_batch\n",
    "    test_logit_output = torch.squeeze(final_model(test_word_seq), 0)\n",
    "    test_preds = torch.round(torch.sigmoid(test_logit_output))\n",
    "    for i, (pred, target) in enumerate(zip(test_preds, test_targets)):\n",
    "        if pred.item() == target.item():\n",
    "            if len(correct_sentences) < 3:\n",
    "                correct_sentences.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            if len(incorrect_sentences) < 3:\n",
    "                incorrect_sentences.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        if len(correct_sentences) == len(incorrect_sentences) and len(correct_sentences) == 3:\n",
    "            break\n",
    "    \n",
    "print(correct_sentences)\n",
    "print(incorrect_sentences)\n",
    "\n",
    "print(\"These are correct sentences: \")\n",
    "for i, idx in enumerate(correct_sentences):\n",
    "    correct_tokens =  test_word_seq[i]\n",
    "    sentence_words = [index_to_word[idx_tok.item()] for idx_tok in correct_tokens if idx_tok > 1]\n",
    "    word = \" \".join(sentence_words)\n",
    "    print(f\"{i + 1}. {word}, WITH TARGET SENTIMENT {test_targets[idx].item()} and PREDICTED SENTIMENT {test_preds[idx].item()}\")\n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"These are incorrect sentences: \")\n",
    "for i, idx in enumerate(incorrect_sentences):\n",
    "    incorrect_tokens =  test_word_seq[idx]\n",
    "    sentence_words = [index_to_word[idx_tok.item()] for idx_tok in incorrect_tokens if idx_tok > 1]\n",
    "    word = \" \".join(sentence_words)\n",
    "    print(f\"{i + 1}. {word}, WITH TARGET SENTIMENT {test_targets[idx].item()} and PREDICTED SENTIMENT {test_preds[idx].item()}\")\n",
    "    \n",
    "\n",
    "print(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of incorrect and correct sentences above, we can see that for the correctly predicted reviews, these revies have a lot of strong sentiment words (e.g. well, good, beautiful). And in general, when we look at the rough ideas these reviews try to convey they are either strongly positive or strongly negative, but there is no mild intention. On the contrary, on the incorrectly predicted reviews, we see that the reviews do have some strong words (either positive or negative) but there is also some mention of a positive aspect of the movie or some reviews are very neutral. Thus we see that without these strong sentiment words the model is having a hard time deciding what category they belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"header_yellow\"> \n",
    "    \n",
    "# Machine Translation \n",
    "    \n",
    "</div>\n",
    "</br>\n",
    "\n",
    "Now that we've warmed up by implementing a sentiment analysis model, we're reading to try a new task: machine translation. Fortunately, we can re-use some of your work from the previous part! We now want to add a Decoder component to your architecture to perform sequence-to-sequence translation. \n",
    "\n",
    "Why are we doing machine translation? As we mentioned at the beginning of this notebook, your task is to help save the day by determining which language the Dark Web hackers are speaking. That is, we've obtained some text from them which seems non-sensical. However, the investigators currently suspect it's either Danish, English, German, Finnish, or Spanish.\n",
    "\n",
    "Your first task is to assume it's English and to see how well you can translate from a bunch of their \"noisy\" data to English (we were fortunate to have a parallel corpus that includes the exact English equivalent of their noisy data).\n",
    "\n",
    "The investigation includes some amazing linguists who were able to also provide parallel corpora for all other languages mentioned above. So, your second task is to consider each of these languages as the true \"source\" language, and aim to translate each to the \"noisy\" target (aka mystery language) that the hackers have been communicating with.\n",
    "\n",
    "Best of luck!\n",
    "\n",
    "Pictured below is our only footage of the suspects:\n",
    "\n",
    "<img src=\"images/hackers1.png\" width=\"400\"><img src=\"images/hackers2.png\" width=\"400\"> (Fun Fact: movie star Angelina Jolie was in this movie, Hackers (1995))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Like before, we have provided pre-tokenized data for you to use. The data\n",
    "files consist of a train set `mt_train_sentences.pkl`, a validation set `mt_val_sentences.pkl`, and a test set `mt_test_sentences.pkl`, \n",
    "with corresponding lists of examples from all six languages:\n",
    "\n",
    "- Danish\n",
    "- English\n",
    "- German\n",
    "- Finnish\n",
    "- Spanish\n",
    "- Mystery langauge\n",
    "\n",
    "\n",
    "The file is formatted as:\n",
    "\n",
    "```\n",
    "{\n",
    "    'danish': [\n",
    "        [token token token ...],\n",
    "        [token token token ...],\n",
    "        ...\n",
    "    ]\n",
    "    'english': [\n",
    "        [token token token ...],\n",
    "        [token token token ...],\n",
    "        ...\n",
    "    ],\n",
    "    'mystery': [\n",
    "        [token token token ...],\n",
    "        [token token token ...],\n",
    "        ...\n",
    "    ],\n",
    "    # etc\n",
    "}\n",
    "```\n",
    "\n",
    "The key indicates the source language, and the $n$-th sentence (`[token token token ...]`) in each list are parallel translations in one of the six languages.\n",
    "\n",
    "Again, in short, your tasks are to:\n",
    "\n",
    "**(a)** train your model on the mystery -> English corpus;\n",
    "\n",
    "**(b)** train your model on each of the five pairings:\n",
    "-  Danish -> Mystery\n",
    "-  English -> Mystery\n",
    "-  German -> Mystery\n",
    "-  Finnish -> Mystery\n",
    "-  Spanish -> Mystery\n",
    "\n",
    "**Note:** these pairings are the reverse of what you did in part **a**. This is because it's natural to view the Mystery language as being the denoised version of the true, \"source\" language. So, we wish to model the mapping from the original source to this denoised version.\n",
    "\n",
    "**(c)** use the results to figure out the identity of the original mystery language you've been given.\n",
    "\n",
    "**Note:** we've randomly assigned mystery languages to each student, so your\n",
    "friend's language will not match up with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.9 Process translation data [2 points]</b>\n",
    "    \n",
    "In the cell below, we provide pre-processing code to load in each dataset and build in its dataloader. \n",
    "Almost everything is given to you *except* the collate function, which you will\n",
    "have to implement in the same style as the previous part, but now adapted for\n",
    "seq2seq translation.\n",
    "\n",
    "Please spend some time reading through the code and playing around with the objects to make sure you understand them.  For example, we recommend that you explore a few batches in each dataloader to understand what will be fed to the model.  Recall that you can generate a batch from any dataloader `dl` with `next(iter(dl))`. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mt_train_sentences.pkl\", \"rb\") as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "with open(\"data/mt_val_sentences.pkl\", \"rb\") as f:\n",
    "    val_dict = pickle.load(f)\n",
    "\n",
    "with open(\"data/mt_test_sentences.pkl\", \"rb\") as f:\n",
    "    test_dict = pickle.load(f)\n",
    "\n",
    "class TranslationDataset(Dataset):   \n",
    "    def __init__(self, source: List[List[str]], target: List[List[str]], min_freq=3, source_vocab=None, target_vocab=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if source_vocab is None and target_vocab is None:\n",
    "            self.source_vocab, self.source_vocab_size = generate_vocab(get_word_counts(source), min_freq)\n",
    "            self.target_vocab, self.target_vocab_size = generate_vocab(get_word_counts(target), min_freq)\n",
    "        else:\n",
    "            self.source_vocab = source_vocab\n",
    "            self.source_vocab_size = len(source_vocab)\n",
    "\n",
    "            self.target_vocab = target_vocab\n",
    "            self.target_vocab_size = len(target_vocab)\n",
    "\n",
    "        self.source, self.target = self._get_idx_dataset(source, target, self.source_vocab, self.target_vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.source[idx]), torch.tensor(self.target[idx])\n",
    "\n",
    "    def _get_idx_dataset(self, source: List[List[str]], target: List[List[str]], source_vocab: Dict[str, int], target_vocab: Dict[str, int]):\n",
    "        source_toks = []\n",
    "        target_toks = []\n",
    "\n",
    "        for src, tar in zip(source, target):\n",
    "            source_toks.append([source_vocab[token] if token in source_vocab else source_vocab[\"<UNK>\"] for token in src] + [source_vocab[\"<EOS>\"]])\n",
    "            target_toks.append([target_vocab[\"<EOS>\"]] + [target_vocab[token] if token in target_vocab else target_vocab[\"<UNK>\"] for token in tar] + [target_vocab[\"<EOS>\"]])\n",
    "        \n",
    "        return source_toks, target_toks\n",
    "\n",
    "train_ds = TranslationDataset(train_dict[\"mystery\"], train_dict[\"english\"])\n",
    "test_ds = TranslationDataset(test_dict[\"mystery\"], test_dict[\"english\"], source_vocab=train_ds.source_vocab, target_vocab=train_ds.target_vocab)\n",
    "val_ds = TranslationDataset(val_dict[\"mystery\"], val_dict[\"english\"], source_vocab=train_ds.source_vocab, target_vocab=train_ds.target_vocab)\n",
    "\n",
    "# TODO: implement this padding function\n",
    "# ASK IF BASICALLY WE NEED TO PAD BOTH TENSORS in batch[0] to be of the same size or do we need to patch all \n",
    "# tensors in batch[0] (for all 32 entries) \n",
    "def pad_collate(batch: List[Tuple[torch.tensor, torch.tensor]]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "    batch_source_lang = [item[0] for item in batch]\n",
    "    batch_target_lang = [item[1] for item in batch]\n",
    "    padded_source_lang = pad_sequence(batch_source_lang, batch_first=True, padding_value=PADDING_IDX)\n",
    "    padded_target_lang = pad_sequence(batch_target_lang, batch_first=True, padding_value=PADDING_IDX)\n",
    "    return (padded_source_lang, padded_target_lang)\n",
    "    \n",
    "train_dl = DataLoader(train_ds, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl = DataLoader(test_ds, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl = DataLoader(val_ds, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   4,  343,    7,    6, 1806,   33,   32,  230,  631, 1092,    2,    2,\n",
      "          117,    2,    2, 1037,   21,    2, 1189,    1,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  45,  111,    9,   10,    2,   64,   65,   29,   25,  189,    2,  144,\n",
      "          267,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  11,    8,   58,    2,    9,   10,  134,  135,  136,  249,    1,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  11,    8,    2,  144,   20,   55,   12,    2,   29, 1324, 1325,  115,\n",
      "          732,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,  174,   30,   18,   85,    2,    2,  276,    1,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  25,    2,    2,    2,   74,   75,   46,  175,   29,  176, 1240, 1241,\n",
      "          727,   20,   98,    2,    2,    1,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  56,   59,  125,   25,   63,   14,   19,  967,    2,    2,    2,  586,\n",
      "            2,   20, 1786, 1787,    1,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  11,    8,   21,    2,  137,  138,   67,    1,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,   55,   12,   42,   24,    3, 1406,   46,   20,   42,   24, 1017,\n",
      "           20,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  51,   52,   53,  737,    9,   10,  134,  135,  136,   12,  132,  131,\n",
      "           62,  638,  639,   37, 1150,   54,    1,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  20,  558,   22,   17,   44,    4,  318,   17,   70,  319,   87,   84,\n",
      "            9,   10,  254,   26,   15,   16,  692,    1,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,   13,   58,  388,    2,    9,   10,   12,  132,  131,    1,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,    2, 1464,   56,   15,   16,    5,    3,  630,  508,  607,\n",
      "          608,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,    8,   43,    6,  142,   12,  121,    1,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  40,   41,  353,  354,  355, 1397, 1398,   55,   12,    4,  377,  303,\n",
      "           21,  149,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  25,  182,   60,   61,  180,  181,  122,   23,   25,   21,   93,    2,\n",
      "         1257,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,  721,   79,  722,  161,  162,   23,    2,  725,    2,   18,    2,\n",
      "         1107,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 245,   59,   24,   12,   68,    3,    2,    9,   10,    2, 1320, 1011,\n",
      "           12,   68, 1314,   22,   24,   26,   70,   15,   16, 1759,    1,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,   13,    6,  142,   12,   23,  233,  809,    2,    2,   14,\n",
      "           19,    2,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,    8,   45,   43,  154,  220,   72,   73,  449,    2,   18,    2,\n",
      "         1257, 1043,  692,  193,  194,   64,   65,   29,    1,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 109, 1038, 1039, 1040,    7,    6,    2,    3,   90,  614,   15,   16,\n",
      "           21,    2,   59,    2,    2,    1,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,   13,  113,   17,  741,  742,  280,   12,   68,    2,    1,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,   13,   60,   61,   76,   23,   25,   23, 1027,    2,   45,\n",
      "           18,   35,   36,   34,    2,    9,   10,   12,  132,  131,  267,   59,\n",
      "           17,    1],\n",
      "        [  11,  273,   15,   16,   14,   19, 1399,    2,   77,  376,    2,  472,\n",
      "          656,   71,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  25,   59,  125,   87,   84,   45,   63,  253,    9,   10,   47,    2,\n",
      "            1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   5,    3,   13,   45,   27,   28,    2,    2,    2,    2,  989,    1,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,    8,   15,   16,   56,   63,   21, 1049,    1,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,   55,   12,    7,    6,    2,    2,   69,  787,  679,   21,  553,\n",
      "            7,    6,    2,   21,    2,    1,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,  535,  536,   48,   14,   19, 1637,    1,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,  174,   30,  105,  298,   18,    9,   10,    2,    2,  707,    1,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   4,  412,  413,   21,  880,    6,  112,   11,    2,  364,  365,   62,\n",
      "           55,   12,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [  86,   26,  128,   15,   16,  192,    2,    2,    1,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]])\n",
      "tensor([[   1,    4,    3,    2, 1188,    8,  215,   88,    2,   20,  948,    2,\n",
      "            2,    1],\n",
      "        [   1,    5,    6,   29,   10,   15,    3,   37,    8,   33,  978,    1,\n",
      "            0,    0],\n",
      "        [   1,   18,    3,   14,    2,  122,    9,    7,   46,  147,    1,    0,\n",
      "            0,    0],\n",
      "        [   1,   15,    3,    2,   17,   36,   90,  575,   21,  586,  148,    1,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   11,   14, 1126,   89,    1,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,   15,    3,    2,   16,  603,   17,    2,  446,    1,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   28,   27,    9,   14,  430,    2,    2,    1,    0,\n",
      "            0,    0],\n",
      "        [   1,   15,    3,  485,    8,  457,    1,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,  393,   14,  191,  151,   17,   44,  443,   17,  634,\n",
      "          151,    1],\n",
      "        [   1,    5,    6,  146,  306,   22,    7,   46,    2,  237,  733,    1,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,    2,   87,    2,   45,    7,  103,   19,   13,   27,\n",
      "            1,    0],\n",
      "        [   1,    5,    6,   14,  577,    2,    9,    7,   65,    1,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    5,    6,   13,    2,    2,   27,    5,    6,  246,    2,   14,\n",
      "          226,    1],\n",
      "        [   1,    4,    3,   70,   21,   12,    1,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,    2,    9,  102,  148,  144,    1,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    5,    6,   55,   16,    7,    2,    1,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   35,  177,    7,  141,  564,  535,   11, 1191,    1,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   58,    2,   47,    7,    2,    2,   11,    7,  399,\n",
      "            2,    1],\n",
      "        [   1,    5,    6,   31,   10,   80,    2,   19,  168,   12,  134,    1,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   70,   10,   80,    2,   34,   33,  296,   11,    2,\n",
      "            1,    0],\n",
      "        [   1,    4,    3,  768,   21,    7,    2,    9,   44,    2,  602,    1,\n",
      "            0,    0],\n",
      "        [   1,    5,    6,   25,  820,  307,   11,   78,    1,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    5,    6,  217,   10,    7,   65,  152,   33,   56,  650,  120,\n",
      "          866,    1],\n",
      "        [   1,   15,    3,   13,   11, 1162,    7,    2,    2,    9,   12,   91,\n",
      "            2,    1],\n",
      "        [   1,    4,    3,   26,   57,   21,    7,  136,    9,  216,    1,    0,\n",
      "            0,    0],\n",
      "        [   1,    5,    6,   26,   11,   40,    9,    2,    2,  158,    1,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   13,   27,    8,    2,  247,    1,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,  231,    8,  282,  513,    8,  643,    7,    2,    1,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,  165,    7,  365,    9,  548,    1,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   35,  197,   11,   14,  343,  936,    1,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    4,    3,   31,    8,  167,  402,    9,   59,  775,    1,    0,\n",
      "            0,    0],\n",
      "        [   1,   15,    3,   90,  404,  995,   77,    1,    0,    0,    0,    0,\n",
      "            0,    0]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "print(batch[0])\n",
    "print(batch[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.10 The LSTM Decoder [8 points]</b>\n",
    "    \n",
    "We are going to build a sequence-to-sequence (seq2seq) translation system.  Our seq2seq will have two major components: (1) an encoder that maps a source sentence to a tuple of (hidden, cell) vectors and (2) a decoder that uses the (hidden, cell) vectors to generate a translation.  The good news is that the encoder has already been implemented for you -- that is, you did it yourself in the previous problem!  We can simply reuse the `EncoderLSTM` that you used for the text classifier as our encoder; part of the point of this exercise is to illustrate that deep learning enables the use of common architectures for NLP problems that are quite different from one another (e.g. text classification vs. machine translation).\n",
    "\n",
    "Thus, our next task is to build the `DecoderLSTM` object.  Like the `EncoderLSTM`, there are two main functions to implement:\n",
    "- `__init__()`: Defines the layers of our network.  We will need an `Embedding` layer to encode the target vocabulary as vectors and an `LSTM` layer for decoding our target words.\n",
    "- `forward()`: Takes three arguments -- (a) the `input_seqs` of the target (i.e. a batch size x sequence length tensor), (b) `hidden_init`, the last hidden state of the encoder, and (c) `cell_init`, the last cell state of the encoder.  This function will return a tuple of three tensors -- (a) the hidden states of the LSTM for all time steps, (b) the final hidden state of the LSTM, and (c) the final cell state of the LSTM.\n",
    "\n",
    "Before moving on to the next section, we recommend testing your `forward()` function with randomly generated inputs (try  `torch.randint` for integer tensors and `torch.randn` for float/decimal tensors) to make sure it works without error.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, padding_idx: int):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.embeddings = nn.Embedding(input_size, hidden_size)#, padding_idx=self.padding_idx) \n",
    "        self.decoder_lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True) ## ASK WHAT TO DO WITH THESE DIMENSIONS\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input_seqs: torch.tensor, \n",
    "        hidden_init: torch.tensor, \n",
    "        cell_init: torch.tensor\n",
    "    ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "        embedding_sequences = self.embeddings(input_seqs)\n",
    "        output, (hn, cn) = self.decoder_lstm(embedding_sequences, (hidden_init, cell_init))\n",
    "        return (output, hn, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0039,  0.0665, -0.1885,  ...,  0.1380,  0.1263, -0.0664],\n",
       "          [ 0.1285,  0.0954, -0.1198,  ...,  0.3513, -0.0104,  0.2396],\n",
       "          [ 0.1616,  0.0418, -0.1507,  ...,  0.0916, -0.0462,  0.0630],\n",
       "          ...,\n",
       "          [-0.0280, -0.0088, -0.0401,  ...,  0.2311,  0.0184, -0.1161],\n",
       "          [-0.0076,  0.0426, -0.1218,  ...,  0.3435, -0.0088, -0.1698],\n",
       "          [ 0.0350,  0.1646, -0.1595,  ...,  0.2306,  0.1544, -0.1141]],\n",
       " \n",
       "         [[ 0.1121,  0.1323, -0.1444,  ...,  0.1270,  0.1613, -0.0353],\n",
       "          [-0.0549,  0.1513, -0.0308,  ...,  0.0651,  0.1714,  0.0166],\n",
       "          [-0.0044,  0.1957, -0.1001,  ...,  0.0385,  0.1159,  0.1462],\n",
       "          ...,\n",
       "          [ 0.0109, -0.0341, -0.1443,  ...,  0.1818,  0.1457,  0.1295],\n",
       "          [-0.2653,  0.0914,  0.0268,  ...,  0.0012,  0.2801,  0.1751],\n",
       "          [-0.4596,  0.1615,  0.1192,  ..., -0.0471,  0.2850,  0.1869]],\n",
       " \n",
       "         [[ 0.0829,  0.1051, -0.2347,  ...,  0.1242,  0.0598, -0.0373],\n",
       "          [ 0.0107,  0.0784, -0.2472,  ...,  0.1373, -0.1402,  0.0614],\n",
       "          [ 0.0904, -0.0036, -0.1795,  ...,  0.0323, -0.0870,  0.0261],\n",
       "          ...,\n",
       "          [-0.2488,  0.0868,  0.0943,  ..., -0.0050,  0.3273,  0.1961],\n",
       "          [-0.4468,  0.1571,  0.1590,  ..., -0.0476,  0.3170,  0.2017],\n",
       "          [-0.5572,  0.1891,  0.1893,  ..., -0.0574,  0.2946,  0.2024]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0835,  0.1487, -0.2029,  ...,  0.0927,  0.1352, -0.1341],\n",
       "          [ 0.2128,  0.1204, -0.1226,  ...,  0.3321, -0.0059,  0.1309],\n",
       "          [ 0.2061,  0.0552, -0.1526,  ...,  0.0856, -0.0419,  0.0285],\n",
       "          ...,\n",
       "          [-0.4025,  0.2130,  0.1527,  ..., -0.0308,  0.2833,  0.1436],\n",
       "          [-0.5305,  0.2162,  0.1871,  ..., -0.0484,  0.2701,  0.1677],\n",
       "          [-0.6019,  0.2162,  0.2030,  ..., -0.0551,  0.2598,  0.1803]],\n",
       " \n",
       "         [[ 0.0260,  0.0013, -0.1384,  ...,  0.1253,  0.1531, -0.0345],\n",
       "          [ 0.1590,  0.0728, -0.1105,  ...,  0.3449,  0.0015,  0.2791],\n",
       "          [ 0.1793,  0.0288, -0.1449,  ...,  0.0908, -0.0383,  0.0724],\n",
       "          ...,\n",
       "          [-0.1319,  0.1244,  0.0595,  ..., -0.0023,  0.4138,  0.1483],\n",
       "          [-0.3744,  0.1778,  0.1354,  ..., -0.0392,  0.3652,  0.1715],\n",
       "          [-0.5169,  0.1999,  0.1747,  ..., -0.0515,  0.3206,  0.1826]],\n",
       " \n",
       "         [[ 0.0515,  0.2194, -0.1818,  ...,  0.1037,  0.1816, -0.1329],\n",
       "          [ 0.0073,  0.1559, -0.2083,  ...,  0.1357,  0.1126, -0.0339],\n",
       "          [ 0.1013,  0.0908, -0.1421,  ...,  0.0868,  0.0130,  0.0239],\n",
       "          ...,\n",
       "          [-0.6007,  0.1915,  0.1888,  ..., -0.0564,  0.2699,  0.1883],\n",
       "          [-0.6432,  0.2009,  0.2016,  ..., -0.0583,  0.2618,  0.1913],\n",
       "          [-0.6686,  0.2055,  0.2082,  ..., -0.0591,  0.2567,  0.1930]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[ 0.0350,  0.1646, -0.1595,  ...,  0.2306,  0.1544, -0.1141],\n",
       "          [-0.4596,  0.1615,  0.1192,  ..., -0.0471,  0.2850,  0.1869],\n",
       "          [-0.5572,  0.1891,  0.1893,  ..., -0.0574,  0.2946,  0.2024],\n",
       "          ...,\n",
       "          [-0.6019,  0.2162,  0.2030,  ..., -0.0551,  0.2598,  0.1803],\n",
       "          [-0.5169,  0.1999,  0.1747,  ..., -0.0515,  0.3206,  0.1826],\n",
       "          [-0.6686,  0.2055,  0.2082,  ..., -0.0591,  0.2567,  0.1930]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0683,  0.2556, -0.2818,  ...,  0.4152,  0.3365, -0.2633],\n",
       "          [-0.7075,  0.2561,  0.2252,  ..., -0.1200,  0.3804,  0.6032],\n",
       "          [-0.9572,  0.3056,  0.3669,  ..., -0.1467,  0.3865,  0.6564],\n",
       "          ...,\n",
       "          [-1.1109,  0.3582,  0.4003,  ..., -0.1414,  0.3350,  0.5742],\n",
       "          [-0.8463,  0.3255,  0.3383,  ..., -0.1332,  0.4260,  0.5917],\n",
       "          [-1.4503,  0.3466,  0.4141,  ..., -0.1544,  0.3284,  0.6103]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model = EncoderLSTM(train_dl.dataset.source_vocab_size, 100, PADDING_IDX)\n",
    "hidden_cell, final_cell = encoder_model(batch[0]) # Alias for model.forward(batch)\n",
    "decoder_model = DecoderLSTM(train_dl.dataset.target_vocab_size, 100, PADDING_IDX)\n",
    "decoder_model(batch[1], hidden_cell, final_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.11 The Seq2Seq model [14 points] </b>\n",
    "    \n",
    "Now comes the fun part: putting everything together!  Using our `EncoderLSTM` and `DecoderLSTM` blocks, let's implement the `Seq2Seq` model below.  There are three main functions to implement:\n",
    "- `__init__()`: Initializing the `Seq2Seq2` model.  You will need three blocks -- the `EncoderLSTM`, the `DecoderLSTM`, and a `Linear` projection layer to map hidden states of the decoder to the target vocabulary for word prediction.  This final projection layer should be something very familiar to you -- i.e. it serves the same role as the final projection layer in `CBOW` (word2vec) from Homework #1.\n",
    "- `forward()`: This function will be used for training the model.  Machine translation models are typically trained with a concept call *teacher forcing*, in which the ground-truth tokens from the true target translation (dubbed the \"teacher\") are used as context to predict the next word.  Let $B$ be the batch size, $T_i$ be the sequence length for the input sequence, $T_o$ be the sequence length for the output sequence, $V_o$ be the size of the output vocabulary, and $M_o$ be the number of non-pad tokens in `output_seqs`.  Our `forward()` function will take a $B \\times T_i$ `input_seqs` tensor and its corresponding target translation, the $B \\times T_o$ `output_seqs` tensor, and return a tuple of (1) a flattened predictions tensor `preds` of size $M_o \\times V_o$ and (2) a flattened target words tensor `targs` of length $M_o$ (Note: `targs` should not contain any padding indices).   \n",
    "- `generate()`: Recall that in machine translation, training is very different from inference.  In training, we use the `forward()` function to train the model with *teacher forcing*.  However, at inference time, we don't know what the true translation is, so the model must generate the entire target sequence from scratch.  It can do this by first encoding the source sequence with the encoder and then passing the EOS token to the decoder/output_layer to get a probability distribution for the first word.  Then, it can take the most likely token from this probability distribution as the next word.  We can then feed this next word back into the decoder to get the next word after that, until our model generates the EOS token again, telling us the translation is finished.  This is the logic you will implement in the `generate()` function.  For ease of implementation, we won't batch this function.  That is, the argument `source` will be a 1D tensor of size $t_i$ and you will return a 1D translation tensor with maximium length `max_steps`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function \n",
    "def flatten_tensors(hidden_states: torch.tensor, target: torch.tensor, padding_idx: int) -> Tuple[torch.tensor, torch.tensor]:\n",
    "    trimmed_hs = []\n",
    "    trimmed_targets = []\n",
    "    for pair in zip(hidden_states, target):\n",
    "        curr_context = pair[0]\n",
    "        curr_target = pair[1]\n",
    "        #ctxt_boolean_mask = ((curr_context == padding_idx).nonzero(as_tuple=True)[0])\n",
    "        targ_boolean_mask = ((curr_target == padding_idx).nonzero(as_tuple=True)[0])\n",
    "        if targ_boolean_mask.numel() > 0:\n",
    "            first_pad_idx_targ = targ_boolean_mask.min(dim=0).values.item()\n",
    "            first_pad_idx_ctxt = first_pad_idx_targ\n",
    "        else:\n",
    "            first_pad_idx_targ = len(curr_target)\n",
    "            first_pad_idx_ctxt = first_pad_idx_targ\n",
    "        cutting_idx = min(first_pad_idx_ctxt, first_pad_idx_targ)\n",
    "        trimmed_hs.append(curr_context[:cutting_idx, :])\n",
    "        trimmed_targets.append(curr_target[:cutting_idx])\n",
    "    target = torch.cat(trimmed_targets, dim=0)\n",
    "    context = torch.cat(trimmed_hs, dim=0)\n",
    "    return context, target\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_vocab_size: int, output_vocab_size: int, hidden_size: int, padding_idx: int):\n",
    "        super().__init__()\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.encoder = EncoderLSTM(input_vocab_size, hidden_size, padding_idx)\n",
    "        self.decoder = DecoderLSTM(output_vocab_size, hidden_size, padding_idx)\n",
    "        self.linear1 = nn.Linear(hidden_size, output_vocab_size)\n",
    "        \n",
    "    def forward(self, input_seqs: torch.tensor, output_seqs: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        enc_hidden_cell, enc_final_cell = self.encoder(input_seqs)\n",
    "        # Trimming off ending EOS\n",
    "        seqs_length = [((t == self.padding_idx).nonzero(as_tuple=True)[0])[0].item() if len(((t == self.padding_idx).nonzero(as_tuple=True)[0])) != 0 else t.shape.numel() for t in output_seqs]\n",
    "        output_seqs_non_EOS = torch.stack([torch.cat([seq[:length-1], seq[length:]]) for seq, length in zip(output_seqs, seqs_length)])\n",
    "        \n",
    "        hidden_states, dec_final_hidden_state, dec_final_cell = self.decoder(output_seqs_non_EOS, enc_hidden_cell, enc_final_cell)\n",
    "        \n",
    "        # Trimming off initial EOS and ending EOS\n",
    "        output_seqs = torch.stack([seq[1:] for seq in output_seqs])\n",
    "        \n",
    "        flatten_hidden_states, flatten_targs = flatten_tensors(hidden_states, output_seqs, self.padding_idx)\n",
    "        out = self.linear1(flatten_hidden_states)\n",
    "        #log_probs_2 = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        return out, flatten_targs\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def generate(self, source: torch.tensor, max_steps: int, eos_idx: int) -> torch.tensor:\n",
    "        translation = []\n",
    "        source = torch.unsqueeze(source,0)\n",
    "        enc_hidden_cell, enc_final_cell = self.encoder(source)\n",
    "        blown_eos_idx = torch.tensor([[eos_idx]])\n",
    "        hidden_states, dec_final_hidden_state, dec_final_cell = self.decoder(blown_eos_idx, enc_hidden_cell, enc_final_cell)\n",
    "        flatten_hidden_states, flatten_targs = flatten_tensors(hidden_states, blown_eos_idx, self.padding_idx)\n",
    "        enc_hidden_cell = dec_final_hidden_state\n",
    "        enc_final_cell = dec_final_cell\n",
    "        out = self.linear1(flatten_hidden_states)\n",
    "        for i in range(1, max_steps):\n",
    "            next_idx = torch.argmax(torch.tensor(out))\n",
    "            translation.append(next_idx.item())\n",
    "            blown_next_idx = torch.unsqueeze(torch.unsqueeze(torch.tensor(next_idx), 0), 0)\n",
    "            hidden_states, dec_final_hidden_state, dec_final_cell = self.decoder(blown_next_idx, enc_hidden_cell, enc_final_cell)\n",
    "            flatten_hidden_states, flatten_targs = flatten_tensors(hidden_states, blown_next_idx, self.padding_idx)\n",
    "            out = self.linear1(flatten_hidden_states)\n",
    "            enc_hidden_cell = dec_final_hidden_state\n",
    "            enc_final_cell = dec_final_cell\n",
    "            # We want to exit the for loop if the next token predicted is eos index.\n",
    "            if torch.argmax(torch.tensor(out)) == eos_idx:\n",
    "                next_idx = torch.argmax(torch.tensor(out))\n",
    "                translation.append(next_idx.item())\n",
    "                break\n",
    "        return translation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "This is translation  [77, 502, 437, 988, 546, 663, 1067, 1109, 213, 64, 1021, 784, 479, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(train_dl.dataset.source_vocab_size, train_dl.dataset.target_vocab_size, 100, PADDING_IDX)\n",
    "batch = next(iter(train_dl))\n",
    "log_probs, targs = seq2seq(batch[0], batch[1])\n",
    "test_1D_tensor = torch.tensor([1,34,2,4])\n",
    "print(test_1D_tensor.shape)\n",
    "translation = seq2seq.generate(torch.tensor([1,34,2,4]), 40, EOS_IDX)\n",
    "print(\"This is translation \", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.12 Train the Seq2Seq model [8 points]</b>\n",
    "    \n",
    "Now it's time to train the model! Implement the `train()` function below to\n",
    "train your model. We've provided code that will call your `train()` to produce\n",
    "a new model, and optionally plot the losses. We recommend training for at least\n",
    "8 epochs to achieve desirable results.\n",
    "\n",
    "Please use your:\n",
    "* **train split** to train the model\n",
    "* **validation split** to compute losses\n",
    "* **test split** to evaluate the performance of your model using BLEU (in the next step)\n",
    "\n",
    "For convenience, you may use the helper function below to compute the loss\n",
    "of your model on your validation set.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "\n",
    "# you do not need to edit this cell\n",
    "def compute_test_loss(model, val_dl, loss_fn):\n",
    "    all_preds, all_targs = [], []\n",
    "    for i, (input_seqs, output_seqs) in enumerate(val_dl):\n",
    "        preds, targs = model(input_seqs, output_seqs)\n",
    "        all_preds.append(preds)\n",
    "        all_targs.append(targs)\n",
    "    preds = torch.cat(all_preds, dim=0)\n",
    "    targs = torch.cat(all_targs, dim=0)\n",
    "    return loss_fn(preds, targs).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_ds: Dataset, train_dl: DataLoader, val_ds: Dataset, val_dl: DataLoader):\n",
    "    model = None\n",
    "    losses = {\n",
    "        'train': [], # keep track of your losses in these lists\n",
    "        'val': []\n",
    "    }\n",
    "    \n",
    "    model = Seq2Seq(train_dl.dataset.source_vocab_size, train_dl.dataset.target_vocab_size, 512, PADDING_IDX)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss() #NLLLoss()\n",
    "    optimizer =  Adam(model.parameters(), lr=0.0001)#, weight_decay=1e-5)\n",
    "    \n",
    "    epochs = 15\n",
    "    for epoch in range(epochs):\n",
    "        train_running_loss = 0.0\n",
    "        val_running_loss = 0.0\n",
    "        for i, train_batch in enumerate(train_dl):\n",
    "            \n",
    "            train_preds, train_targets = model(train_batch[0], train_batch[1])\n",
    "            train_loss = loss_function(train_preds, train_targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_running_loss += train_loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        for i, val_batch in enumerate(val_dl):\n",
    "            with torch.no_grad():\n",
    "                val_preds, val_targets = model(val_batch[0], val_batch[1])\n",
    "                val_loss = compute_test_loss(model, val_dl, loss_function)\n",
    "\n",
    "                val_running_loss += val_loss#.item()\n",
    "\n",
    "        print('Epoch %d, training_loss %.3f, validation_loss %.3f' %\n",
    "            (epoch + 1, train_running_loss / len(train_dl), val_running_loss / len(val_dl)))\n",
    "        \n",
    "        losses['train'].append(train_running_loss/len(train_dl))\n",
    "        losses['val'].append(val_running_loss/len(val_dl))\n",
    "    print(\"Finished training!\")\n",
    "    \n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the cell below to train your model. For reference, it takes about 1 minute to train on our machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 4.640, validation_loss 3.673\n",
      "Epoch 2, training_loss 3.658, validation_loss 3.414\n",
      "Epoch 3, training_loss 3.411, validation_loss 3.250\n",
      "Epoch 4, training_loss 3.250, validation_loss 3.145\n",
      "Epoch 5, training_loss 3.128, validation_loss 3.069\n",
      "Epoch 6, training_loss 3.019, validation_loss 3.007\n",
      "Epoch 7, training_loss 2.920, validation_loss 2.945\n",
      "Epoch 8, training_loss 2.825, validation_loss 2.897\n",
      "Epoch 9, training_loss 2.736, validation_loss 2.847\n",
      "Epoch 10, training_loss 2.650, validation_loss 2.812\n",
      "Epoch 11, training_loss 2.566, validation_loss 2.788\n",
      "Epoch 12, training_loss 2.480, validation_loss 2.759\n",
      "Epoch 13, training_loss 2.400, validation_loss 2.740\n",
      "Epoch 14, training_loss 2.319, validation_loss 2.726\n",
      "Epoch 15, training_loss 2.239, validation_loss 2.712\n",
      "Finished training!\n",
      "CPU times: user 29min 55s, sys: 4min 49s, total: 34min 45s\n",
      "Wall time: 21min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e071dc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model, losses = train(train_ds, train_dl, val_ds, val_dl)\n",
    "\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses).plot(title='Train and Validation Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.13 Evaluate model performance with BLEU [2 points]</b>\n",
    "\n",
    "While the loss is a good way of keeping track of our training progress, it is not a universal metric for our model performance. Heuristically, we have no way of telling how well our model is working for an application standpoint beyond the handful of examples we can print out -- not to mention the difficulty of comparing the quality of the translations on different models which are trained and evaluated on different datasets!\n",
    "\n",
    "The BLEU metric was proposed to combat this discrepancy. BLEU is empirically proven to align with how humans perceive the quality of translations. In 1-2 sentences, explain what (unigram) BLEU evaluates. Only include equations as you find them necessary. May Google be your friend (or Mooogle if you've downloaded and saved a lot of web pages about Machine Translation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Answer: (Unigram) BLEU is a score that allows you to measure how good a machine translation is. The idea is if the translation is pretty close to a reference provided by humans, then we will get a high BLEU score. Intuitively, we look at each of the words in the translation output and see if it appears in any of the corresponding references. We will count the maximum of number of times that the word appears in any reference and divide it by the total number of tokens in the translation, thus computing modified precision of machine translation. In Unigram BLEU, we look at modified  precision of words or unigrams. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a method stub that translates all the examples from the test set, and\n",
    "returns both the model's translations as well as the original translations.\n",
    "This method will then be called to compute your BLEU score.\n",
    "\n",
    "**IMPORTANT:** Pay close attention to how your translations should be formatted:\n",
    "- `candidate_text`: these are the model's translations. It should have type\n",
    "`List[List[str]]`. Each inner list corresponds to a list of translated words.\n",
    "It should look like:\n",
    "\n",
    "```python\n",
    "    candidate_text = [\n",
    "        ['this', 'is', 'sentence', 'one'],\n",
    "        ['here', 'is', 'another', 'mighty', 'fine,' 'translation']\n",
    "    ]\n",
    "```\n",
    "\n",
    "- `reference_text`: these are the actual translations. When BLEU is computed,\n",
    "it allows for there to be more than one possible reference translation for\n",
    "every machine-translated example. As a result, it has a weirder type: `List[List[List[str]]]`.\n",
    "The extra nested list holds all the possible reference translation for every\n",
    "one machine translation. It should look like:\n",
    "```python\n",
    "    reference_text = [\n",
    "        [\n",
    "            # these are all possible reference translations for the first machine translated example\n",
    "            ['this', 'is', 'sentence', 'one'],\n",
    "            ['here', 'is', 'another', 'translation', 'for', 'sentence one'],\n",
    "        ],\n",
    "        [\n",
    "            # this example only contains one reference translation\n",
    "            ['here', 'is', 'another', 'mighty', 'fine,' 'translation'],\n",
    "        ]\n",
    "    ]\n",
    "```\n",
    "\n",
    "Practically, because we only have a single reference translation for every\n",
    "machine translation, your `reference_text` list should hold only a single\n",
    "example for every machine-translated text.\n",
    "\n",
    "For reference, we will use PyTorch's [bleu_score()](https://pytorch.org/text/stable/data_metrics.html) function\n",
    "to compute these scores.\n",
    "\n",
    "**NOTE**: `bleu_score()` is not included in the standard PyTorch installation.\n",
    "You will need to install the additional package [TorchText](https://pytorch.org/text/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_corpus(vocab: Dict[str, int], test_dl: DataLoader, model: nn.Module) -> Tuple[List[List[str]], List[List[List[str]]]]:\n",
    "    index_to_word = {v: k for k, v in vocab.items()}\n",
    "    candidate_text = []\n",
    "    reference_text = []\n",
    "\n",
    "    for source, target in test_dl:\n",
    "        current_translate_sentence = []\n",
    "        current_target_sentence = []\n",
    "        for source_item, target_item in zip(source, target):\n",
    "            translation = model.generate(source_item, 512, EOS_IDX)\n",
    "        candidate_text.append([index_to_word[idx] for idx in translation])\n",
    "        reference_text.append([[index_to_word[idx.item()] for idx in target_item if idx != PADDING_IDX]])\n",
    "        \n",
    "    return candidate_text, reference_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to compute you BLEU score. We achieved scores of around 0.3 - 0.5\n",
    "\n",
    "Depending on how you implemented your model, your mileage may vary. Scores\n",
    "less than 0.1 probably indicate something is off with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46453648791398827"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_text, reference_text = translate_corpus(train_ds.target_vocab, test_dl, model)\n",
    "bleu_score(candidate_text, reference_text, max_n=1, weights=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_yellow'><b>2.14 Identify the mystery language [6 points]</b>\n",
    "    \n",
    "You are now ready to unveil the mystery language! Train a model for each of the five different pairings:\n",
    "* Danish --> Mystery\n",
    "* English --> Mystery\n",
    "* German --> Mystery\n",
    "* Finnish --> Mystery\n",
    "* Spanish --> Mystery\n",
    "\n",
    "**NOTE:** The direction of translation is the *opposite* of what you did before\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 5.555, validation_loss 4.483\n",
      "Epoch 2, training_loss 4.341, validation_loss 3.961\n",
      "Epoch 3, training_loss 3.912, validation_loss 3.657\n",
      "Epoch 4, training_loss 3.632, validation_loss 3.451\n",
      "Epoch 5, training_loss 3.421, validation_loss 3.303\n",
      "Epoch 6, training_loss 3.253, validation_loss 3.185\n",
      "Epoch 7, training_loss 3.110, validation_loss 3.090\n",
      "Epoch 8, training_loss 2.983, validation_loss 3.008\n",
      "Epoch 9, training_loss 2.868, validation_loss 2.945\n",
      "Epoch 10, training_loss 2.766, validation_loss 2.889\n",
      "Epoch 11, training_loss 2.669, validation_loss 2.842\n",
      "Epoch 12, training_loss 2.577, validation_loss 2.802\n",
      "Epoch 13, training_loss 2.490, validation_loss 2.782\n",
      "Epoch 14, training_loss 2.407, validation_loss 2.751\n",
      "Epoch 15, training_loss 2.326, validation_loss 2.731\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e0817210>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: train five different models, one for each of the five different pairings\n",
    "\n",
    "train_ds_d_m = TranslationDataset(train_dict[\"danish\"], train_dict[\"mystery\"])\n",
    "val_ds_d_m = TranslationDataset(val_dict[\"danish\"], val_dict[\"mystery\"], source_vocab=train_ds_d_m.source_vocab, target_vocab=train_ds_d_m.target_vocab)\n",
    "test_ds_d_m = TranslationDataset(test_dict[\"danish\"], test_dict[\"mystery\"], source_vocab=train_ds_d_m.source_vocab, target_vocab=train_ds_d_m.target_vocab)\n",
    "    \n",
    "train_dl_d_m = DataLoader(train_ds_d_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl_d_m = DataLoader(test_ds_d_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl_d_m = DataLoader(val_ds_d_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "\n",
    "\n",
    "model_d_m, losses_d_m = train(train_ds_d_m, train_dl_d_m, val_ds_d_m, val_dl_d_m)\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses_d_m).plot(title='Train and Validation Loss Danish to mystery')\n",
    "\n",
    "#raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 5.517, validation_loss 4.466\n",
      "Epoch 2, training_loss 4.329, validation_loss 3.956\n",
      "Epoch 3, training_loss 3.913, validation_loss 3.664\n",
      "Epoch 4, training_loss 3.641, validation_loss 3.462\n",
      "Epoch 5, training_loss 3.436, validation_loss 3.319\n",
      "Epoch 6, training_loss 3.272, validation_loss 3.199\n",
      "Epoch 7, training_loss 3.126, validation_loss 3.095\n",
      "Epoch 8, training_loss 2.998, validation_loss 3.011\n",
      "Epoch 9, training_loss 2.881, validation_loss 2.938\n",
      "Epoch 10, training_loss 2.773, validation_loss 2.880\n",
      "Epoch 11, training_loss 2.671, validation_loss 2.832\n",
      "Epoch 12, training_loss 2.576, validation_loss 2.798\n",
      "Epoch 13, training_loss 2.487, validation_loss 2.759\n",
      "Epoch 14, training_loss 2.400, validation_loss 2.744\n",
      "Epoch 15, training_loss 2.319, validation_loss 2.708\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e0b6fc10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3yV5f3/8dcnmyxCFoEESJhhr4AgoAyLuHArrVq1tlSrrV12fNtvq35ttePXWtuqdS9qa1HrXgjIENAAInuFFVYWIWGErM/vj/sOHmJ2TnJyTj7Px+M8csZ9rvM5J8n7XOe673NdoqoYY4zxf0G+LsAYY4x3WKAbY0yAsEA3xpgAYYFujDEBwgLdGGMChAW6McYECAt0LxORYBE5JiK9O0Aty0TkprZuW0RuFJF32qIOEekrIsdaVmXn05zfi8d9XhCRu9u6NtP2On2gu+Fbc6oWkZMel69rbnuqWqWq0aq6ty3q9QYRuUFEdtZxfZiIFIjIrOa0p6rPquoFXqotV0SmerSdo6rR3mi71uOEiIiKSLq3227CY98nIhW1/vYKvP043vy91BCR/iLS4i+viMh57uv+Uq3rs9zrF7SyvvtE5JnWtOHPOn2gu+Eb7YbGXuASj+vm1d5eRELav0qvexlIEpHJta6/ECgHPmj/kjqdeZ5/e6qa6OuC2tFh4FwRifO47uvANh/Vc5q//393+kBvjPuO/28ReVFESoHrRWSiiKwUkWIROSgiD4lIqLv9GT0/9+PsQyLyjoiUisgKEcmo57GCRGS+iBxy214sIoM9bm+wLRGZJSJbReSoiPwFkLoeR1VPAPNx/ok8fR14QVWrRCRBRN4WkXwROSIib4hIaj11f1NEFjelDhEZICKLRKTQ/TTwvIh0dW97EegJvOP2Wn9Yu0coImki8qaIFInIdhH5Rq3f1Yvu61QqIhtEZExdNTfE/T38SkT2iEieiDwjIrHubZEi8k+3/mIR+UREEt3bbhGR3e5j54jInBY8ds3fz7dFZIf72j/kcXuwiDzoPn6OiHy3vh6z5+/FfU4Puc/nqIh8LiJDPDaPb8rfKLDEba/mk8W4hl6vepQBbwDX1jxn4Crgnx61/0NEflfr+bwjIne45/9HRA6ISImIbBGRqSJyMfAT4Dq3ttXutnEi8rQ4/6u5InKviAR5vEZL3NemCLjP/b16/t/1EJETIpLQwHPqGFTVTu4J2A2cV+u6+3B6rZfgvAF2AcYBZwEhQF+cnsUd7vYhgALp7uUXgAIgCwgF/o0TmnU9fhBwExADRAB/A7I9bq+3LSAZOAZc7t52F1AJ3FTPY50LFAMR7uVuwClgmHs5yW2rCxALvALM97j/spq2gW8Ci5tSBzAQmAGEudsuB/7o0W4uMNXjcn/nz/T05eXAX93XZ4z7epzr8bs6CZwPBAN/AJbV8/zP+D3Vum2u+zvNcH8XrwFPu7fdDvzXfV2C3d9FtPsaHQUGuNv1AIbU89j3Ac80UtdrQFcgHSjC/bsE7gA2AKlAPLCo1utT3+/lIuATt80gYAiQ0oK/0TN+H429XnXc/zyc/7NzgOXudbOBt4BbgQXudWcD+4Ag93J34ASQCAwF9njUnwH0re+1Bd4EHgYigRRgNXCLx2tUCdzm/j67AI8Bv/G4/4+AV32dT005+byAjnSi/kBf2Mj9fgz8xz1fV6A/6rHtbGBDE+tJdNuKaqwt4Bt4hJf7T3uQ+gNdgBzgGvfybcDqBmrJAvI9LtcXHM2t4yrgU4/L9Qa6+49bUfN6uNf9AXjC43f1rsdtI4Bj9TxuQ4H+ETDX4/JQnDe7IJzwWgYMr3WfWJw3yMtx3yQbeC1rOgnFHqcPatU1wWP7V4Afu+eX4IaRe3kWTQv0mcAWnI5IUK16mvw3St2BXu/rVcf9awK95u+vH86nxWvxCHR3223ANPf894HX3fODcIZtZgAhdby2z3hcTsV5kw/3uO4Gj9f7m0BOrTYmAbsAcS9/BlzRlP9ZX59syKVp9nleEJFMEXlLnKGREuBenPCtzyGP8ydwenRf4n6c/r37UboE2OHe5Nl2fW319KxTVatxwrFObkI+zxfDLjcAz3rUEiUiT4jIXreWhTT8HGs0WIeIpIjISyKy3233mSa2W9N2gaoe97huD84/bY3ar09UE9uu/Th7aj1GGM6nlmeABUDNc3hAREJUtQT4Kk4P/pA7LDSwgcf4p6rGeZy+Uuv2Jv2ea52vl6q+DzwKPAIcFpFHRSSmCY/XFA29XvXVozhvJHcCU3B69bU9B1zvnr8e5+8VVd2K02u+F8hzh9lS6nmoPkA4znMuFpFi4O84Pf4aZ7yGqrocp9c+WUSGAb1xPkF0eBboTVN7jPIfOB97+6tqLPAr6hmvbqav4+yYnI7z0bi/e31T2j4I9Kq54I4RpjVyn+eAmSJyNk4P/EWP236C0yMe7z7H6U15Ak2o43c4vbfhbrs3cebza+gIigNAooh4hnRvYH8Ta2uqAzhB4PkY5TifUMpV9W5VHQxMxumRXwegqu+o6nk4wy07cP5OvO0gZ76everbsDZVfVBVxwDDcIZcftiCx6/r91Pv69VIW8/hvAG+rqplddz+PHCFiIzG6cm/cboI1RdUdRLO32gwcH899e3DeYOK93jzjFXVEY08p5o3kxuAl1T1VCPPpUOwQG+ZGJzx0uPuzpNve7HdU0Ahznjfb5px3zeBUSJyqbuT6Qc00EMCUNWdwCqcnVHvqKrnP2AMzj/CEXdn0K+8VEcMcBw4KiK9cIarPB3G2S9RV727gGzgtyISLiKjgJuBLx2N1AzhIhLhcQrGeWP7oYiku73Y3wAvqmq1iEwXkWHuG1UJzhBQlbvj7BIRicQJs+NAVSvqqs9LwPdFpKeIdMPZR9EoERnvnkLc2spbWF8eoCLi+Tuq9/VqqCFV3QFMpZ6/LVXdgzPc8SzOkGaZ+1wGi8g0EQnHGU456fFcDgPpIiJuG/twhoT+KCKx7g7c/iJyTiPP83mc4cCv4YS7X7BAb5kfATcCpTi9sH97qd2ncXo7B4CNwMdNvaOqHsYZh/wDzhtCb5ywbsyzOL2r2n+0f8L5lFDo1tHoF1SaWMevgfE4b4iv4xxC6em3wD3ux+Pv1/EQ1wIDcIYI5gP/o6qLmlJbPbbwRSicxOmRPY7zO12KM85bijM0AM7wwis4Yb4RZ/jlRZxe4l04PehCnJ16dzTwuDVHYniemnIUxSPAYmA9zs69t3DCuTFxwJM44/W73Tr/3IT7nUFVS3F6w6vc31EWDb9ejbW3VFUPNrDJs8Bw3OEWVzjwe5wduYdwduj/0r3t3zjDPUUi8ol73fU4Q2+bgCPAf3B2jjZU126c17hcVZv8f+hrNYP+xhg/JCKXAA+qaj9f19IWRGQ6zhtRX23nsBKR53B2mN7dno/bGn59EL0xnY27/2AKzpe/euAMV7zq06LaiIiE4fT0H/dBmPcFLsX5dOA3bMjFGP8iOGPUR3GGXD4H7vFpRW1ARIbjDI/EAw81srm3H/t+YB3wW+3AU3jUxYZcjDEmQFgP3RhjAoTPxtATExM1PT3dVw9vjDF+afXq1QWqWuchyT4L9PT0dLKzs3318MYY45dEZE99t9mQizHGBAgLdGOMCRAW6MYYEyDsi0XGGL9SUVFBbm4uZWV1zecVOCIiIkhLSyM0NLTJ97FAN8b4ldzcXGJiYkhPT8edgyvgqCqFhYXk5uaSkVHf4lFfZkMuxhi/UlZWRkJCQsCGOYCIkJCQ0OxPIU3qoYvIbpwZ1KqASlXNqnX7VJwJ6ne5V72iqvc2qxJjjGmiQA7zGi15js0ZcpmmqgUN3L5UVS9udgXNtO1wKf/+dB93nT+IiNDgtn44Y4zxG3435JJ75ARPLtvFql1Fvi7FGNMJFRcX8/DDDzf7fhdeeCHFxcVtUNEXmhroCrwvIqtFZG4920wUkXUi8o6IDK1rAxGZKyLZIpKdn9/Y6lR1O7tfIhGhQSzaktei+xtjTGvUF+hVVQ0vAPX2228TFxfXVmUBTQ/0Se5ahBcAt9exfNMaoI+qjgT+Cvy3rkZU9TFVzVLVrKSkBldHq1dEaDCT+iXy4ZbD2EyRxpj29rOf/YydO3cyatQoxo0bx7Rp0/ja177G8OHO1OmXXXYZY8eOZejQoTz22GOn75eenk5BQQG7d+9m8ODBfOtb32Lo0KHMnDmTkydPeqW2Jo2hq+oB92eeiLyKs4TYEo/bSzzOvy0iD4tIYiNj7i02LTOZD7fksSPvGAO6xzR+B2NMQLrnjY1sOlDS+IbNMKRnLL++pM5BBgAeeOABNmzYwGeffcbixYu56KKL2LBhw+nDC5966ini4+M5efIk48aN48orryQh4czVBbdv386LL77I448/zjXXXMPLL7/M9ddf3+raG+2hi0iUu/BrzWopM3FWvPfcJqVmUVYRGe+2W9jq6uoxPTMZgA9t2MUY42Pjx48/41jxhx56iJEjRzJhwgT27dvH9u3bv3SfjIwMRo0aBcDYsWPZvXu3V2ppSg+9O/Cqm9chwD9V9V0RuRVAVR/FWR37NhGpxFlod05bLhnVM64Lg3vEsnBLHreeG5BLKRpjmqChnnR7iYqKOn1+8eLFLFiwgBUrVhAZGcnUqVPrPJY8PDz89Png4OD2G3JR1RxgZB3XP+px/m/A37xSURPNyEzmkY92UnyinLjIsPZ8aGNMJxYTE0NpaWmdtx09epRu3boRGRnJli1bWLlyZbvW5neHLdaYlplMVbXy0baWHS1jjDEtkZCQwKRJkxg2bBh33XXXGbfNmjWLyspKRowYwf/+7/8yYcKEdq3NZ2uKZmVlaWsWuKiqVsb9ZgFTBiTylzmjvViZMaYj27x5M4MHD/Z1Ge2irucqIqtrf1u/ht/20IODhKmDkvhoWz6VVdW+LscYY3zObwMdYEZmd4pPVLB2X9t++8oYY/yBXwf6lIGJhAQJH262wxeNMcavAz02IpRx6fEs3HLY16UYY4zP+XWgA8wYnMy2w8fYV3TC16UYY4xP+X2g13xrdNFWG3YxxnRufh/ofZOiyUiMsnF0Y0yHFB0d3W6P5feBDjBtUDIrdhZy/FSlr0sxxhifCYhAnzE4mfKqapbvaJPJHY0x5rSf/vSnZ8yHfvfdd3PPPfcwY8YMxowZw/Dhw3nttdd8UltzlqDrsMalxxMdHsKirXnMHJri63KMMe3lnZ/BofXebTNlOFzwQL03z5kzh+9///t85zvfAeCll17i3Xff5Qc/+AGxsbEUFBQwYcIEZs+e3e5rnwZEoIeFBHHOwEQ+3JyHqnaKBWSNMb4xevRo8vLyOHDgAPn5+XTr1o0ePXrwgx/8gCVLlhAUFMT+/fs5fPgwKSnt28EMiEAHZxz97fWH2HighGGpXX1djjGmPTTQk25LV111FfPnz+fQoUPMmTOHefPmkZ+fz+rVqwkNDSU9Pb3OaXPbWkCMoQNMHZSMCHa0izGmzc2ZM4d//etfzJ8/n6uuuoqjR4+SnJxMaGgoixYtYs+ePT6pK2ACPSkmnJFpcSy049GNMW1s6NChlJaWkpqaSo8ePbjuuuvIzs4mKyuLefPmkZmZ6ZO6AmbIBZxFL/7fB9vILz1FUkx443cwxpgWWr/+i52xiYmJrFixos7tjh071l4lBU4PHZxFL8C+NWqM6ZwCKtCH9oyle2w4C20c3RjTCQVUoIsI0zO7s3R7PuWVtuiFMYHKVyuttaeWPMeACnRwxtGPl1fxya4iX5dijGkDERERFBYWBnSoqyqFhYVEREQ0634BtVMUYFL/RMJDgvhwy2EmD0j0dTnGGC9LS0sjNzeX/PzAXiA+IiKCtLS0Zt2nSYEuIruBUqAKqKy9QKk4X838C3AhcAK4SVXXNKsSL+kSFszEfgks3JLHry4eYt8aNSbAhIaGkpGR4esyOqTmDLlMU9VR9aw2fQEwwD3NBR7xRnEtNSMzmT2FJ8gpOO7LMowxpl15awz9UuA5dawE4kSkh5fabraawxftaBdjTGfS1EBX4H0RWS0ic+u4PRXY53E5173uDCIyV0SyRSS7Lce/0rpFkpkSw4e21qgxphNpaqBPUtUxOEMrt4vIObVur2ug+ku7oFX1MVXNUtWspKSkZpbaPNMyk/l09xGOnqxo08cxxpiOokmBrqoH3J95wKvA+Fqb5AK9PC6nAQe8UWBLzchMpqpaWbo9sPeEG2NMjUYDXUSiRCSm5jwwE9hQa7PXga+LYwJwVFUPer3aZhjduxtxkaE2jm6M6TSacthid+BV9/C/EOCfqvquiNwKoKqPAm/jHLK4A+ewxZvbptymCw4Spg1KZtHWPKqqleAgO3zRGBPYGg10Vc0BRtZx/aMe5xW43bultd60zGReXbufz/YdYWyfeF+XY4wxbSrgvvrv6dwBSQQHCQu32LCLMSbwBXSgd40MJatPN1vFyBjTKQR0oAPMGJzMlkOl7C8+6etSjDGmTQV8oE/P7A5gwy7GmIAX8IHeLymK3vGRLLJAN8YEuIAPdGfRi2SW7yjgZHmVr8sxxpg2E/CBDs44+qnKaj7eWeDrUowxps10ikAfnxFPVFgwH9qwizEmgHWKQA8PCWbygEQWbckL6GWrjDGdW6cIdIAZmd05eLSMzQdLfV2KMca0iU4T6FMznel6F9oc6caYANVpAj05JoKRaV1tHN0YE7A6TaCDM1nXZ/uKKTx2ytelGGOM13WqQJ+R2R1VWLzVFr0wxgSeThXoQ3vGkhwTbtMAGGMCUqcK9KAg51ujS7blU15Z7etyjDHGqzpVoIMzjl56qpLs3UW+LsUYY7yq0wX65P6JhAUH2bCLMSbgdLpAjwoPYUK/BAt0Y0zA6XSBDjAjM5mcguPk5B/zdSnGGOM1nTLQp2cmA7bohTEmsHTKQO8VH8mA5GgWbbVAN8YEjiYHuogEi8haEXmzjttuEpF8EfnMPX3Tu2V63/TByazKKaK0rMLXpRhjjFc0p4d+J7C5gdv/raqj3NMTrayrzc3I7E5ltbJ0uy16YYwJDE0KdBFJAy4COnxQN9WY3nF07RLKh5tt2MUYExia2kN/EPgJ0NDXK68Ukc9FZL6I9KprAxGZKyLZIpKdn+/b+VRCgoM4d2ASi7fmUV1ti14YY/xfo4EuIhcDeaq6uoHN3gDSVXUEsAB4tq6NVPUxVc1S1aykpKQWFUxRDrx2O1S2fsbEGYOTKTxezrrc4la3ZYwxvtaUHvokYLaI7Ab+BUwXkRc8N1DVQlWtSdjHgbFerdJT4U5Y+wIs+k2rmzp3YBJBYocvGmMCQ6OBrqo/V9U0VU0H5gALVfV6z21EpIfHxdk0vPO0dQZ8BcbeDMsfgj0ft6qpuMgwsvrE2zi6MSYgtPg4dBG5V0Rmuxe/JyIbRWQd8D3gJm8UV6+Z90G3PvDqrXCqdWuETstMZtPBEg4dLfNSccYY4xvNCnRVXayqF7vnf6Wqr7vnf66qQ1V1pKpOU9UtbVHsaeHRcPk/4Og+eO8XrWpqxmD71qgxJjD47zdFe0+ASXfCmmdh67stbmZAcjRp3brY4tHGGL/nv4EOMPXn0H0YvP5dOF7YoiZEhBmZySzbUUBZRZWXCzTGmPbj34EeEu4MvZQVw5vfB23Z8eTTMpMpq6hmxc6WvSkYY0xH4N+BDpAyDKb9Aja/Dp+/1KImJvRNoEtosI2jG2P8mv8HOsDZ34VeE+Dtu+BobrPvHhEazOQBibyz4SB5pXa0izHGPwVGoAcFw+WPQHUl/Pc7UN38BaDvnDGA46eqmPvcahtLN8b4pcAIdID4vjDrt7DrI/j08WbffVhqV/587SjW5Rbzo/+ss/ldjDF+J3ACHWDMjTBgJnzwK8jf1uy7zxqWwk9nZfLW5wd58MPtbVCgMca0ncAKdBGY/VcI7QKvfhuqmr94xbfP6cvVY9N46MPt/Hft/jYo0hhj2kZgBTpATApc/Gc4sAaW/qnZdxcRfnP5cM7KiOcn8z8ne3dRGxRpjDHeF3iBDjD0chh+DSz5Pexf0+y7h4UE8ej1Y+kZF8G3n1/NvqITbVCkMcZ4V2AGOsCFv4eoZGfopeJks+/eLSqMJ28aR0VVNd945lNKbO1RY0wHF7iB3qUbXPZ3KNgGH97boib6JUXzyPVj2VVwnDv+uZbKquYfDmmMMe0lcAMdoN90GD8XVj4Mu5a0qIlJ/RP5v8uGsWRbPv/35iYvF2iMMd4T2IEOcN49kNAfXr0Nyo62qImvju/Nt6Zk8OyKPTz78W7v1meMMV4S+IEeFulM4FV6EN75WYub+dkFgzlvcDL3vLGRxVttzhdjTMcT+IEOkJYFU34E6/4Jm99oURPBQcJf5oxmUEosd/xzLVsPtW6lJGOM8bbOEegA59wFPUbCG3fCsZb1sKPCQ3jyxiy6hAVzy7OfUnDsVON3MsaYdtJ5Aj0kzBl6OXUMXv9ei+dO7xnXhSe+nkV+6SnmPpdtE3kZYzqMzhPoAMmDYcavYNs7sPaFFjczslccf752FGv2FvPTlz9HW/jmYIwx3tS5Ah1gwnegz2R492dwZHeLm7lweA/uOn8Qr312gIc+3OG9+owxpoU6X6AHBcFlDwPS4rnTa3xnaj+uGJ3Knxds4/V1B7xXozHGtECTA11EgkVkrYi8Wcdt4SLybxHZISKrRCTdm0V6Xbc+cMEDsGc5rPx7i5sREe6/cjjj0rvx4/+sY83eI14s0hhjmqc5PfQ7gc313HYLcERV+wN/Bn7X2sLa3KjrYNBFzrQAh1v+DdDwkGD+cUMWKbERzH0um9wjNpGXMcY3mhToIpIGXAQ8Uc8mlwLPuufnAzNERFpfXhsSgUv+AuGxzgReleUtbio+KoynbsriVGU1tzyTTalN5GWM8YGm9tAfBH4C1DfgnArsA1DVSuAokFB7IxGZKyLZIpKdn5/fgnK9LDrJCfVDn8NHrftQ0T85hoevG8OO/GN878W1VNkSdsaYdtZooIvIxUCeqq5uaLM6rvtSoqnqY6qapapZSUlJzSizDQ2+2Bl+WfYn2Pdpq5qaMiCJe2YPZdHWfO57yybyMsa0r6b00CcBs0VkN/AvYLqI1D6IOxfoBSAiIUBXwH+W+pl1P8SmwvybIW9Lq5q6fkIfbp6UztPLd/P8yj1eKtAYYxrXaKCr6s9VNU1V04E5wEJVvb7WZq8DN7rnr3K38Z8xh4iucO3zUHkKnjgPtr3fquZ+edEQpg1K4u7XN7JkWwcYWjLGdAotPg5dRO4VkdnuxSeBBBHZAfwQaPm0hr7SczR8ayHEp8OL18LHf2vx9ADBQcJDXx1N/6Robp+3hu2HbSIvY0zbE191pLOysjQ7O9snj92g8uPOUS+b34DR18NFf4KQ8BY1lXvkBJf9/WMqqqp58NpRTMtM9nKxxpjORkRWq2pWXbd1vm+KNiYsCq5+Ds75iTPfy3OXwvGCFjWV1i2Sl2+bSGpcF25+5lP+9P5WO/rFGNNmLNDrEhQE038BVz4JB9bCY9Pg8MYWNdUnIYpXvnM2V49N46GFO7jp6U8oOt7yY96NMaY+FugNGX4V3Pw2VJXDkzNhy9staiYiNJg/XD2S3105nFW7irj4oaWstWkCjDFeZoHemNSxMHeRsy7pv74Gy/7c4p2l147rzSu3nU1QkHDNP1bw/IrdNvWuMcZrLNCbIrYn3PwODL0MFtwN/70NKspa1NSw1K68+d3JTBmQxP++tpEf/PszTpRXerdeY0ynZIHeVGGRcNXTMO0XsO5FePaSFi9lFxcZxhNfz+LHMwfy2roDXPb35ezMP+blgo0xnY0FenOIwLk/gaufhUPrnZ2lBz9vUVNBQcId0wfw3DfGU3CsnEv/tpx31h/0csHGmM7EAr0lhl4G33gXtBqeOh82vd7ipqYMSOLN706mf3I0t81bw2/e2kRFVcsX3TDGdF4W6C3Vc5SzszR5MLx0Ayz5Q6sWnn7p2xO5cWIfHl+6i+seX0VeScvG6I0xnZcFemvEpMBNb8Hwa2DhffDyN6HiZIuaCgsJ4p5Lh/GXOaNYv/8oFz60jJU5hV4u2BgTyCzQWyu0C1zxGMz4FWyYD89cBKWHWtzcpaNSee2OScRGhHDdE6v4x0c77dBGY0yTWKB7gwhM+RFcO8+Zfvexac43TFtoYPcYXrtjEucP7c7972zh1hdWU2KrIBljGmGB7k2DL4Zb3oOgYHjqAtj4aoubiokI5e9fG8MvLxrMgs15zP7rMjYfLPFiscaYQGOB7m0pw51peHuMgP/cBIsfaPHOUhHhm1P68uK3JnCivIrLH17OK2tyvVuvMSZgWKC3hehkuPENGPlVWHw/vHAF5G9tcXPjM+J583uTGZkWxw9fWscvXl3PqcoqLxZsjAkEFuhtJSQcLnsELvgD5GbDI2fDOz+Dky2blCs5JoJ53zyLb5/bl3mr9nLNoyvs26XGmDPYAhft4Vg+LLoP1jwHEXEw7X9g7M0QHNKi5t7dcIi75q/jZHkVN09K53szBhATEerloo0xHVFDC1xYoLenQ+vh3Z/D7qWQPATO/y30m9aipvJLT/GH97bwn9W5JESF8ZPzM7lqbBpBQeLloo0xHYkFekei6ixv9/4voXgPDLoQZt4HCf1a1NznucXc/fpG1uwtZkRaV359yVDG9unm5aKNMR2FBXpHVFEGKx+Gpf8PKk/BhFvhnLsgomuzm1JV/vvZfu5/ewt5pae4YnQqP70gk+6xEW1QuDHGlyzQO7LSQ/Dh/8Fn8yAqEab/Ekbf4BzL3kzHT1Xy90U7eGLpLkKChTum9+eWyRmEhzS/LWNMx2SB7g8OrHWOgtm30jmWfdYDkD65RU3tKTzO/725mQWbD9MnIZJfXjSE8wYnI2Lj68b4u4YCvdHDFkUkQkQ+EZF1IrJRRO6pY5ubRCRfRD5zT9/0RuGdSs/RzpS8Vz0FJ4udOWH+fQMc2d3spvokRPHEjVk8943xhAYH8a3nsvn6U5+wI6/U+3UbYzqMRnvo4nTrolT1mIiEAsuAO1V1pcc2NwFZqnpHUx/YeugNqDgJH//VWb+0ugom3g5TfgjhMc1vqqqa51bs4cEF2zhZXsXXJ6Zz576Ef4kAABe9SURBVHkD6NrFDnM0xh+1qoeujppvsIS6J5v+ry2FdnFWRvruamcxjWV/gr+OhbXzoLp5i1+EBgdxy+QMFv94KldnpfH0x7uY/sfFvPjJXqqq7ddoTCBp0jdFRSRYRD4D8oAPVHVVHZtdKSKfi8h8EelVTztzRSRbRLLz8/NbUXYnEdvTmZr3lgXQtRe89h14YjrsXdn4fWtJiA7n/itG8MYdk8lIjOLnr6xn9t+Wkb27qA0KN8b4QrN2iopIHPAq8F1V3eBxfQJwTFVPicitwDWqOr2htmzIpZmqq2H9f2DB3VB6AIZd6RzmmDy42U2pKq+vO8D9b2/hUEkZs0f25OcXZtKjaxfv122M8SqvHuUiIr8GjqvqH+u5PRgoUtUGD6i2QG+h8uOw7EH4+CGoLIPeZ0PWN2DIbGf+mGY4UV7JI4t38o8lOQSLcPu0fnxzSl8iQu0wR2M6qlYFuogkARWqWiwiXYD3gd+p6pse2/RQ1YPu+cuBn6rqhIbatUBvpeMFzrHr2U/DkV0QmQCjroOxNzX7W6f7ik5w31ubeG/jYVLjunDb1H5cNTbNgt2YDqi1gT4CeBYIxhlzf0lV7xWRe4FsVX1dRO4HZgOVQBFwm6puaahdC3Qvqa6GXYsh+ynY8jZoFfSd5vTaB10AwU0/mmX5jgJ+/+4W1uUeJTE6jJsnZXD9hD52RIwxHYh9saizKDkIa5+H1c9AyX6IToExX4exN0LXtCY1oaqsyCnk0Y9yWLItn+jwEL52Vm9umZxhUwkY0wFYoHc2VZWw4wOn1779A2fN0wHnw7hboN/0Jk8rsGH/Uf6xJIe3Pj9AcJBwxeg05p7bl35J0W38BIwx9bFA78yO7IE1zzpzsR/Ph7jezjj76BuclZWaYG/hCR5fmsNL2fsor6pm5pDu3HpuP0b3tlkdjWlvFugGKsth61tOr33XEggKgcGXOGPt6VOcXnwjCo6d4pnlu3luxW5KyiqZ0DeeW8/tx7kDk2yeGGPaiQW6OVPBdmecfe0LUFYMCf2dYB/5VYiMb/Tux05V8uKqvTy5bBeHSsoY3COWW8/ty0XDexASbKsaGtOWLNBN3SpOwqbXnF77vlUQHA5DL4fhV0Pfcxs9Qqa8spr/frafRz/aSU7+cXrFd2HulL5cndXLDnk0po1YoJvGHdoAq5+Gz1+CUyXQJd75stLQK5xpfBvYkVpdrXyw+TCPLN7JZ/uKSYgK4+ZJ6dwwIZ2ukXbIozHeZIFumq6iDHZ+CBtega3vQMVxiEp2JgkbegX0OguC6h5WUVVW7Sri0Y92snhrPlFhwXx1fG9umZJh0woY4yUW6KZlyk/A9vdhw8vOz8oyiE2FIZc5c8mkjql3Z+qmAyX8Y8lO3vz8IEECl4zsyY0T0xnZK66dn4QxgcUC3bTeqVLY+i5sfMU5tr26AuL6OGPuw66AlBF1hvu+ohM8sTSH/6zO5UR5FSPSunL9hD5cMqInXcJsnN2Y5rJAN951shi2vOWE+85FznQDCf2dIZlhV9Q5A2RpWQWvrt3P8yv2sD3vGF27hHL12DSum9CHjMQoHzwJY/yTBbppO8cLYfPrTrjvXgZaDUmDnSGZYVd8aaKwmnH251fu4b0Nh6isVqYMSOT6CX2YkZlshz0a0wgLdNM+Sg87h0FufAX2rnCuSxnhBPuQyyA+44zN80rK+Nen+/jnqr0cKimjR9cIvja+N9eO70VyjM0bY0xdLNBN+zu6Hzb919mhun+1c11SJgyYCQNnOUfLBIcAUFlVzYLNecxbtYel2wsICRJmDUvhhgl9GJ8Rb99CNcaDBbrxrSO7nal9t70Lez52dqhGdIX+X4GB50P/805/QzUn/xjzVu3lP9n7KCmrZGD3aG6Y0IfLRqcSE2HHtBtjgW46jrISyFkE295zDoU8ng8S5PTYa3rvyYM5WVHNG+sO8NzK3WzYX0JUWDCXj0nl+gl9yEyJ9fWzMMZnLNBNx1RdDQfWOj337e/BwXXO9V17w0An3DV9MusOneL5FXt44/MDlFdWMz49nusn9mHW0BTCQmwnqulcLNCNfyg54PTat73v9OIrTkBoJGScCwPPpzhtOi9tq+SFlXvZW3SCxOgwrhybxhWj0xiUEuPr6o1pFxboxv9UlDmHQW5/z+nBF+91rk8Zjg44nzURZ/Ho9jgWbiugqloZ2jOWy0encumoVJJimrdYtjH+xALd+DdVyN/ijLtvew/2rXSOd49M5FTvKawhk3kH03jrcFeCgoI5Z0Ail49JY+aQ7jbrowk4FugmsJwogp0LnZ777mVQehCAqvCu7OoynHdLM1h4oh+7wgYyc3gvLh+Tyvj0eIKC7PBH4/8s0E3gUoXiPbBnBez92PlZuB2ACgljbXV/VlYNZFeXkaSPnsrF4wbamqjGr1mgm87lWL7zTdW9K6nasxw5tJ4graJKhY2azu6oEcQOPIeRky6gW3Kqr6s1pllaFegiEgEsAcKBEGC+qv661jbhwHPAWKAQuFZVdzfUrgW6aTenSiH3U45tW0rJ1iXEF39OBOUAHApNoyJ1AinDpxGaMQm6pTdpfVVjfKW1gS5AlKoeE5FQYBlwp6qu9NjmO8AIVb1VROYAl6vqtQ21a4FufKaynF3rPyZn9fuE7l/FiOrNxMlxAMojuxOacTaSmuXM995jJITZbJCm42go0EMau7M6iX/MvRjqnmq/C1wK3O2enw/8TUREfTWeY0xDQsLIGD2VjNFTqayqZvmOfD5euZyyncsYXbqZCZuWkbLxVQBUgpCkwZA6GnqOcUI+eSiEhPn4SRjzZU0aQxeRYGA10B/4u6r+tNbtG4BZqprrXt4JnKWqBbW2mwvMBejdu/fYPXv2eOVJGOMNpWUVvLvhEK+u3c+OnByGyU7OjdrHlKh99C7bQkhZkbNhcDikDHfCvSbkEwbUuzSfMd7ktZ2iIhIHvAp8V1U3eFy/ETi/VqCPV9XC+tqyIRfTkRUcO8V7Gw/x1ucHWZlTSLUqZ8cf56up+UzsspeEoxuQg+ug3P3wGhYDPUdBz9GQOtYJ+a69bDzeeF2rhlw8qWqxiCwGZgEbPG7KBXoBuSISAnQFilpWrjG+lxgdznVn9eG6s/qcEe53boimWjPISLyQi8ckc1nacfpWbEUOrIX9a2DVo1Dl7HAlMvHMXnzP0RCd7NsnZgJaU3aKJgEVbph3Ad4Hfqeqb3psczsw3GOn6BWqek1D7VoP3fijmnB/e/1BVuwspFohIzGKi4b34MLhPRicFIbkbXLmgK8J+fwtnN7tFJngzAufNOjMn9HdrTdvmqS1R7mMAJ4FgoEg4CVVvVdE7gWyVfV199DG54HROD3zOaqa01C7FujG3zUa7j1inMU5TpU6M0keXAf5W93TZig7+kVjEXF1B31sTwt6cwb7YpExbazJ4V5DFY4ddnrv+Vu/+Jm3GU56jFaGxTjhnpzpBr0b9rFpthO2k7JAN6Yd1RfuFw5P4StDUhiR2rXheWWOFzjBXjvsj+d9sU1oFCQNdAI+cQB0y4D4vs66rRFd2/5JGp+xQDfGRwqPneK9jYd5a/0BVuYUUVWtJMeEM2Nwd2YO6c7EfglNnxHyRNEXwzU1QZ+3BY4dOnO7LvFOsHuGfLcM56eN1fs9C3RjOoAjx8tZtDWPBZsP89HWfI6XVxEZFsw5A5I4b0h3pmcmEx/Vgi8snSp11m0t2gVHdjk/i3Kc80dznamGa4RGfhHu3dKdn/F9neu69jq9cLfpuCzQjelgTlVWsWJnIR9sOsyCzYc5XHKKIIGsPvF8ZUh3zhvSnYxEL0w5UFkOR/edGfI1wX9kN1SWfbFtUIgT6jW9+thUiElxevXR3Z3zXeJt7N7HLNCN6cBUlfX7j7Jg02He33SYLYdKAeifHM15g7vzlSHdGd0rzvvzuVdXO3PJe4b86Z85Zx6FUyMo5MyAP32+O0SnfPEzOhmCQ71brwEs0I3xK/uKTrBgs9NzX5VTRGW1khgdxoxMp+c+uX8iXcLaYSWm8hPO+HzpYY+f7qn00Bc/TxTUff/IhDNDvuZnbE+n9981FaKSIMhWlWoOC3Rj/NTRkxUs3prHgs15LN6SR+mpSiJCg5jcP4mZQ7ozfXAyidE+XkO1qgKO5dUd9p4/jx2G6soz7xsUAjE9nICP7emcuqZ9EfqxqU5v30L/NAt0YwJAeWU1n+wq4oNNh1iwOY/9xScRgdG94pg2KJlpmckM7Rl75vHuHUl1tXOMfckBKNnvnI7uP/NyyYEzx/XBI/R7nhn0nuEf3b3ThL4FujEBRlXZfLCUDzYdZuGWw6zLdca7k2PCmTooiWmDkpk0IJHYCD8bx1aFk0eco3NqB73nG0DlyS/fNyTCOYonNBLCImud7+Icu+95fWgXZ6770C7udlFfbBfaxdk2Ig66dOtQh3paoBsT4PJLT7FkWz4Lt+axZFs+pWWVhAQJWendmJ6ZzLRByfRPju64vffmqAn9mqA/mgvH86H8OFScgIqT7vmTzuXT592f5Sec67+0rEM9QiK++IQQk+Jx3uNnTI92myPfAt2YTqSyqpo1e4tZtDWPRVvyTh81kxrXhWmZSUzPTGZi33basdpRqTpDOzXhXnMqP/FF+Jef+GKIqPSQc0RQyQHnZ+1hIXBm14zt8UXA1w792J5e6e1boBvTiR0oPsnirfks2prH8h0FnCivIiwkiIl9E5g2KIlpmcn0SbBl9pqs5hNC6UE35A+eGfY1P4/nf/m+weFOL/+sb8PE21v08BboxhjA+ULTJ7uKWLQln8Vb88gpcNZS7ZsU5exYHZTMuIxuhId04t67t1SWu0f51A77QzBgJoy4ukXNWqAbY+q0u+C4MzSzNZ+VOYWUV1YTFRbMpP6JnDMwiSkDEq333sFYoBtjGnWivJIVOwtZuCWPxVvz2V/sHEnSK74Lk/snMbl/IpP6JxAXaQtk+5IFujGmWVSVnILjLNtewLIdBazcWUjpqUpEYHhqVyb3T2TygETG9rHhmfZmgW6MaZXKqmrW5RazdHsBy3cUsHZvMZXVSkRoEOMzEpjiBnxmSkxgHBrZgVmgG2O8qrSsglU5RSzbUcDS7fnszHd2riZGhzGpfyKT+ycyZUASKV0jfFxp4Gko0G3yY2NMs8VEhHKeO80vwMGjJ08PzyzfUcBrnx0AnBkjJ7sBP6FfAtHhFjltyXroxhivqq5Wth4uZdn2ApbuKOCTXYWUVVQTEiSM7h3HxH6JTOybwOjecU1frcmcZkMuxhifKauoYs3eIyxzx9/X7z9KtUJYSBBjescxsW8iE/slMLJXV9vB2gQW6MaYDqOkrIJPdxWxYmchK3IK2XSwBFWICA1ibJ9uTOybwIS+CYxIiyMsxFZHqq1VgS4ivYDngBSgGnhMVf9Sa5upwGvALveqV1T13obatUA3xgAcPVHBql1OuK/YWXh67pkuocFkpXdjYj834FO7EhJsAd/anaKVwI9UdY2IxACrReQDVd1Ua7ulqnpxa4s1xnQuXSNDmTk0hZlDUwAoOl7OJ7sKT/fgf//uVgCiwoIZlxF/ugc/tGesBXwtjQa6qh4EDrrnS0VkM5AK1A50Y4xptfioMGYN68GsYT0AKDh2ilU5RazIKWDFzkIWb3UmvYoJD2F8RjwT+iYwsV8Cg3vEEuztdVf9TLPG0EUkHVgCDFPVEo/rpwIvA7nAAeDHqrqxjvvPBeYC9O7de+yePXtaUboxpjPKKyljRU4hK3OKWJlTyC53grGYiBDOcgP+rIwEhvQMzID3yk5REYkGPgJ+o6qv1LotFqhW1WMiciHwF1Ud0FB7NoZujPGGg0dPsjKnkFVuwO8uPAE4AT8+3Q34vvEM6REYQzStDnQRCQXeBN5T1T81YfvdQJaq1rMcuAW6MaZtHDpaxqpdhadDvmaK4JjwEMZlxDOhbzxnZfjvGHyrdoqKMzHDk8Dm+sJcRFKAw6qqIjIeCAIKW1GzMca0SErXCC4dlcqlo1IBOFxS5oT7LqcHv3BLHgDR4SGMS+/m9uATGOanAe+pKUe5TAJuANaLyGfudf8D9AZQ1UeBq4DbRKQSOAnMUV8d4G6MMR66x54Z8HklZafDfWVOIYvcnazR4SFkpXfjrIwEJvSNZ1hqV0L9LODti0XGmE4tr7SMT9yAX5VTxPa8Y4BzmOSYPt0Y26cbWX3iGdU7rkPMRWPfFDXGmCbKLz11OuA/3V3E1sOlqEKQQGZKLFnpTsiP7dON1Lgu7T5dsAW6Mca0UGlZBWv3FpO95whr9hxh7d4jHC+vAqB7bDhZfeIZ06cbWX26MaRnbJsP09j0ucYY00IxEaGcMzCJcwYmAc5iH1sOlbJm7xGydx9h9Z4jvLX+IODMRzMyLe50L35M727tumSf9dCNMaaVDh0tY/WeI2TvKWLNniNsPFBCZbWTrf2To8nq0+10Lz4jMapVwzQ25GKMMe3oRHkl6/YddXvxRazec4SSskrAmdrgtnP78a1z+raobRtyMcaYdhQZFsLEfs4cM+As+rEz/xjZe5whmuTY8DZ5XAt0Y4xpY0FBwoDuMQzoHsNXx/duu8dps5aNMca0Kwt0Y4wJEBboxhgTICzQjTEmQFigG2NMgLBAN8aYAGGBbowxAcIC3RhjAoTPvvovIvlAS1eJTgTqXd6uA/Knev2pVvCvev2pVvCvev2pVmhdvX1UNamuG3wW6K0hItn1zWXQEflTvf5UK/hXvf5UK/hXvf5UK7RdvTbkYowxAcIC3RhjAoS/Bvpjvi6gmfypXn+qFfyrXn+qFfyrXn+qFdqoXr8cQzfGGPNl/tpDN8YYU4sFujHGBAi/C3QRmSUiW0Vkh4j8zNf11EdEeonIIhHZLCIbReROX9fUFCISLCJrReRNX9fSEBGJE5H5IrLFfY0n+rqmhojID9y/gw0i8qKIRPi6Jk8i8pSI5InIBo/r4kXkAxHZ7v7s5ssaa9RT6x/cv4XPReRVEYnzZY2e6qrX47Yfi4iKSKI3HsuvAl1EgoG/AxcAQ4CvisgQ31ZVr0rgR6o6GJgA3N6Ba/V0J7DZ10U0wV+Ad1U1ExhJB65ZRFKB7wFZqjoMCAbm+LaqL3kGmFXrup8BH6rqAOBD93JH8AxfrvUDYJiqjgC2AT9v76Ia8AxfrhcR6QV8BdjrrQfyq0AHxgM7VDVHVcuBfwGX+rimOqnqQVVd454vxQmcVN9W1TARSQMuAp7wdS0NEZFY4BzgSQBVLVfVYt9W1agQoIuIhACRwAEf13MGVV0CFNW6+lLgWff8s8Bl7VpUPeqqVVXfV9VK9+JKIK3dC6tHPa8twJ+BnwBeOzLF3wI9FdjncTmXDh6SACKSDowGVvm2kkY9iPMHVu3rQhrRF8gHnnaHh54QkShfF1UfVd0P/BGnJ3YQOKqq7/u2qibprqoHwemgAMk+rqepvgG84+siGiIis4H9qrrOm+36W6BLHdd16OMuRSQaeBn4vqqW+Lqe+ojIxUCeqq72dS1NEAKMAR5R1dHAcTrOcMCXuGPPlwIZQE8gSkSu921VgUlEfoEz3DnP17XUR0QigV8Av/J22/4W6LlAL4/LaXSwj66eRCQUJ8znqeorvq6nEZOA2SKyG2coa7qIvODbkuqVC+Sqas0nnvk4Ad9RnQfsUtV8Va0AXgHO9nFNTXFYRHoAuD/zfFxPg0TkRuBi4Drt2F+w6Yfz5r7O/X9LA9aISEprG/a3QP8UGCAiGSIShrNj6XUf11QnERGcMd7NqvonX9fTGFX9uaqmqWo6zuu6UFU7ZC9SVQ8B+0RkkHvVDGCTD0tqzF5ggohEun8XM+jAO3E9vA7c6J6/EXjNh7U0SERmAT8FZqvqCV/X0xBVXa+qyaqa7v6/5QJj3L/rVvGrQHd3etwBvIfzD/GSqm70bVX1mgTcgNPT/cw9XejrogLId4F5IvI5MAr4rY/rqZf7SWI+sAZYj/N/16G+qi4iLwIrgEEikisitwAPAF8Rke04R2M84Msaa9RT69+AGOAD93/tUZ8W6aGeetvmsTr2JxNjjDFN5Vc9dGOMMfWzQDfGmABhgW6MMQHCAt0YYwKEBboxxgQIC3RjjAkQFujGGBMg/j8qtP8vGitH4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_e_m = TranslationDataset(train_dict[\"english\"], train_dict[\"mystery\"])\n",
    "val_ds_e_m = TranslationDataset(val_dict[\"english\"], val_dict[\"mystery\"], source_vocab=train_ds_e_m.source_vocab, target_vocab=train_ds_e_m.target_vocab)\n",
    "test_ds_e_m = TranslationDataset(test_dict[\"danish\"], test_dict[\"mystery\"], source_vocab=train_ds_e_m.source_vocab, target_vocab=train_ds_e_m.target_vocab)\n",
    "    \n",
    "train_dl_e_m = DataLoader(train_ds_e_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl_e_m = DataLoader(test_ds_e_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl_e_m = DataLoader(val_ds_e_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "\n",
    "model_e_m, losses_e_m = train(train_ds_e_m, train_dl_e_m, val_ds_e_m, val_dl_e_m)\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses_e_m).plot(title='Train and Validation Loss English to Mystery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 5.524, validation_loss 4.469\n",
      "Epoch 2, training_loss 4.298, validation_loss 3.888\n",
      "Epoch 3, training_loss 3.814, validation_loss 3.533\n",
      "Epoch 4, training_loss 3.482, validation_loss 3.287\n",
      "Epoch 5, training_loss 3.225, validation_loss 3.093\n",
      "Epoch 6, training_loss 3.013, validation_loss 2.925\n",
      "Epoch 7, training_loss 2.815, validation_loss 2.794\n",
      "Epoch 8, training_loss 2.643, validation_loss 2.660\n",
      "Epoch 9, training_loss 2.480, validation_loss 2.560\n",
      "Epoch 10, training_loss 2.333, validation_loss 2.466\n",
      "Epoch 11, training_loss 2.200, validation_loss 2.385\n",
      "Epoch 12, training_loss 2.076, validation_loss 2.312\n",
      "Epoch 13, training_loss 1.962, validation_loss 2.270\n",
      "Epoch 14, training_loss 1.859, validation_loss 2.202\n",
      "Epoch 15, training_loss 1.760, validation_loss 2.154\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb81955df50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_g_m = TranslationDataset(train_dict[\"german\"], train_dict[\"mystery\"])\n",
    "val_ds_g_m = TranslationDataset(val_dict[\"german\"], val_dict[\"mystery\"], source_vocab=train_ds_g_m.source_vocab, target_vocab=train_ds_g_m.target_vocab)\n",
    "test_ds_g_m = TranslationDataset(test_dict[\"danish\"], test_dict[\"mystery\"], source_vocab=train_ds_g_m.source_vocab, target_vocab=train_ds_g_m.target_vocab)\n",
    "    \n",
    "train_dl_g_m = DataLoader(train_ds_g_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl_g_m = DataLoader(test_ds_g_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl_g_m = DataLoader(val_ds_g_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "\n",
    "model_g_m, losses_g_m = train(train_ds_g_m, train_dl_g_m, val_ds_g_m, val_dl_g_m)\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses_g_m).plot(title='Train and Validation Loss German to Mystery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 5.523, validation_loss 4.500\n",
      "Epoch 2, training_loss 4.378, validation_loss 4.012\n",
      "Epoch 3, training_loss 3.960, validation_loss 3.706\n",
      "Epoch 4, training_loss 3.677, validation_loss 3.499\n",
      "Epoch 5, training_loss 3.471, validation_loss 3.346\n",
      "Epoch 6, training_loss 3.305, validation_loss 3.231\n",
      "Epoch 7, training_loss 3.167, validation_loss 3.137\n",
      "Epoch 8, training_loss 3.044, validation_loss 3.063\n",
      "Epoch 9, training_loss 2.933, validation_loss 2.988\n",
      "Epoch 10, training_loss 2.832, validation_loss 2.936\n",
      "Epoch 11, training_loss 2.738, validation_loss 2.886\n",
      "Epoch 12, training_loss 2.649, validation_loss 2.847\n",
      "Epoch 13, training_loss 2.568, validation_loss 2.814\n",
      "Epoch 14, training_loss 2.488, validation_loss 2.785\n",
      "Epoch 15, training_loss 2.413, validation_loss 2.767\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7f266b490>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_f_m = TranslationDataset(train_dict[\"finnish\"], train_dict[\"mystery\"])\n",
    "val_ds_f_m = TranslationDataset(val_dict[\"finnish\"], val_dict[\"mystery\"], source_vocab=train_ds_f_m.source_vocab, target_vocab=train_ds_f_m.target_vocab)\n",
    "test_ds_f_m = TranslationDataset(test_dict[\"danish\"], test_dict[\"mystery\"], source_vocab=train_ds_f_m.source_vocab, target_vocab=train_ds_f_m.target_vocab)\n",
    "    \n",
    "train_dl_f_m = DataLoader(train_ds_f_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl_f_m = DataLoader(test_ds_f_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl_f_m = DataLoader(val_ds_f_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "\n",
    "model_f_m, losses_f_m = train(train_ds_f_m, train_dl_f_m, val_ds_f_m, val_dl_f_m)\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses_f_m).plot(title='Train and Validation Loss Finnish to Mystery')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training_loss 5.543, validation_loss 4.475\n",
      "Epoch 2, training_loss 4.348, validation_loss 3.977\n",
      "Epoch 3, training_loss 3.928, validation_loss 3.670\n",
      "Epoch 4, training_loss 3.645, validation_loss 3.466\n",
      "Epoch 5, training_loss 3.436, validation_loss 3.316\n",
      "Epoch 6, training_loss 3.276, validation_loss 3.208\n",
      "Epoch 7, training_loss 3.138, validation_loss 3.115\n",
      "Epoch 8, training_loss 3.017, validation_loss 3.038\n",
      "Epoch 9, training_loss 2.907, validation_loss 2.981\n",
      "Epoch 10, training_loss 2.806, validation_loss 2.919\n",
      "Epoch 11, training_loss 2.711, validation_loss 2.880\n",
      "Epoch 12, training_loss 2.622, validation_loss 2.837\n",
      "Epoch 13, training_loss 2.537, validation_loss 2.812\n",
      "Epoch 14, training_loss 2.456, validation_loss 2.785\n",
      "Epoch 15, training_loss 2.377, validation_loss 2.767\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb823e37f90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_s_m = TranslationDataset(train_dict[\"spanish\"], train_dict[\"mystery\"])\n",
    "val_ds_s_m = TranslationDataset(val_dict[\"spanish\"], val_dict[\"mystery\"], source_vocab=train_ds_s_m.source_vocab, target_vocab=train_ds_s_m.target_vocab)\n",
    "test_ds_s_m = TranslationDataset(test_dict[\"danish\"], test_dict[\"mystery\"], source_vocab=train_ds_s_m.source_vocab, target_vocab=train_ds_s_m.target_vocab)\n",
    "    \n",
    "train_dl_s_m = DataLoader(train_ds_s_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "test_dl_s_m = DataLoader(test_ds_s_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "val_dl_s_m = DataLoader(val_ds_s_m, collate_fn=pad_collate, num_workers=0, shuffle=True, batch_size=32)\n",
    "\n",
    "model_s_m, losses_s_m = train(train_ds_s_m, train_dl_s_m, val_ds_s_m, val_dl_s_m)\n",
    "# optionally plot your losses\n",
    "pd.DataFrame(losses_s_m).plot(title='Train and Validation Loss Spanish to Mystery')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the BLEU score of all five models on the test set. The one with the highest BLEU score, often by a noticeable shot, is the underlying language of the mystery language. Report your findings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bleu score for Danish to mystery  0.3326721708345804\n"
     ]
    }
   ],
   "source": [
    "# TODO: evaluate a BLEU score for all five models to identify the mystery language!\n",
    "\n",
    "candidate_text_d_m, reference_text_d_m = translate_corpus(train_ds_d_m.target_vocab, test_dl_d_m, model_d_m)\n",
    "bleu_score_d_m = bleu_score(candidate_text_d_m, reference_text_d_m, max_n=1, weights=[1])\n",
    "print(\"This is bleu score for Danish to mystery \", bleu_score_d_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bleu score for English to Mystery  0.1031307578086853\n"
     ]
    }
   ],
   "source": [
    "candidate_text_e_m, reference_text_e_m = translate_corpus(train_ds_e_m.target_vocab, test_dl_e_m, model_e_m)\n",
    "bleu_score_e_m = bleu_score(candidate_text_e_m, reference_text_e_m, max_n=1, weights=[1])\n",
    "print(\"This is bleu score for English to Mystery \", bleu_score_e_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bleu score for German to Mystery  0.176630437374115\n"
     ]
    }
   ],
   "source": [
    "candidate_text_g_m, reference_text_g_m = translate_corpus(train_ds_g_m.target_vocab, test_dl_g_m, model_g_m)\n",
    "bleu_score_g_m = bleu_score(candidate_text_g_m, reference_text_g_m, max_n=1, weights=[1])\n",
    "print(\"This is bleu score for German to Mystery \", bleu_score_g_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bleu score for Finnish to Mystery  0.15804597735404968\n"
     ]
    }
   ],
   "source": [
    "candidate_text_f_m, reference_text_f_m = translate_corpus(train_ds_f_m.target_vocab, test_dl_f_m, model_f_m)\n",
    "bleu_score_f_m = bleu_score(candidate_text_f_m, reference_text_f_m, max_n=1, weights=[1])\n",
    "print(\"This is bleu score for Finnish to Mystery \", bleu_score_f_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/jsoldevilla/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bleu score for Spanish to Mystery  0.17547568678855896\n"
     ]
    }
   ],
   "source": [
    "candidate_text_s_m, reference_text_s_m = translate_corpus(train_ds_s_m.target_vocab, test_dl_s_m, model_s_m)\n",
    "bleu_score_s_m = bleu_score(candidate_text_s_m, reference_text_s_m, max_n=1, weights=[1])\n",
    "print(\"This is bleu score for Spanish to Mystery \", bleu_score_s_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the mystery language?: Mystery Language is Danish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_green'>\n",
    "    \n",
    "<b>3. RESEARCH [20 points]</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we build a foundation in NLP, it's also important to also see what the latest, cutting-edge work (research) looks like. It's incredibly worthwhile to learn about the types of problems people work on, their methodology and approach to the problem, the datasets they work on, the issues they raise, and the solutions they posit. The field moves incredibly fast, but the __approach__ to ML/NLP research is relatively stable -- different types of papers are accepted as the years progress, but that's a different story.\n",
    "\n",
    "We want to help you get practice reading research papers, which mostly entails thinking critically about the work, being able to discern the main takeaways/conclusions, and to reflect on the work in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.1: Read an NLP research paper [0 points]</b>\n",
    "    \n",
    "Select and read a paper that was published in ACL, NAACL, EMNLP, or COLING in 2020 or 2021. You can find a list of such published papers by searching Google (Mooogle can't help you here), a la \"ACL 2020 accepted papers\". For this assignment, you are allowed to pick either a short paper (4-5 pages) or long paper (8-9 pages), **but you must not select a workshop paper**. List below the name of the paper, authors, venue, and year published.\n",
    "\n",
    "While I highly encourage you to look at the aforementioned venues to find a paper that interests you, alternatively, you could select one of the following papers:\n",
    "\n",
    "- An LSTM-based precursor to BERT:\n",
    "> context2vec: Learning Generic Context Embedding with Bidirectional LSTM. Melamud et al. CoNLL 2016.\n",
    "\n",
    "- Clever, famous usage of Attention for NLP + Vision:\n",
    "> Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. Xu et al. ICML 2015.\n",
    "\n",
    "- Breakthrough paper that illustrated the power of seq2seq for Machine Translation:\n",
    "> Neural Machine Translation by Jointly Learning to Align and Translate. Bahdanau, Cho, and Bengio. ICLR 2015.\n",
    "\n",
    "- Another famous MT paper around the same time:\n",
    "> Sequence to Sequence Learning with Neural Networks. Sutskever, Vinyals, and Le. NIPS 2014 (now called NeurIPS).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper I chose is \"Amalgamation of protein sequence, structure and textual information for improving protein-protein ineraction identification\", Saha Sriparna and Dutta, which appeard in ACL 2020. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.2: Problem? [2 point]</b> What is the problem that it is trying to address? In other words, what is it trying to solve? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, they authors are proposing a new multi-modal dataset that isrelevatn for Protein-Protein interactions(PPI) by incorporating textual information from biomedical corpora, structural propertis of protein molecules and structuralinfromation. Additionally, the authors propose a multi-modal architecture using self attention to integrate extracted features from all the data sources. In particular, they are trying to solve the problem of having limited datasets (and types of data) for PPI tasks and proposing a new architecture to extract data from this new data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.3: Solution? [2 point]</b> At a very high-level, what was their solution? (2-3 sentences). Here, you don't have room to go into the small details (e.g., about the model), so you'll need to summarize the most important elements that comprised the solution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the lack of multi-modal datasets, the authors propose a new dataset for PPI interactions by combining text information from popular PPI benchmark corpora, namely BioInfer and HRPD50 datasets. Furthermore, they extracted data from the XML representations of the proteins (from the corpora mentioned above), additionally, they encoded (using DNNs) the genomic sequence and 3d structure of proteins from FASTA and RCSB protein data bank. Additionally, the authors proposed a new architecture to predict interaction between proteins that includes encoders with self-attention for combining the embeddings coming from textual information, from protein sequence and protein 3D structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.4: Data? [2 points]</b> What dataset(s) did they use? Are they freely available? What's the size of the data? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper proposes a new dataset which in the end is available in their GitHub repo, but the sources to biuld that dataset are public and freely available. In particular these datasets are BioInfer, HRPD50, FASTA sequence and RCSB protein Data Bank. The dataset contains at least 10,000 relations since that is the size of BioInfer and HRPD50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.5: Model [2 points]</b> Very related to the 'solutions' question, describe here any models that they used, and what made it effective (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the solution of presenting the dataset, they find relationships between 2 or mor proteins identities from the XML representation of the corpora BioInfer and HRPD50 and once they found these relationships, they also the genomic sequence of the proteins by looking at the FASTA sequence dataset and the protein structures by looking at the RCSB Protein Data Bank archive. For the network they are proposing, they propose to do feature extraction from the proposed corpora taking text that describe the relationship between the identified proteins by using a BioBERT model to provide vector representation for the textprovided as input and after use a Bidirectional LSTM to encode the embedded representation coming out from BERT and get a vector representation. Afterwards, they extract the sequence features by applying a DNN to the vector of one-hot vector representation of the nucleotides in the protein and finally extracted the structural feature by applying Graph CNN's. Finally, they combine all the extracted features using attention mechanisms and finally passing the result to a softmax layer for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.6: Results? [2 points]</b> What are their main results? (~2 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main results of the paper come from the evaluation of the dataset using the proposed architecture. In particular, they find out that the proposed architecture surpasses all the baselines and SOTA results when predicting interaction between proteins, in particular, they get better Recall, Precision and F-score results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.7: Strengths? [2 points]</b> List 2-3 strengths of the paper\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The proposed datasets is multi-modal, so it combines textual iformation with sequence features and 3D structure data for the proteins. This could give us a richer set of features for classification.\n",
    "- The proposed network seems simple but it gives the best results for Precision, Recall and F-score, surpassing SOTA results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.8: Weaknesses? [2 points]</b> Although you may be new to this problem and all of its content, try to list 2-3 weaknesses of the paper (anything that you think could strengthen the paper is sufficient).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The training dataset seems rather small. Perhaps future work could focuse on expanding the corpora used for finding the probable protein interactions.\n",
    "- While the methods for feaure extraction of the different types of data make sense, there is no deeper analysis on why using the attention mechanism. It would have been interesting to compare results on how to combine these features: using attention mechanism, self-attention, just concatenating and see data on why one is better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.9: Evaluation [2 points]</b>\n",
    "    \n",
    "How would you evaluate this paper in terms of:\n",
    "- scientific contribution\n",
    "- effectiveness to solve the problem\n",
    "- how convincing it was.\n",
    "    \n",
    "Give each of these elements a score from 1-10 (10 is best). No word explanation necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scientific contribution: 8\n",
    "- Effectiveness to solve the problem: 9\n",
    "- How convincing it was: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>3.10: Research Ideas [4 points]</b>\n",
    "    \n",
    "Think of 1-2 research ideas that you have based on this paper. It doesn't have to be grand; most research is very incremental. Specifically, your research idea should have a concrete question that you're aiming to answer. List it below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As suggested in the weaknesses of the paper, I think it could be interested to expand the dataset size by using more corpora to generate the multi-modal data and furthermore, to explore different ways to combine the extracted features, not only attention mechanism but also self-attention or simple concatenation. In particular, I would like to answer the questions: 1) Does having a much larger dataset increases the gap between the metric baseline and SOTA? 2) How does changing the extracted feature combination method change the results we see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_green'><b>BONUS POINTS [5 points]</b> I mention the full details in the syllabus on the course website. However, in short, these bonus points cannot bring one's grade to exceed 100. That is, if someone received a 97 on this homework, doing this bonus could allow their grade to reach 100 points. If the person had an 83 on the homework, then the most they could achieve is an 88.\n",
    "    \n",
    "The task: read another research paper (allowed to be a Short Paper) and answer the same questions again. Please copy and paste all of the questions below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1: Paper I read:\n",
    "\n",
    "For this second paper I read \"Show, attend and tell: Neural Image Caption Generation with Visual Attention\" by Xu, et.al. and was suggested by the professor.\n",
    "\n",
    "\n",
    "3.2: Problem? [2 point] What is the problem that it is trying to address? In other words, what is it trying to solve? (2-3 sentences)\n",
    "\n",
    "The authors are trying to provide a new way to desscribe the contents of an image using trainable neural networks. In particular, they want to train a model that generates a short description of a presented image.\n",
    "\n",
    "3.3: Solution? [2 point] At a very high-level, what was their solution? (2-3 sentences). Here, you don't have room to go into the small details (e.g., about the model), so you'll need to summarize the most important elements that comprised the solution.\n",
    "\n",
    "In a very high level, the authors are proposing a network that will use a CNN to extract features from a given image by taking some of the initial layers to extract certain pieces of the network. Then, they pass these features through an LSTM which will be predicting the context vector, that is computed from attention weights and a collection of annotation vectors that correspond to features extracted at different image locations. Finally the context vectors are used to predict the next word. The paper proposes two ways of computing the context vectors, one which is stoachastic and one dterministic.\n",
    "\n",
    "\n",
    "3.4: Data? [2 points] What dataset(s) did they use? Are they freely available? What's the size of the data? (2-3 sentences)\n",
    "\n",
    "The authors used the dataset Flickr8k and Flickr30k which each have 8000 and 30000 images respectively as well as the Microsoft COCO dataset with 82783 images.They are freely available datasets.\n",
    "\n",
    "3.5: Model [2 points] Very related to the 'solutions' question, describe here any models that they used, and what made it effective (2-3 sentences)\n",
    "\n",
    "In gneral, the authors proposed a section to use a CNN to extract features from the input image and used features from the initial layers to get simpler features from the image. Then, these features were input for an LSTM. One of the features of the LSTM is a context vector that is computed with attention weights and certain annotation vectors $a$ that come from the features extracted from the CNN. In the proposed solution, the computation of the context vector could be stochastic (soft-attentiont) or deterministic (hard-attention).\n",
    "\n",
    "3.6: Results? [2 points] What are their main results? (~2 sentences)\n",
    "\n",
    "The authors showed that they produce SOTA BLEU score inall the different datasets using the hard-attention mechanism and almost SOTA results using the METEOR score. \n",
    "\n",
    "3.7: Strengths? [2 points] List 2-3 strengths of the paper\n",
    "\n",
    "- I think the method proposed is simple enough and the paper provides enough intuition as to what choices of methods were made. \n",
    "- I think the paper makes a great job of providing intuition as to what the model is actually looking at in terms of features in the picture to generate the proposed text.\n",
    "\n",
    "\n",
    "3.8: Weaknesses? [2 points] Although you may be new to this problem and all of its content, try to list 2-3 weaknesses \n",
    "\n",
    "- There were discrepancies in the results of the soft-attention and hard-attention networks. I think it would have been interesting to dig a bit deeper into the reason for difference in results.\n",
    "- From the pictures they showed of where the model was paying attention, it would have been interesting on plotting a few of the first layers to see if there was a clearer choice of what layer to choose or maybe combine several layers of the CNN for generating input features for the LSTM.\n",
    "\n",
    "3.9: Evaluation [2 points]\n",
    "How would you evaluate this paper in terms of:\n",
    "\n",
    "scientific contribution\n",
    "effectiveness to solve the problem\n",
    "how convincing it was.\n",
    "Give each of these elements a score from 1-10 (10 is best). No word explanation necessary.\n",
    "\n",
    "- Scientific contribution: 10\n",
    "- Effectiveness to solve the problem: 9\n",
    "- How convincing it was: 9\n",
    "\n",
    "\n",
    "3.10: Research Ideas [4 points]\n",
    "Think of 1-2 research ideas that you have based on this paper. It doesn't have to be grand; most research is very incremental. Specifically, your research idea should have a concrete question that you're aiming to answer. List it below.\n",
    "\n",
    "- It could be interesting to measure the power of more sophisticated encoder-decoder architctures (transformers/BERT) in the image captioning task. In particular, I would like to answer the question: Can we increase the SOTA performance in the image captioning task by using transformers in my architecture.\n",
    "- I think it could be interesting to see if we can use NLP architectures to do the opposite task. Take strings/captions and generate an image that represents that text. IN particular, I would like to answer the question: Can we use NLP and CV architectures to generate images based from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='header_blue'>\n",
    "    \n",
    "# 4. SELF-REFLECTION [0 points]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='q_blue'><b>4.1: Self-reflection and Feedback [0 points]</b>\n",
    "\n",
    "Are you thriving in the course? Are there elements that are particularly confusing to you? I want everyone to be and feel fully supported. Toward this, I strongly urge you all to think critically about your own learning and efforts. Please provide us with feedback about how you're doing in the course and if there's anything further or different we can do to better assist your learning. I want everyone to give their earnest account, so the form is completely anonymous.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Anonymous Self-Reflection and Feedback Form](https://forms.gle/3LT6UfhtCtqp2G7X9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "interpreter": {
   "hash": "0d3e0cb9dfa8cf737dbf538b02aa0665a58b73e014f15f8af0ea4296e4e6b732"
  },
  "kernel_loop": {
   "byte_size": "82791"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
