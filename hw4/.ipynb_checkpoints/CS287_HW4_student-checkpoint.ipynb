{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "\n",
       "hr {\n",
       "    height: 1px;\n",
       "    background-color: black;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "div.quote {\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12px;\n",
       "\talign-items: center;\n",
       "\tmax-width: 80%;\n",
       "\ttext-align: center;\n",
       "}\n",
       "\n",
       "div.header_mint {\n",
       "\tbackground-color: #BEFFD1;\n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_mint {\n",
       "\tbackground-color: #BEFFD1;\n",
       "\tborder-color: #38D266;\n",
       "\tborder-left: 5px solid #38D266; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "div.header_purple {\n",
       "\tbackground-color: #D0C7FF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_purple {\n",
       "\tbackground-color: #D0C7FF;\n",
       "\tborder-color: #9183D9;\n",
       "\tborder-left: 5px solid #9183D9; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_teagreen {\n",
       "\tbackground-color: #DEEFB7; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_teagreen {\n",
       "\tbackground-color: #CFFBFF;\n",
       "\tborder-color: #5FB49C;\n",
       "\tborder-left: 5px solid #5FB49C; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_lightcyan {\n",
       "\tbackground-color: #CFFBFF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_lightcyan {\n",
       "\tbackground-color: #9bf6ff;\n",
       "\tborder-color: #3D767B;\n",
       "\tborder-left: 5px solid #3D767B; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_aquagreen {\n",
       "\tbackground-color: #AACFC4; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_aquagreen {\n",
       "\tbackground-color: #AACFC4;\n",
       "\tborder-color: #5F758E;\n",
       "\tborder-left: 5px solid #5F758E; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_lightpurp {\n",
       "\tbackground-color: #CBC5EA; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "\n",
       "div.q_lightpurp {\n",
       "\tbackground-color: #CBC5EA;\n",
       "\tborder-color: #73628A;\n",
       "\tborder-left: 5px solid #73628A; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_silver {\n",
       "\tbackground-color: #707078; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_silver {\n",
       "\tbackground-color: #707078;\n",
       "\tborder-color: #090909;\n",
       "\tborder-left: 5px solid #090909; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_pink {\n",
       "\tbackground-color: #FFC8C8;\n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_pink {\n",
       "\tbackground-color: #FFC8C8;\n",
       "\tborder-color: #FF8484;\n",
       "\tborder-left: 5px solid #FF8484; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_yellow {\n",
       "\tbackground-color: #FDFFB6; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_yellow {\n",
       "\tbackground-color: #FDFFD0;\n",
       "\tborder-color: #FFD6A5;\n",
       "\tborder-left: 5px solid #FFD6A5; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_orange {\n",
       "\tbackground-color: #FFD6A5; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_orange {\n",
       "\tbackground-color: #FFD6A5;\n",
       "\tborder-color: #D6562C;\n",
       "\tborder-left: 5px solid #D6562C; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.header_green {\n",
       "\tbackground-color: #CAFFBF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_green {\n",
       "\tbackground-color: #CAFFBF;\n",
       "\tborder-color: #98C98E;\n",
       "\tborder-left: 5px solid #98C98E; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "div.header_blue {\n",
       "\tbackground-color: #C9FAFF; \n",
       "\twidth: 100%;\n",
       "\tbox-shadow: 5px 5px 10px 2px #888;\n",
       "\tfont-size: 15px;\n",
       "\tpadding-top: 8px;\n",
       "\tpadding-left: 20px;\n",
       "\tpadding-right: 20px; \n",
       "\tpadding-bottom: 20px;\n",
       "}\n",
       "\n",
       "div.q_blue {\n",
       "\tbackground-color: #C9FAFF;\n",
       "\tborder-color: #A0C4FF;\n",
       "\tborder-left: 5px solid #A0C4FF; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "h1 {\n",
       "    text-align: left; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "h2 { \n",
       "    text-align: left; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# RUN THIS CELL\n",
    "################################\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"style.css\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_mint'>\n",
    "\n",
    "# <img style=\"float: left; padding-right: 10px; width: 60px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> AC295/CS287/E-115B: Deep Learning for NLP\n",
    "\n",
    "<br/>\n",
    "<hr color=black>\n",
    "\n",
    "## Homework 4: Great Party Trick - Second Edition\n",
    "### THE MINT BOOK\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2021**<br/>\n",
    "**Instructor**: Chris Tanner<br/>\n",
    "**Release Date**: Oct 19 (Tues) @ 11:59pm<br/>\n",
    "<font color=\"red\">**Due Date**: Nov 2 (Tues) @ 11:59pm</font>\n",
    "\n",
    "<hr color=black>\n",
    "<center>\n",
    "<div class='quote'>\n",
    "\n",
    "_\"The goal will be to make this one short.\"_\n",
    "\n",
    "    Chris Tanner (October 17, 2021)\n",
    "</div>\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "Om7RMzm7G5gn",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_mint'>\n",
    "    \n",
    "# LEARNING OBJECTIVES\n",
    "\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "The purpose of this homework is to help you:\n",
    "\n",
    "- think critically about serious ethical issues\n",
    "- gain practical experience using Transformers for generation\n",
    "- understand the power and shortcomings of GPT-2\n",
    "- become more comfortable reading research papers\n",
    "\n",
    "To assist you reach these learning objectives, this homework is structured into three parts:\n",
    "- <span style=\"background-color: #FDFFB6\"><b>Foundation (concepts):</b></span> demonstrate an understanding of the core concepts taught in lectures\n",
    "- <span style=\"background-color: #FFC8C8\"><b>Application (programming):</b></span> gain experience putting that knowledge into practice \n",
    "- <span style=\"background-color: #CAFFBF\"><b>Research (creating new knowledge):</b></span> use your current NLP knowledge and skills to go beyond the course material, to grasp cutting-edge results and to critically accept or challenge that information. This serves as practice for you to research your own NLP interests and to be well-equipped to continuously learn the latest, greatest NLP work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "3drb-dhOG5go",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_mint'>\n",
    "    \n",
    "## SUPPORT\n",
    "\n",
    "</div>\n",
    "\n",
    "- **Supplemental Resources:** See the list of [supplemental resources](https://harvard-iacs.github.io/CS287/supplemental) for a wealth of rich information concerning Machine Learning, NLP, and Math. Some of the courses listed concern the exact topics covered in this homework and lectures.\n",
    "- **Sanity Check cells:** We provide several 'sanity check' cells which allow you to see our expected outputs. You should ensure your code produces the same. <span style=\"background-color: #FDFFB6\"><b>**NOTE:** We are not claiming that passing the sanity check cells indicates that you have _fully_ implemented everything correctly; rather, they provide simple checks to help inform you if you are on the right track.</span>\n",
    "- **Ed**: If you are stuck on anything conceptual (not code) about the content from lectures, please post a question on Ed. This is your community, and please contribute and help each other out. If your questions concern the homework, you can post these on Ed, too, but make sure you are not posting any of your code or solutions in general. If you think you've spotted a bug in our homework questions, or something that needs clarifying, please let us know on Ed! We want to correct these issues ASAP.\n",
    "- **OH:** After having given a wholehearted attempt, if you are having trouble with the homework, please come to Office Hours.\n",
    "- **Classmates:** We have a strict policy about the homeworks being individual. You are free to discuss _concepts_ with one another, to help each other learn the material. However, no student shall ever discuss their solutions or see another student's solutions to any problem. Once you see someone's coding solution, it's nearly impossible to harness that information in a way that you can write your own unique solution. You've been robbed of a learning opportunity and will likely just regurgitate someone else's work. As a reminder, if you want to take a shortcut on any problem by looking online for already-existing solutions, that's permissible, but you must cite your sources. Otherwise, it constitutes cheating. Posting any pieces of this homework online for others to see if a flagrant violation of our academic policy.\n",
    "- **Other:** I want everyone to be and feel fully supported. If there's anything else we, as a teaching staff, can do to further assist in your learning, please let us know. Related, at the end of this homework assignment, you are expected to complete an anonymous feedback form. I urge you to critically and earnestly think about your own learning, communicate to us your thoughts, and to optionally tell us possible adjustments we could make so that you meet our learning expectations and you achieve your own learning goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "jhL5ardpG5gp",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_purple'>\n",
    "    \n",
    "# 1. FOUNDATION (CONCEPTS) [8 points]\n",
    "\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "91_Vwp4SG5gq",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_purple'><b>1.1 Debiasing [2 points]</b>\n",
    "\n",
    "In Lecture 13, Ellie Lasater-Guttmann gave a lecture on biased embeddings, where we mostly discussed type-based word embeddings. At the end, she mentioned that contextualized word representations (aka token-based embeddings) are not immune, as they can lead to undesirable consequences, too. In general, which do you think would be harder to debias, contextualized word representations (i.e., token-based) or word embeddings (i.e., type-based)? Explain your reasoning in 3-5 sentences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "AVWC1p9lG5gq",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "91_Vwp4SG5gq",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_purple'><b>1.2 Responsibility [6 points]</b>\n",
    "\n",
    "Large language models (LLMs) like BERT and GPT-2 are usually developed by big software companies who have the computational resources and interest to create such. Keep in mind that LLMs will continue to be developed by a myriad of companies for the foreseeable future (for decades, I'd guess), so this is not a dig at the creators of BERT (Google) or GPT-2 (OpenAI). Let's say you've just graduated from Harvard and are working for a company named Transparent AI (I'm making up this name, so if such a company exists, it's not intentional). You are on a team of 50 people who work on building a LLM, and your specific job is to make an aspect of the model more parallelizable and computationally efficient.\n",
    "\n",
    "**Q1 (3 points)**: Do you feel you have any responsibility to help ensure the model's predictions are equitable and as bias-free as possible? If so, then what are possible actions you should/would take? To be clear, this question isn't asking what technical aspects you would add to the model; it's asking what human-level actions you would take, such as speaking with others, volunteering to do extra engineering work, etc. Please discuss with a minimum of 3 sentences.\n",
    "\n",
    "**Q2 (3 points)**: The company is large and very hierarchical. Everyone has quarterly expectations, a manager to appease, yet a finite amount of time and personal lives and hobbies outside of work. Where should responsibility lie in addressing these issues? Meaning, who all should be accountable? Please discuss with a minimum of 3 sentences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "AVWC1p9lG5gq",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "JG-wtTycG5gs",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_pink'>\n",
    "    \n",
    "# 2. APPLICATION (PROGRAMMING) [60 points]\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "# Fine-Tuning GPT2 for Song Lyric Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "W2xDryYs0Ou3",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You've made it to the last programming part! We promise this one will be short(ish).\n",
    "\n",
    "In this section, we'll experiment with OpenAI's GPT2 model in a song lyric generation task. Like BERT, GPT2 is a *large language model* (LLM), and has\n",
    "achieved historically stunning results on a wide variety of NLP tasks.\n",
    "As in the last homework, because training GPT2 from scratch is \n",
    "infeasible on your laptop, we will borrow the pretrained GPT2 weights published on [HuggingFace](https://huggingface.co/transformers/model_doc/gpt2.html) and finetune them for our downstream task.\n",
    "\n",
    "You will:\n",
    "1. Pick your favorite artists (either from our provided dataset, or feel free to bring your own!)\n",
    "2. Finetune GPT2 on your artists' lyrics\n",
    "3. Generate novel lyrics\n",
    "\n",
    "As before, *we strongly recommend you use Colab for this assignment*. Unless you're one of the lucky few who've managed to snag an RTX 3080 amidst this silicon shortage (or have a similarly beefy GPU on hand), **you will not be able to run this notebook on your local machine.**\n",
    "\n",
    "**DISCLAIMER**: We offer the dataset of lyrics on an as-is basis for pedagogical purposes. We do not support, condone, or affiliate with any problematic messages potentially embedded in this dataset. To view the original source, see [here](https://www.kaggle.com/deepshah16/song-lyrics-dataset).\n",
    "\n",
    "*A side note*: you've probably heard of [GPT3](https://en.wikipedia.org/wiki/GPT-3), OpenAI's successor to GPT2. So why aren't we using GPT3? For a couple reasons:\n",
    "* The model is ginourmous. It's an order of magnitude *bigger* than GPT2. As you will soon see, Colab's GPUs can barely handle the *smallest* GPT2 model. If we gave you GPT3, we'd need a dedicated datacenter just for this class.\n",
    "* The model is **closed source**. In a rather controversial move, OpenAI awarded Microsoft [exclusive access](https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-model/) to the model. Researchers can still use a public API to query to the model, but only Microsoft has access to the weights directly.\n",
    "\n",
    "In the past, OpenAI has cited social concerns around releasing GPT3 openly to the public, claiming that GPT3-generated text can be difficult to distinguish from human-authored text. Malicious individuals could, for example, use it to generate large quantities of fake news. Hence, even prior to the Microsoft deal, OpenAI has never openly released the training weights.\n",
    "\n",
    "All that's to say, we won't be able to use GPT3 in the assignment. But if you're curious to learn more, do check out [the original paper](https://arxiv.org/abs/2005.14165). Also, if you're a fan of text-based dungeon crawlers, take a look at [AI Dungeon](https://play.aidungeon.io/main/home), which uses GPT3 to drive their\n",
    "\"Dragon AI\" (the free tier uses GPT2).\n",
    "\n",
    "All right, enough chat, let's dive in! (after a brief warning message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "lXlbi0REBZbk",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**WARNING**: GPT2 is *huge*. We will use the smallest model in the GPT2 family, but even so, it will stretch Colab to breaking. More so than in previous homeworks, we will have to pay attention to memory usage. For tips on writing\n",
    "memory-efficient PyTorch code, check out their [FAQ](https://pytorch.org/docs/stable/notes/faq.html) and their blerb on [memory management](https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-management).\n",
    "\n",
    "Some tools that may come in handy for debugging memory issues:\n",
    "* [torch.cuda.memory_allocated()](https://pytorch.org/docs/stable/generated/torch.cuda.memory_allocated.html#torch.cuda.memory_allocated)\n",
    "* [torch.cuda.max_memory_allocated()](https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html)\n",
    "* [gc.collect()](https://docs.python.org/3/library/gc.html)\n",
    "* [torch.cuda.empty_cache()](https://pytorch.org/docs/stable/generated/torch.cuda.empty_cache.html)\n",
    "\n",
    "You can find the size (in bytes) of any tensor using\n",
    "```python\n",
    "t = make_huge_pytorch_tensor()\n",
    "bytes_per_element = t.element_size()\n",
    "total_elements = t.nelement()\n",
    "\n",
    "total_size = bytes_per_element * total_elements\n",
    "```\n",
    "\n",
    "One final note, whenever a cell fails to execute, temporary variables declared\n",
    "in that cell may not always be deleted by Python. To handle a memory leak, you can try to force a garbage collection cycle and release any cached GPU memory:\n",
    "\n",
    "```python\n",
    "import gc  # Python's garbage collection interface\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "However, any variables still in reference somewhere in the notebook will not be\n",
    "garbage-collected. The easist way to refresh the entire slate is to just\n",
    "restart your kernel and run everything from the top.\n",
    "\n",
    "**The important takeaway**: If you get an error that looks like\n",
    "\n",
    "```\n",
    "RuntimeError: CUDA out of memory\n",
    "```\n",
    "The easiest (sometimes only) way out of this is to restart the whole notebook and run it from the top. **Simply rerunning your cells without restarting will probably give you another memory error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "8MTbztBUKeNh",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_pink'>\n",
    "\n",
    "## Setting up\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "fqi5PL4iKh1g",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "As in the previous homework, let's install tranformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "N8KSS0KyyCDX",
    "new_sheet": false,
    "outputId": "d280e530-9e73-4380-b33a-58c97b1d09de",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "rqrHjjIUKrsW",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-check Colab has allocated a GPU for you. If not, remember to select from the top bar `Runtime --> Change runtime type` and set `Hardware Acceleration` to\n",
    "`GPU`. Then run the following cell to print out diagnostic info about your GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i767xxThLG1z",
    "new_sheet": false,
    "outputId": "be7dcdc5-4c4b-442a-f484-9bad69619002",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 17 18:20:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "z6gxnsvZLj8y",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here are some suggested imports for you to use. Feel free to add any additional you would like! (as long as they don't trivialize the assignment, of course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "id": "tq8TXyJwrSCf",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2TokenizerFast, GPT2Model, get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "neXglk0MLtC8",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Because you may need to restart and rerun your notebook many times as you deal with memory issues, you may want to keep your data files on Google drive rather than in Colab's local storage. The local storage is cleared every time Colab allocates a new compute instance for you. To learn more about connecting to Drive, see [this example notebook](https://colab.research.google.com/notebooks/io.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "MH_sLgSiNJhj",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_pink'>\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "GM74jUUiMlEk",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.1 Assemble the data [3 points]</b>\n",
    "    \n",
    "We've pre-processed a lyrics dataset for you. It contains 3 columns: the artist, title, and lyrics. Every artist in the dataset has at least 100 unique songs, and there are 12 unique artists represented. \n",
    "\n",
    "For the sake of training speed, we encourage you to choose 4 artists of the 12 to use. Then, from the data, create a series of prompts for GPT-2 by creating a single string per song. Each string should contain, in the following order:\n",
    "- An `<|endoftext|>` token \n",
    "- The tokens `song artist:`\n",
    "- The name of the artist\n",
    "- The tokens `song title:`\n",
    "- The title of the song\n",
    "- The tokens `song lyrics`:\n",
    "- The lyrics of the song\n",
    "- An `<|endoftext|>` token \n",
    "\n",
    "This is so that we can use this formatting as a prompt for GPT-2 to generate titles and lyrics later, conditioned on artist.\n",
    "\n",
    "Then, split your dataset into a train and validation set. We recommend using 80-90% for training.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "id": "FmAOAMx7aTl_",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Read in, process, and split your data below\n",
    "\n",
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "nnZ0CLIUNUbW",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.2 Make a SongLyrics Dataset [3 points]</b>\n",
    "\n",
    "Using your split  data, prepare a SongLyrics dataset to use for training.\n",
    "\n",
    "It's up to you how you'd like to structure your dataset, as long as it works with your model and training code further down. Some suggestions:\n",
    "* Use [GPT2TokenizerFast](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2tokenizerfast), a speedier variant of the tokenizer, written in Rust\n",
    "* `GPT2TokenizerFast.from_pretrained('gpt2')` will load the GPT2 (small version) weights from HuggingFace. The [docs for the parent class `PreTrainedTokenizer`](https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html#pretrainedtokenizer) may also be helpful. \n",
    "* By default GPT2 does not include padding tokens. For reasons that will soon be clear, we won't really need them in either in this assignment, but if you'd like, feel free to add your own padding token with `tokenizer.add_special_tokens()`\n",
    "* When tokenizing, ensure that your examples are shorter than the max sequence\n",
    "length accepted by GPT2 (1024 tokens). An easy way to assure this is to set `truncation=True` when calling your tokenizer. See [the docs](https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase) for a full and exhaustive list of all the useful customizations you can try\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "id": "fvLesPNiG9vH",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class SongLyrics(Dataset):\n",
    "    def __init__(self, data: List[str]):\n",
    "        raise NotImplementedError   # TODO: implement        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError   # TODO: implement        pass\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        raise NotImplementedError   # TODO: implement        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "5jL35FzxP6iV",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.3 Dataloaders [2 points]</b>\n",
    "\n",
    "Make new dataloaders out of your dataset. For the dataloader, you may find the option `pin_memory=True` to be helpful, as it caches tensors in GPU memory for quicker access. See [this thread](https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723) for details.\n",
    "\n",
    "**VERY IMPORTANT**: On both of your dataloaders, set `batch_size=1`. Any larger of a batch_size and **you will run into memory issues**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "e5b7f68fb3774b61b3ee0d53d5887902",
      "8204ec53bdaf4d5aafe454fb2b214d1c",
      "a6f8e12c178447d9aa68606de34c70d5",
      "39a661f1a36d4ff5864488a94ccc8276",
      "30eb7e8a7e044d568f806a00529c0a3c",
      "025e01116824455e8b70c4dca85f2f24",
      "296fe0aeaf234eb3a7afbb5c92cfd5f4",
      "5e41604eb8c14c63aafacfe70e34b4f9",
      "6709f10fbf724a2e8ab1e4b5fea05ad2",
      "18db0f741d7c4a44bda84f8831ecca45",
      "0d56cebb76e645cdb7a3a1cbe1b84e1d",
      "1c729acbeff441cc987701bf3e2409a1",
      "b38d18b2fbec450186b44e1dc0a52e28",
      "01b2878c7fc3474cb814054b752715ad",
      "9d94c8d28cc2473bb3c1987bc9c5a189",
      "0389cfa273704b78b9b03be0701e2a66",
      "b1fa862825e84bfc922fff8b8b8878c4",
      "69f0e7a209104fa1a84544fbe2a275de",
      "7f70fe6e28044efc9b92471d9c992ce9",
      "16f9dd84a9af4c54b0555589b695e66c",
      "1096730759ed46f9919f5f14c8abcf9f",
      "55d07adfe752463fbee3f67b19f4ff15",
      "bb5f17900b0141219d24142d0b447e08",
      "23f13728922c4be393f44555005b3612",
      "a5c7fabe1d8347689d09f34a7081d25a",
      "7d2de255bab3493b996d90602ef9de3e",
      "7da403c9d944495caa3c6c9457b99915",
      "51280023210a4286b6d66c008da63e9a",
      "4a5f484f29954b07836871bf0372e0ca",
      "e7408553cb6c41c28675b52758552ff2",
      "50c464ba6ef14a6290d0a1f3d97e28a1",
      "3288849322c94113be1cff4bd74f6c4a",
      "661a7e842cc44d9e8d7ee5c298e14bfc",
      "8edc5fb7172d47daab9127e8a5f8bf6b",
      "a12d9b62092a46979105216fa97a1aa9",
      "5af686e54f63414fba6a2fca10db7a23",
      "2fb82b05c6824b5f93210830366fd7e2",
      "295b4203047c45c49f26efb057f9605b",
      "446bca6140d84ef2a3879816dcc07e70",
      "4813cac23d8d4fbe83a95c859212fe79",
      "f33881a0e77246a6b85055b2313096a4",
      "c42869b9fc6b446eae63ec0b3050d2ee",
      "1ca0e30c7ae44981bcbba52f31234b6e",
      "913243f2301f4adaa9fe16095d2bd736"
     ]
    },
    "collapsed": true,
    "id": "82mqff4hHj_7",
    "new_sheet": false,
    "outputId": "d818e1bb-e6ba-4471-8be0-fac769ff34d3",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_dl = None\n",
    "test_dl = None\n",
    "\n",
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "dtawwd_gQeYV",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_pink'>\n",
    "\n",
    "## Model and training\n",
    "\n",
    "</div>\n",
    "\n",
    "To access the GPT2 weights, we will use HuggingFace's GPT2Model class. Please take a moment to familiarize yourself with the class's [API](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2model), especially the `forward()` method and its return type.\n",
    "\n",
    "We can instantiate a GPT2Model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fd2109a3918e4788a3c6a8be3e5d8c7b",
      "ba3cc33f63ed41a989f2b08ed0234f65",
      "fc297b28bc46492285d9b401f5a51598",
      "4d70d58468ce4f8dbb739b50a98efbe1",
      "f9543fa001364b8292cabf19a7dd3cd6",
      "63d752c17c2a4bf79278c228ee41a808",
      "6b555668b43d4544b1eb74d24a671969",
      "135210d23cff4d6da47cfdf0953ed15d",
      "3430e14e44a047239366a8fc53647998",
      "5252abd87f184ccb9fb8cd90a80cc65a",
      "1c8f4786c3f748ac92f3bfc1b56784e1"
     ]
    },
    "collapsed": true,
    "id": "jeyCGXkOzQaV",
    "new_sheet": false,
    "outputId": "03cf62ba-728a-4f7a-81c0-37ecf01d2c5b",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "AYekuVZazbiH",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This gives you a PyTorch module that you can use just like any other. To feed an input through the model, simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "id": "RwOjx9x7zlQv",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "example = next(iter(train_dl))\n",
    "output = model(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "lYfRwXNW0YW7",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We can inspect the shape of our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6bhbA_LNoNmd",
    "new_sheet": false,
    "outputId": "151b29f2-57ab-4772-a2bd-ba2459adbe5c",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(example.shape)\n",
    "print(output[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "beAKdmsi0bjG",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "What do you think each of those dimensions corresponds to? (a rhetorical question, no need to type an answer here! But please do think about this before reading on)\n",
    "\n",
    "```\n",
    " _________________________________________\n",
    "( Hmmm... what do those dimensions means? )\n",
    " -----------------------------------------\n",
    "        o   ^__^\n",
    "         o  (oo)\\_______\n",
    "            (__)\\       )\\/\\\n",
    "                ||----w |\n",
    "                ||     ||\n",
    "```\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "All right so the dimensions are\n",
    "\n",
    "$$ B \\times N \\times H$$\n",
    "where:\n",
    "* $B$ is batch size\n",
    "* $N$ is sequence length\n",
    "* $H$ is hidden size\n",
    "\n",
    "As the documentation indicates, `last_hidden_state` corresponds to the output of the final decoder block in GPT2, constructing an embedded representation of each of the $N$ inputs. Each embedded representation is a vector of length $H$. The (small) GPT2 model uses $H = 768$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "\n",
    "<div class='q_pink'><b>2.4 GPT2 Language Model [16 points]</b>\n",
    "\n",
    "Below, you will find skeleton code outlining the shape of a GPT2 language model. Using the base GPT2Model class, we will construct on top a language model head that predicts the next word after the current input. For example, suppose our sentence is:\n",
    "\n",
    "```\n",
    "The quick brown fox jumps over the lazy\n",
    "```\n",
    "\n",
    "From this sentence, the GPT2Model constructs a sequence of 8 embeddings\n",
    "\n",
    "$$ h_1, h_2, ..., h_8$$\n",
    "where\n",
    "\n",
    "$$ h_1  = f(The)$$\n",
    "$$ h_2 = f(The\\; quick)$$\n",
    "$$ h_3 = f(The\\; quick\\; brown)$$\n",
    "\n",
    "That's to say, the $i$th embedding is constructed as a function over the previous $i$ inputs. Then given the embedding $h_i$, we'd like to predict the $i+1$st word. So our end output should be 8 words\n",
    "\n",
    "$$ w_1, w_2, w_3, ..., w_8$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ w_1 = g(h_1)$$\n",
    "$$ w_2 = g(h_2)$$\n",
    "$$ w_3 = g(h_3)$$\n",
    "\n",
    "And ideally, after training we should have that \n",
    "\n",
    "$$w_1 \\approx quick$$\n",
    "$$w_2 \\approx brown$$\n",
    "$$w_3 \\approx fox$$\n",
    "\n",
    "All the way until $w_8 \\approx dog$ (or whatever mammal the fox was feeling like jumping over today).\n",
    "\n",
    "So to recap, we have the weights from the base model GPT2Model, which produces a hidden vector for each token in the input sequence. Our goal is to use GPT2Model to build a language model that achieves the above prediction task. The only component missing is some way to transform the GPT2 embeddings into predicted words, then use a loss function to compare the predictions to the actual next words. As in HW2, pay close attention to the alignments between input words and predicted words, so as to ensure that your model isn't simply predicting the next word.\n",
    "\n",
    "**CAUTION:** While you have the freedom to design this as you'd like, take the easy route and be frugal where you can! Your sequence length can be up to 1024 tokens, and the vocabulary size is over 50,000. Even though we're using a batch size of only 1, keep in mind the sheer size (in MB) of the tensors at play, not to mention the gradients PyTorch is saving along the way!\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "id": "72A542YbucPV",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class GPT2LanguageModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 768 # parameters fixed by GPT2\n",
    "\n",
    "raise NotImplementedError   # TODO: implement        pass\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        raise NotImplementedError   # TODO: implement        pass\n",
    "    \n",
    "\n",
    "def compute_loss(preds, target_ids):\n",
    "    raise NotImplementedError   # TODO: implement    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "ocp_-zty9HLG",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.5 Train the model [10 points]</b>\n",
    "\n",
    "It's time to train the beast! **Train your model below, printing out train and validation loss at regular intervals.**\n",
    "\n",
    "We (and the [Huggingface team](https://github.com/huggingface/transformers/blob/master/src/transformers/training_args.py)) recommend using `Adam` or `AdamW` as an optimizer with a learning rate of `5e-5`, no weight decay, and default beta and epsilon parameters (`betas = [0.9, 0.999]`, `eps = 1e-8`). You may need to tweak these parameters slightly to achieve good model performance. \n",
    "\n",
    "You may want to consider using a [linear scheduler](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#transformers.get_linear_schedule_with_warmup) for the learning rate. By default, Huggingface uses a linear scheduler with no warmup and which takes a scheduler step for every optimizer step (instead of every epoch).\n",
    "\n",
    "Finally, since we are forced to use a batch size of 1 due to memory constraints, you may also want to consider using [gradient accumulation](http://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html). In PyTorch, this just means doing multiple `loss.backward()` across batches before calling `optimizer.step()` and `optimizer.zero_grad()`.\n",
    "\n",
    "If everything goes to plan, you should see times of around 5 minutes per epoch, depending on the size of your datasets. Training for 5 - 10 epochs is plenty (you could probably get away with even fewer).\n",
    "\n",
    "To take advantage of GPU acceleration, as in the previous homework, remember to move your model to the GPU:\n",
    "\n",
    "```\n",
    "model.cuda()\n",
    "```\n",
    "\n",
    "as well as your training examples as you receive them:\n",
    "\n",
    "```\n",
    "example_tensor = example_tensor.cuda()\n",
    "```\n",
    "\n",
    "**MEGA CAUTION**: If you haven't read any of our previous warnings yet, read this one!\n",
    "\n",
    "When you move your model and examples to the GPU, you will start dipping into the very finite pool of VRAM (video RAM) available on Colab's cut-rate GPUs. If you've followed our previous advice (batch_size=1, frugal model), you should be fine. However, the moment you run this cell, **your model and examples will stay in GPU memory**. Worse, if your cell fails with an error or you halt execution prematurely, your cell may leak memory.\n",
    "\n",
    "For example, Colab has probably allocated for you a Tesla K80 GPU with 12 GB of VRAM. For us, running the training cell will take almost 7GB of VRAM. Once this cell finishes (or throws an error), that 7GB of VRAM continues hanging around. That means the next time we run this cell, if that memory hasn't been released (and it probably hasn't), PyTorch will try to allocate *another 7GB*, but because there isn't another 7GB free, it will return a `CUDA out of memory` error. To manually free that memory, you can try some of our tips from above (manual garbage collection, deleting unused variables, emptying the cache), but it probably won't get everything. \n",
    "\n",
    "**If all else fails, the easiest (sometimes only) way to empty your memory is to restart your kernel and rerun the notebook from the start.**\n",
    "\n",
    "To do so, on the top bar select `Runtime --> Restart and run all`.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qQ5N0cfW9JC1",
    "new_sheet": false,
    "outputId": "99c60c43-e465-4873-fcd1-8ec31b417c74",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# implement your training loop here\n",
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "aB6SquKYCzgU",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_pink'>\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "<div class='q_pink'><b>2.6 Generate text [6 points]</b>\n",
    "    \n",
    "Now the fun part, playing with our trained model! To start, fill out the method below that generates a novel sequence of text. Given some primer text, you should use GPT2 to continually generate the next token until it hits either the max sequence length or the end of text token `<|endoftext|>`.\n",
    "\n",
    "Some hints:\n",
    "* Observe that with a single invocation, GPT2 will only predict one additional new token. The other $N - 1$ predictions are for tokens in your input sequence. Thus, you will have to call GPT2 many times, feeding back the primer plus the new predicted word, to produce a sequence of novel words.\n",
    "* To generate different examples with each call, rather than calling `argmax` over your word probabilities, why not use them as sampling probabilities instead? That is, if your vocabulary is `[ball, cow, planet, grass]` and your probabilities for the next word are `[0.1, 0.5, 0.2, 0.2]`, then with probability $0.5$ the next word should be `cow`.\n",
    "* To convert an index back into the original token, use HuggingFace's `tokenizer.decode()` method. Check out the [API](https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase) for details.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(primer: str, max_length=50):\n",
    "    raise NotImplementedError   # TODO: implement    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "Iq529eEpFxn8",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Try running the cell below to test your `generate()` function. Feel free to play around with different primers to get a feel for how your model behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ROTxVDJDROlO",
    "new_sheet": false,
    "outputId": "5cb681a6-28d1-4dbb-feea-97487048db97",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 5\n",
    "max_length = 5\n",
    "primer = \"your prompt here\"\n",
    "for i in range(n_examples):\n",
    "    ex = generate(primer, max_length)\n",
    "    print(f'Ex {i}: {ex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "VkGqLe_tL9wN",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "<div class='q_pink'><b>2.7 Unconditioned Generation [5 points]</b>\n",
    "    \n",
    "    \n",
    "Now lets do a few particular examples. Generate $10$ songs without conditioning (i.e. with only the `<|endoftext|>` token for a primer). Write a few sentences evaluating how your model performs. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_phXEbTwpm_x",
    "new_sheet": false,
    "outputId": "aa220767-9cf0-4401-f5fb-b3d7e08606fe",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "sDagi0wo9pNN",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "fmq85ywsH66h",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.8 Lyric Completion [5 points]</b>\n",
    "\n",
    "### Lyric Completion Evaluation\n",
    "\n",
    "Now let's use the beginning of each song as a primer. For a couple of songs in the validation set, omit the final $\\{10\\%, 30\\%, 50\\%, 70\\%, 90\\%\\}$ of each song and generate the remaining lyrics for the song. \n",
    "\n",
    "Write a few sentences comparing your predictions to the true lyrics. How do these differ between artists? How does the length of the primer affect the style and accuracy of the completed lyrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "w3bf9hDkCUBO",
    "new_sheet": false,
    "outputId": "e4caaace-6582-4b9d-9259-6ee55239d586",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "-bUXZWuL-B-c",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "j-P2aVIa1Iau",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.9 Song Title Generation [5 points]</b>\n",
    "\n",
    "\n",
    "Now condition on only the artist names and generate several song titles per artist. Write a few sentences about the generated titles. How realistic are these titles? How do they compare to the other titles' of the artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "NPmr5PfX1IvT",
    "new_sheet": false,
    "outputId": "37856e99-d21e-4fc8-965d-a890134c099e",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "33LlxraI-Stv",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "1FTboYjO1JGu",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_pink'><b>2.10 Full Song Generation [5 points]</b>\n",
    "\n",
    "Now condition on artist names and *new* song titles of your creation. Write a few sentences evaluating the resulting lyrics. How realistic are they given your titles? How reasonable are they for a song in general? How does their style compare to other lyrics by that artist?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "jec94Zfl1JfS",
    "new_sheet": false,
    "outputId": "9d470bc2-ef31-4a47-e168-6e7e1b047b3d",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError   # TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "f2mc3XMg-bwL",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_green'>\n",
    "    \n",
    "# 3. RESEARCH PAPER 1 [16 points]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**NOTE:** Since I want everyone to dedicate the vast majority of the remaining semester to the research project, I highly suggest selecting papers that are related to your project. And, for this final homework, we will ask you to read two papers, not just one.\n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "As we build a foundation in NLP, it's also important to also see what the latest, cutting-edge work (research) looks like. It's incredibly worthwhile to learn about the types of problems people work on, their methodology and approach to the problem, the datasets they work on, the issues they raise, and the solutions they posit. The field moves incredibly fast, but the __approach__ to ML/NLP research is relatively stable -- different types of papers are accepted as the years progress, but that's a different story.\n",
    "\n",
    "We want to help you get practice reading research papers, which mostly entails thinking critically about the work, being able to discern the main takeaways/conclusions, and to reflect on the work in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.1: Read an NLP research paper [0 points]</b>\n",
    "    \n",
    "Select and read a paper that was published in ACL, NAACL, EMNLP, or COLING in 2020 or 2021. You can find a list of such published papers by searching Google, a la \"ACL 2020 accepted papers\". For this assignment, you are allowed to pick either a short paper (4-5 pages) or long paper (8-9 pages), **but you must not select a workshop paper**. List below the name of the paper, authors, venue, and year published.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR PAPER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.2: Problem? [2 point]</b> What is the problem that it is trying to address? In other words, what is it trying to solve? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.3: Solution? [2 point]</b> At a very high-level, what was their solution? (2-3 sentences). Here, you don't have room to go into the small details (e.g., about the model), so you'll need to summarize the most important elements that comprised the solution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.4: Data? [2 points]</b> What dataset(s) did they use? Are they freely available? What's the size of the data? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.5: Model [2 points]</b> Very related to the 'solutions' question, describe here any models that they used, and what made it effective (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.6: Results? [2 points]</b> What are their main results? (~2 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.7: Strengths? [2 points]</b> List 2-3 strengths of the paper\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.8: Weaknesses? [2 points]</b> Although you may be new to this problem and all of its content, try to list 2-3 weaknesses of the paper (anything that you think could strengthen the paper is sufficient).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.9: Evaluation [2 points]</b>\n",
    "    \n",
    "How would you evaluate this paper in terms of:\n",
    "- scientific contribution\n",
    "- effectiveness to solve the problem\n",
    "- how convincing it was.\n",
    "    \n",
    "Give each of these elements a score from 1-10 (10 is best). No word explanation necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>3.10: Research Ideas [4 points]</b>\n",
    "    \n",
    "Think of 1-2 research ideas that you have based on this paper. It doesn't have to be grand; most research is very incremental. Specifically, your research idea should have a concrete question that you're aiming to answer. List it below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_green'>\n",
    "    \n",
    "# 4. RESEARCH PAPER 2 [16 points]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And another one! -- DJ Khaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.1: Read an NLP research paper [0 points]</b>\n",
    "    \n",
    "Select and read a paper that was published in ACL, NAACL, EMNLP, or COLING in 2020 or 2021. You can find a list of such published papers by searching Google, a la \"ACL 2020 accepted papers\". For this assignment, you are allowed to pick either a short paper (4-5 pages) or long paper (8-9 pages), **but you must not select a workshop paper**. List below the name of the paper, authors, venue, and year published.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR PAPER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.2: Problem? [2 point]</b> What is the problem that it is trying to address? In other words, what is it trying to solve? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.3: Solution? [2 point]</b> At a very high-level, what was their solution? (2-3 sentences). Here, you don't have room to go into the small details (e.g., about the model), so you'll need to summarize the most important elements that comprised the solution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.4: Data? [2 points]</b> What dataset(s) did they use? Are they freely available? What's the size of the data? (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.5: Model [2 points]</b> Very related to the 'solutions' question, describe here any models that they used, and what made it effective (2-3 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.6: Results? [2 points]</b> What are their main results? (~2 sentences)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.7: Strengths? [2 points]</b> List 2-3 strengths of the paper\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.8: Weaknesses? [2 points]</b> Although you may be new to this problem and all of its content, try to list 2-3 weaknesses of the paper (anything that you think could strengthen the paper is sufficient).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.9: Evaluation [2 points]</b>\n",
    "    \n",
    "How would you evaluate this paper in terms of:\n",
    "- scientific contribution\n",
    "- effectiveness to solve the problem\n",
    "- how convincing it was.\n",
    "    \n",
    "Give each of these elements a score from 1-10 (10 is best). No word explanation necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>4.10: Research Ideas [4 points]</b>\n",
    "    \n",
    "Think of 1-2 research ideas that you have based on this paper. It doesn't have to be grand; most research is very incremental. Specifically, your research idea should have a concrete question that you're aiming to answer. List it below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_green'><b>BONUS POINTS [5 points]</b> I mention the full details in the syllabus on the course website. However, in short, these bonus points cannot bring one's grade to exceed 100. That is, if someone received a 97 on this homework, doing this bonus could allow their grade to reach 100 points. If the person had an 83 on the homework, then the most they could achieve is an 88.\n",
    "    \n",
    "The task: read another research paper -- meaning, a total of 3 papers. It's allowed to be a Short Paper. Write answers to the same questions again. Please copy and paste all of the questions below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='header_blue'>\n",
    "    \n",
    "# 5. SELF-REFLECTION [0 points]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class='q_blue'><b>5.1: Self-reflection and Feedback [0 points]</b>\n",
    "\n",
    "Are you thriving in the course? Are there elements that are particularly confusing to you? I want everyone to be and feel fully supported. Toward this, I strongly urge you all to think critically about your own learning and efforts. Please provide us with feedback about how you're doing in the course and if there's anything further or different we can do to better assist your learning. I want everyone to give their earnest account, so the form is completely anonymous.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Anonymous Self-Reflection and Feedback Form](https://forms.gle/3LT6UfhtCtqp2G7X9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPT2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b2878c7fc3474cb814054b752715ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69f0e7a209104fa1a84544fbe2a275de",
      "placeholder": "",
      "style": "IPY_MODEL_b1fa862825e84bfc922fff8b8b8878c4",
      "value": "Downloading: 100%"
     }
    },
    "025e01116824455e8b70c4dca85f2f24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0389cfa273704b78b9b03be0701e2a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55d07adfe752463fbee3f67b19f4ff15",
      "placeholder": "",
      "style": "IPY_MODEL_1096730759ed46f9919f5f14c8abcf9f",
      "value": " 446k/446k [00:00&lt;00:00, 1.12MB/s]"
     }
    },
    "0d56cebb76e645cdb7a3a1cbe1b84e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1096730759ed46f9919f5f14c8abcf9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "135210d23cff4d6da47cfdf0953ed15d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16f9dd84a9af4c54b0555589b695e66c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18db0f741d7c4a44bda84f8831ecca45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c729acbeff441cc987701bf3e2409a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01b2878c7fc3474cb814054b752715ad",
       "IPY_MODEL_9d94c8d28cc2473bb3c1987bc9c5a189",
       "IPY_MODEL_0389cfa273704b78b9b03be0701e2a66"
      ],
      "layout": "IPY_MODEL_b38d18b2fbec450186b44e1dc0a52e28"
     }
    },
    "1c8f4786c3f748ac92f3bfc1b56784e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ca0e30c7ae44981bcbba52f31234b6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23f13728922c4be393f44555005b3612": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "295b4203047c45c49f26efb057f9605b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_913243f2301f4adaa9fe16095d2bd736",
      "placeholder": "",
      "style": "IPY_MODEL_1ca0e30c7ae44981bcbba52f31234b6e",
      "value": " 665/665 [00:00&lt;00:00, 15.0kB/s]"
     }
    },
    "296fe0aeaf234eb3a7afbb5c92cfd5f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fb82b05c6824b5f93210830366fd7e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c42869b9fc6b446eae63ec0b3050d2ee",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f33881a0e77246a6b85055b2313096a4",
      "value": 665
     }
    },
    "30eb7e8a7e044d568f806a00529c0a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d56cebb76e645cdb7a3a1cbe1b84e1d",
      "placeholder": "",
      "style": "IPY_MODEL_18db0f741d7c4a44bda84f8831ecca45",
      "value": " 0.99M/0.99M [00:00&lt;00:00, 4.97MB/s]"
     }
    },
    "3288849322c94113be1cff4bd74f6c4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3430e14e44a047239366a8fc53647998": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39a661f1a36d4ff5864488a94ccc8276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6709f10fbf724a2e8ab1e4b5fea05ad2",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e41604eb8c14c63aafacfe70e34b4f9",
      "value": 1042301
     }
    },
    "446bca6140d84ef2a3879816dcc07e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4813cac23d8d4fbe83a95c859212fe79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a5f484f29954b07836871bf0372e0ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d70d58468ce4f8dbb739b50a98efbe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3430e14e44a047239366a8fc53647998",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_135210d23cff4d6da47cfdf0953ed15d",
      "value": 548118077
     }
    },
    "50c464ba6ef14a6290d0a1f3d97e28a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51280023210a4286b6d66c008da63e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5252abd87f184ccb9fb8cd90a80cc65a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55d07adfe752463fbee3f67b19f4ff15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af686e54f63414fba6a2fca10db7a23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4813cac23d8d4fbe83a95c859212fe79",
      "placeholder": "",
      "style": "IPY_MODEL_446bca6140d84ef2a3879816dcc07e70",
      "value": "Downloading: 100%"
     }
    },
    "5e41604eb8c14c63aafacfe70e34b4f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63d752c17c2a4bf79278c228ee41a808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "661a7e842cc44d9e8d7ee5c298e14bfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6709f10fbf724a2e8ab1e4b5fea05ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69f0e7a209104fa1a84544fbe2a275de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b555668b43d4544b1eb74d24a671969": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d2de255bab3493b996d90602ef9de3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50c464ba6ef14a6290d0a1f3d97e28a1",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7408553cb6c41c28675b52758552ff2",
      "value": 1355256
     }
    },
    "7da403c9d944495caa3c6c9457b99915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_661a7e842cc44d9e8d7ee5c298e14bfc",
      "placeholder": "",
      "style": "IPY_MODEL_3288849322c94113be1cff4bd74f6c4a",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 3.55MB/s]"
     }
    },
    "7f70fe6e28044efc9b92471d9c992ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8204ec53bdaf4d5aafe454fb2b214d1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8edc5fb7172d47daab9127e8a5f8bf6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5af686e54f63414fba6a2fca10db7a23",
       "IPY_MODEL_2fb82b05c6824b5f93210830366fd7e2",
       "IPY_MODEL_295b4203047c45c49f26efb057f9605b"
      ],
      "layout": "IPY_MODEL_a12d9b62092a46979105216fa97a1aa9"
     }
    },
    "913243f2301f4adaa9fe16095d2bd736": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d94c8d28cc2473bb3c1987bc9c5a189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16f9dd84a9af4c54b0555589b695e66c",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f70fe6e28044efc9b92471d9c992ce9",
      "value": 456318
     }
    },
    "a12d9b62092a46979105216fa97a1aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c7fabe1d8347689d09f34a7081d25a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a5f484f29954b07836871bf0372e0ca",
      "placeholder": "",
      "style": "IPY_MODEL_51280023210a4286b6d66c008da63e9a",
      "value": "Downloading: 100%"
     }
    },
    "a6f8e12c178447d9aa68606de34c70d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_296fe0aeaf234eb3a7afbb5c92cfd5f4",
      "placeholder": "",
      "style": "IPY_MODEL_025e01116824455e8b70c4dca85f2f24",
      "value": "Downloading: 100%"
     }
    },
    "b1fa862825e84bfc922fff8b8b8878c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b38d18b2fbec450186b44e1dc0a52e28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba3cc33f63ed41a989f2b08ed0234f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb5f17900b0141219d24142d0b447e08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5c7fabe1d8347689d09f34a7081d25a",
       "IPY_MODEL_7d2de255bab3493b996d90602ef9de3e",
       "IPY_MODEL_7da403c9d944495caa3c6c9457b99915"
      ],
      "layout": "IPY_MODEL_23f13728922c4be393f44555005b3612"
     }
    },
    "c42869b9fc6b446eae63ec0b3050d2ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5b7f68fb3774b61b3ee0d53d5887902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6f8e12c178447d9aa68606de34c70d5",
       "IPY_MODEL_39a661f1a36d4ff5864488a94ccc8276",
       "IPY_MODEL_30eb7e8a7e044d568f806a00529c0a3c"
      ],
      "layout": "IPY_MODEL_8204ec53bdaf4d5aafe454fb2b214d1c"
     }
    },
    "e7408553cb6c41c28675b52758552ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f33881a0e77246a6b85055b2313096a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9543fa001364b8292cabf19a7dd3cd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c8f4786c3f748ac92f3bfc1b56784e1",
      "placeholder": "",
      "style": "IPY_MODEL_5252abd87f184ccb9fb8cd90a80cc65a",
      "value": " 523M/523M [00:20&lt;00:00, 21.2MB/s]"
     }
    },
    "fc297b28bc46492285d9b401f5a51598": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b555668b43d4544b1eb74d24a671969",
      "placeholder": "",
      "style": "IPY_MODEL_63d752c17c2a4bf79278c228ee41a808",
      "value": "Downloading: 100%"
     }
    },
    "fd2109a3918e4788a3c6a8be3e5d8c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc297b28bc46492285d9b401f5a51598",
       "IPY_MODEL_4d70d58468ce4f8dbb739b50a98efbe1",
       "IPY_MODEL_f9543fa001364b8292cabf19a7dd3cd6"
      ],
      "layout": "IPY_MODEL_ba3cc33f63ed41a989f2b08ed0234f65"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
